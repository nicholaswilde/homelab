# llama

See documentation located [here][1].

## Notes

- [Tutorial: Offline Agentic coding with llama-server](https://github.com/ggml-org/llama.cpp/discussions/14758)

[1]: <https://nicholaswilde.io/homelab/apps/llama/>
