{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Homelab","text":"<p>A repo for my homelab setup.</p>"},{"location":"#background","title":"Background","text":"<p>I just want to document and share my homelab setup and experiences.</p> <p>My current setup is Proxmox installed on an AMD64 desktop computer, and old AMD64 laptop, a Raspberry Pi 4 8GB, and a Raspberry Pi 5 16GB.</p> <p>I also have an Intel NUC running Ubuntu server with Home Assistant and add ons in Docker containers.</p> <p>I also have a Raspberry Pi Zero W running an NTP server.</p> <p>Note</p> <p>All commands run on LXCs are being run as <code>root</code> and so <code>sudo</code> is not required.</p> <p>Note</p> <p>The commands assume that this repo is cloned into a directory <code>/root/git/nicholaswilde/homelab</code>.</p> <p>Note</p> <p>I tend to use tteck's ProxmoxVE Helper Scripts and Proxmox arm64 Install Scripts to create LXCs and not run in Docker containers to reduce resources.</p> <p>Info</p> <p>Features or applications that I come across on the Internet and have not yet been incorporated into my homelab are tracked in the repository issues.</p>"},{"location":"#setup-maintenance","title":"Setup &amp; Maintenance","text":"<p>My homelab is setup and maintained using Ansible, which is documented here.</p>"},{"location":"#development","title":"Development","text":"<p>Check out the Development page.</p>"},{"location":"#license","title":"License","text":"<p>\u200b\u200bApache License 2.0</p>"},{"location":"#author","title":"\u200bAuthor","text":"<p>\u200bThis project was started in 2024 by \u200bNicholas Wilde\u200b.</p>"},{"location":"#references","title":"References","text":"<ul> <li>https://docs.techdox.nz/</li> </ul>"},{"location":"AGENTS/","title":"Markdown Documentation Guidelines for Gemini","text":"<p>Context: This directory contains all project documentation in Markdown format.</p> <p>Specific Instructions for Markdown Files: - Use clear and descriptive headings (H1 for main topic, H2 for sub-sections). - Employ bullet points and numbered lists for readability. - Use backticks (<code>`</code>) for inline code and triple backticks (<code>) for code blocks, specifying the language (e.g.,</code>bash<code>, ```python</code>). - Keep paragraphs concise. - Link to relevant files or sections using relative paths where appropriate. - Ensure a consistent tone and voice (e.g., formal, informal, instructional). - Favor simple Markdown over complex HTML embeds unless absolutely necessary. - All documentation is written in Markdown and generated using the MkDocs with the Material theme. - Adhere strictly to the MkDocs-Material syntax extensions for features like admonitions, content tabs, and icons. - Ensure all new pages are added to the <code>nav</code> section of the <code>mkdocs.yml</code> file to appear in the site navigation. - All internal links must be relative and point to other <code>.md</code> files within the <code>docs/</code> directory. - Do not use first-person nor third-person perspective in the document.</p>"},{"location":"AGENTS/#markdown-style-guide","title":"Markdown Style Guide:","text":"<ul> <li>Headings: Use ATX-style headings (<code>#</code>, <code>##</code>, <code>###</code>, etc.). The main page title is always H1 (<code>#</code>).</li> <li>All Headings should start with emoji using mkdocs-material compatible shortcode.</li> <li>Admonitions: Use admonitions to highlight important information.</li> <li><code>!!! note</code> for general information.</li> <li><code>!!! code</code> for computer code and commands.</li> <li><code>!!! abstract</code> for referencing files.</li> <li><code>??? abstract</code> for long files that need to be collapsed.</li> <li><code>!!! tip</code> for helpful advice.</li> <li><code>!!! warning</code> for critical warnings or potential issues.</li> <li><code>!!! danger</code> for severe risks.</li> <li>Code Blocks: Always specify the language for syntax highlighting (e.g., <code>```python</code>). For shell commands, use <code>shell</code> or <code>bash</code>. Use <code>ini</code> for <code>.env</code> files.</li> <li>Lists: Use hyphens (<code>-</code>) for unordered lists and numbers (<code>1.</code>) for ordered lists.</li> <li>Icons &amp; Emojis: Use Material Design icons and emojis where appropriate to improve visual communication, e.g., <code>:material-check-circle:</code> for success.</li> <li>Icons &amp; Emojis: Use the short codes for emoji instead of the emoji itself.</li> <li>Use 2 spaces for indentation.</li> <li>List items that are links should be inclosed with &lt; and &gt;.</li> <li>Formatting shall be compatible with markdownlint.</li> <li>All hyperlinks should reference a number and the numbers should be at the bottom of the document (e.g. <code>[tool name][1] and</code>1: ` )"},{"location":"AGENTS/#sections","title":"Sections:","text":"<ul> <li>All sections should have emoji in front of the section name.</li> <li>References: Always end a page with a References section.</li> <li>References section starts with the  emoji.</li> <li>References section has a list of relevant links.</li> <li>Config: Create a config section</li> <li>Installation: Create an installation section.</li> <li>This section should show instructions for both amd64 and arm64 architectures.</li> <li>Usage: Create a usage section</li> <li>Upgrade: Create an upgrade section.</li> </ul>"},{"location":"AGENTS/#file-naming-conventions","title":"File Naming Conventions:","text":"<ul> <li>Applications: Files in <code>docs/apps/</code> should be named <code>app-name.md</code> (e.g., <code>adguard.md</code>).</li> <li>Tools: Files in <code>docs/tools/</code> should be named <code>tool-name.md</code> (e.g., <code>sops.md</code>).</li> <li>Hardware: Files in <code>docs/hardware/</code> should be named <code>hardware-name.md</code> (e.g., <code>rpi5.md</code>).</li> </ul>"},{"location":"AGENTS/#content-structure","title":"Content Structure:","text":"<p>All markdown files should follow a consistent structure to ensure readability and maintainability. The recommended sections are:</p> <ul> <li>Front Matter: (Optional) Includes <code>tags</code> for categorization.</li> <li>Title: H1 heading with an appropriate emoji and the name of the application, tool, or hardware.</li> <li>Description: A brief overview of the item, often including a hyperlink to its official source.</li> <li>Installation: Instructions on how to install the item, typically with code blocks for different architectures or methods (e.g., <code>amd64</code>, <code>arm64</code>, <code>Docker</code>, <code>Task</code>).</li> <li>Config: Details on how to configure the item, including relevant file paths and example configurations.</li> <li>Usage: Instructions and examples on how to use the item.</li> <li>Upgrade: Instructions on how to upgrade the item, often with <code>Task</code> or manual commands.</li> <li>Troubleshooting: (Optional) Common issues and their solutions.</li> <li>References: A list of relevant external links, with numbered references at the bottom of the document.</li> </ul>"},{"location":"AGENTS/#docsapps","title":"docs/apps/","text":"<p>This directory contains documentation for applications installed in the homelab. Each application's markdown file should provide comprehensive instructions for installation, configuration, usage, and upgrading, adhering to the general content structure.</p>"},{"location":"AGENTS/#docstools","title":"docs/tools/","text":"<p>This directory contains documentation for various tools used in the homelab. Each tool's markdown file should detail its installation, configuration, and usage, following the general content structure.</p>"},{"location":"AGENTS/#docshardware","title":"docs/hardware/","text":"<p>This directory contains documentation for hardware components in the homelab. Each hardware's markdown file should include its specifications, configuration details, and any specific setup or usage instructions, following the general content structure.</p>"},{"location":"AGENTS/#regarding-dependencies","title":"Regarding Dependencies:","text":"<ul> <li>The primary dependency is mkdocs-material.</li> <li>The project also uses the pymdown-extensions for advanced formatting.</li> <li>Mermaid is an acceptable plugin.</li> <li>Do not introduce new MkDocs plugins without prior discussion and approval.</li> </ul>"},{"location":"AGENTS/#example-script-structure","title":"Example Script Structure:","text":"<p>tags:   - relevant-tags</p>"},{"location":"AGENTS/#emoji-name-of-application-or-tool","title":":emoji: Name of application or tool","text":"<p>Description of application or tool. The name of the tool should be a hyperlink to the original source.</p>"},{"location":"AGENTS/#installation","title":"Installation","text":"<p>Instructions on how to install the application or tool.</p> amd64arm64 <pre><code>code to install the application or tool\n</code></pre> <pre><code>code to install the application or tool\n</code></pre>"},{"location":"AGENTS/#config","title":"Config","text":"<p>Instructions on how to configure the application or tool.</p> <p>homelab/path/config/file</p> <pre><code>example of yaml config file\n</code></pre>"},{"location":"AGENTS/#usage","title":"Usage","text":"<p>Instructions on how to use the application or tool.</p>"},{"location":"AGENTS/#upgrade","title":"Upgrade","text":"<p>Code to upgrade the application or tool.</p> TaskManual <pre><code>task update\n</code></pre> <pre><code>command to update application or tool\n</code></pre>"},{"location":"AGENTS/#references","title":"References","text":"<ul> <li> <li>"},{"location":"travel/","title":"Travel","text":"<p>My network setup when traveling.</p>","tags":["travel"]},{"location":"travel/#equipment","title":"Equipment","text":"<ul> <li>Fire TV Stick Lite to stream content on the stock TV.</li> <li>TP-Link AC750 Wireless Portable Nano Travel Router to provide my own network where my phone, computer, and Fire TV Stick is preconfigured to connect to.</li> <li>CableGeeker Ethernet Splitter 1 to 2 High Speed 1000Mbps to keep the existing networking devices on the network, such as a VOIP phone or streaming device.</li> <li>Anker 511 USB C Charger 30W to charge phones.</li> <li>Anker Dual Port 12W USB A Charger Block with Foldable Plug to power the splitter and router.</li> <li>eufy Security, SpaceView Pro Video Baby Monitor E210</li> </ul>","tags":["travel"]},{"location":"travel/#diagrams","title":"Diagrams","text":"<p>The purpose of these diagrams and tables are for me to visualize and count the number of items I need to pack.</p>","tags":["travel"]},{"location":"travel/#ethernet","title":"Ethernet","text":"<pre><code>graph TD\n    Charger[\"Anker Dual Port 12W USB A Charger Block\"]\n    Splitter[\"CableGeeker Splitter\"]\n    Router[\"TP-Link AC750 Router\"]\n    Phone[\"VOIP Phone/Router\"]\n\n    Wall -- Ethernet Cable --&gt; Splitter\n    Splitter -- Ethernet Cable --&gt; Router\n    Splitter -- Ethernet Cable --&gt; Phone:::critical\n    Charger -- \"USB A to C Cable\" --&gt; Splitter\n    Charger -- \"USB A to Micro Cable\" --&gt; Router\n\n    classDef critical stroke:#000,stroke-width:2px</code></pre>","tags":["travel"]},{"location":"travel/#power-connections","title":"Power Connections","text":"<pre><code>graph TD\n    Phone1[\"Android Phone 1\"]\n    Phone2[\"Android Phone 2\"]\n    Power1[\"Anker 511 USB C Charger 30W\"]\n    Power2[\"Anker B2692 USB C Charger 45W\"]\n    Power3[\"USB A Charger\"]\n    Power4[\"USB A Charger\"]\n    FireTV[\"Fire TV Stick Lite\"]\n    Monitor[\"Baby Monitor/Camera\"]\n\n    Power1 -- \"USB C to C Cable\" --&gt; Phone1\n    Power2 -- \"USB C to C Cable\" --&gt; Phone2\n    Power3 -- \"USB A to Micro Cable\" --&gt; FireTV\n    Power4 -- \"USB C to Micro Cable\" --&gt; Monitor</code></pre>","tags":["travel"]},{"location":"travel/#cables-power-adapters","title":"Cables &amp; Power Adapters","text":"Type Side A Side B Qty Notes USB C C 2 Phones USB A C 1 Splitter USB A Micro 3 Router &amp; Baby Monitor USB C - 1 Watch Ethernet RJ45 RJ45 3 Router Charger A - 2 -","tags":["travel"]},{"location":"travel/#future","title":"Future","text":"","tags":["travel"]},{"location":"travel/#storage","title":"Storage","text":"<p>I'd like to store my setup in a larger Maxpedition case, such as the Maxpedition Fatty Pocket Organizer.</p>","tags":["travel"]},{"location":"travel/#references","title":"References","text":"","tags":["travel"]},{"location":"about/development/","title":"Development","text":"<p>The development of my homelab is mainly done by watching YouTube videos and occasionally browsing Reddit.</p>","tags":["about"]},{"location":"about/development/#installation","title":"Installation","text":"","tags":["about"]},{"location":"about/development/#repo","title":"Repo","text":"<p>Generally, the repo is meant to be used as a centralized location for my homelab config files and setup instructions.</p> <p>This repo is cloned into each container and VM and then updated and maintained on that container and VM.</p> <pre><code>(\n    [ -d ~/git/nicholaswilde ] || mkdir -p ~/git/nicholaswilde\n    cd ~/git/nicholaswilde &amp;&amp; \\\n    git clone git@github.com:nicholaswilde/homelab.git &amp;&amp; \\\n    cd homelab\n)\n</code></pre>","tags":["about"]},{"location":"about/development/#containers-vms","title":"Containers &amp; VMs","text":"<p>I use different installation methods for the containers and VMs depending on what is available.</p>","tags":["about"]},{"location":"about/development/#proxmox-helper-script","title":"Proxmox Helper Script","text":"<p>If a it exists as a Proxmox Helper Script, I'll use that.</p>","tags":["about"]},{"location":"about/development/#lxc","title":"LXC","text":"<p>If that doesn't exist, I'll clone a Debian LXC and manually install the app. Generally, I like to stick with LXCs because of their lower overhead.</p>","tags":["about"]},{"location":"about/development/#vm","title":"VM","text":"<p>I'll use a VM if I need to pass through a device or the installation is complicated. I'll clone an existing Debian or Ubuntu VM and do a manual installation.</p>","tags":["about"]},{"location":"about/development/#docker","title":"Docker","text":"<p>Sometimes if the installation is really complicated, I'll use Docker inside of and LXC or VM. I generally try to avoid Docker containers because of the overhead of Docker being installed in the container or VM.</p>","tags":["about"]},{"location":"about/development/#tools","title":"Tools","text":"","tags":["about"]},{"location":"about/development/#apt","title":"apt","text":"<p>Tools are generally installed, generally, using <code>apt</code>.</p> <p>Note</p> <p>I try to avoid using other package systems, such as <code>pip</code> or <code>npm</code>, to avoid the overhead of having those package systems installed.</p>","tags":["about"]},{"location":"about/development/#reprepro","title":"reprepro","text":"<p>If a <code>deb</code> file is available for download for the tool, I'll add it to my <code>reprepro</code> registry and install the tool using <code>apt</code>. Updating the tool is then just a matter of running apt update using Ansible.</p>","tags":["about"]},{"location":"about/development/#installer","title":"installer","text":"<p>If the tool is only available to download as a binary file, I'll use my <code>installer</code> container.</p>","tags":["about"]},{"location":"about/development/#config","title":"Config","text":"<p>Config files are backed up into this repo so that can be replicated or referenced when lost.</p>","tags":["about"]},{"location":"about/development/#keys","title":"Keys","text":"<p>Keys are syncronized across containers using Syncthing so that I don't have to manually copy them over.</p>","tags":["about"]},{"location":"about/development/#backups","title":"Backups","text":"<p>The original files are copied into the original config location with a <code>.bak</code> extension before making any changes to them.</p> Example <pre><code>cp /etc/prometheus/prometheus.yml /etc/prometheus/prometheus.yml.bak\n</code></pre>","tags":["about"]},{"location":"about/development/#symlinks","title":"Symlinks","text":"<p>Generally, config files are moved to the repo for remote backup and then symlinked back to the original location.</p> <p>Note</p> <p>The app service needs to be stopped and restarted when moving the config files.</p> Example <pre><code>(\n  systemctl stop prometheus.service\n  cp /etc/prometheus/prometheus.yml /root/git/nicholaswilde/homelab/pve/prometheus/prometheus.yml\n  ln -s /root/git/nicholaswilde/homelab/pve/prometheus/prometheus.yml /etc/prometheus/prometheus.yml\n  systemctl stop prometheus.service\n)\n</code></pre> <p>Warning</p> <p>Some apps have trouble starting their service when using symlinked config files.</p>","tags":["about"]},{"location":"about/development/#encrypted-files","title":"Encrypted Files","text":"<p>If the config file contains secrets, the file is encrypted and saved in the repo and the unencrypted file is added to <code>.gitignore</code>.</p> <p>Encrypted files will end in <code>.enc</code> and are encrypted using SOPS and age.</p> Example <pre><code>sops -d --input-type dotenv --output-type dotenv .env.enc &gt; .env\n</code></pre>","tags":["about"]},{"location":"about/development/#env-files","title":".env Files","text":"<p>.env files are used to store variables and secrets. There are used whenever possible.</p> <p><code>.env</code> files are ignored in this repo so that secrets aren't commited.</p>","tags":["about"]},{"location":"about/development/#template-files","title":"Template Files","text":"<p>Template files end in <code>.tmpl</code> and are not used by the app and are meant to be copied.</p> Example <pre><code>cp .env.tmpl .env\n</code></pre>","tags":["about"]},{"location":"about/development/#workflow","title":"Workflow","text":"<p>My general workflow when creating a new LXC or VM.</p> <ol> <li>Create VM or LXC container.</li> <li>Run <code>homelab-pull</code>.</li> <li>Add to Ansible inventory.</li> <li>Setup app.</li> <li>Backup config files to repo on cintainer.</li> <li>Add to AdGuardHome.</li> <li>Run AdGuardHome sync.</li> <li>Add to Traefik.</li> <li>Add to homepage.</li> <li>Add to homelab docs.</li> <li>Add to WatchYourLAN.</li> <li>Add to Beszel.</li> <li>Add to authentik.</li> </ol>","tags":["about"]},{"location":"about/development/#new-document-pages","title":"New Document Pages","text":"<p>New pages for this site can be created using jinja2 and the <code>.template.md.j2</code> file.</p> <p><code>homelab/docs</code></p> Taskjinja2-cli <pre><code>APP_NAME=\"New App\" task new &gt; apps/new-app.md\n</code></pre> <pre><code>jinja2 .template.md.j2 -D app_name=\"New App\" -D app_port=8080 -D config_path=/opt/new-app &gt; apps/new-app.md\n</code></pre>","tags":["about"]},{"location":"about/development/#upgrades","title":"Upgrades","text":"","tags":["about"]},{"location":"about/development/#upgrades-via-proxmox-helper-scripts","title":"Upgrades via Proxmox Helper Scripts","text":"<p>The helper scripts can update the app in the LXC/VM.</p>","tags":["about"]},{"location":"about/development/#docker-upgrades","title":"Docker Upgrades","text":"<p>Docker tags are scanned by Mend Renovate , which opens a PR if a newer version is available.</p> <p>The PR is then merged and then the repo is pulled and updated on the LXC/VM and then Docker Compose performs a pull and restarts the Docker container.</p> <p>The old and unused images are then purged to save space in the LXC/VM.</p> <p>Warning</p> <p>The below commands purge any unused Docker images! Use at your own risk!</p> <p><code>homelab/docker/appname</code></p> TaskManual <pre><code>task upgrade\n</code></pre> <pre><code>(\n  git pull origin\n  docker compose up --force-recreate --build -d\n  docker image prune -a -f\n)\n</code></pre>","tags":["about"]},{"location":"about/development/#cronjobs","title":"Cronjobs","text":"<p>Cronjobs  are run on some containers to periodically perform functions, usually to sync files.</p> <p>Edit job</p> Manual <pre><code>crontab -e\n</code></pre> <pre><code>0 2 * * * * /foo.sh\n</code></pre>","tags":["about"]},{"location":"about/development/#services","title":"Services","text":"<p>Systemd services are used to keep processes running in the background.</p> <p>The services are usually created automatically if installed via a package manager, such as <code>apt</code> .</p> <p>Apps that are manually installed, such as Ventoy, need a service to keep them running after restarts.</p> <p>Docker  containers don't require services because they are managed by the restart policy.</p>","tags":["about"]},{"location":"about/development/#logs","title":"Logs","text":"<p>Logs are used to debug applications. They may be looked at once or followed get to real time updates.</p>","tags":["about"]},{"location":"about/development/#lxc-logs","title":"LXC Logs","text":"Example journalctl <pre><code>journalctl -xeu prometheus.service\n</code></pre>","tags":["about"]},{"location":"about/development/#docker-logs","title":"Docker Logs","text":"Example OnceFollowed <pre><code>docker logs immich-server\n</code></pre> <pre><code>docker logs immich-server -f\n</code></pre>","tags":["about"]},{"location":"about/development/#references","title":"References","text":"","tags":["about"]},{"location":"about/future/","title":"Future","text":"<p>Ramblings and stream of conscienceness on the future of my homelab.</p>","tags":["about"]},{"location":"about/future/#size","title":"Size","text":"<p>I currently use a shallow full size 8U rack mounted to a wall.</p> <p>In general, I like to keep the footprint small and out of way, but also accessible.</p> <p>One thought is to go to a mini rack, but then I'd have to get rid of my current switch.</p> <p>The other concern is the number of ports, which I like to keep connected to RJ45 ports routed to rooms in the house, althrough some are not being used.</p> <p> Do I disconnect the ports that I'm not using from the patch panel and figure out a solution when I need them ?</p>","tags":["about"]},{"location":"about/future/#os","title":"OS","text":"","tags":["about"]},{"location":"about/future/#desktop","title":"Desktop","text":"<p>I don't use many desktop environments. When I do, it's either ChromeOS or Windows 11.</p> <p>I don't have a desire at the moment to try anything new.</p>","tags":["about"]},{"location":"about/future/#server","title":"Server","text":"<p>My favorite server OS is Debian which I got used to when I started with Ubuntu. I prefer Debian over Ubuntu, at the moment, due to it's smaller size and just install the applications that I need.</p> <p>I tried Arch a while ago, but was too finicky to setup and time consuming.</p> <p>I haven't tried Alpine linux, other than when compiling my own Docker images.</p> <p>What I would like to try is NixOS because it's infractructure as code and it is easy to backup.</p>","tags":["about"]},{"location":"about/future/#nas","title":"NAS","text":"<p>I'd like to have some type of NAS to properly store my files as well has some kind of backup.</p> <p>I currently have 5TB external drive attached to my HP Pro desk, but it's not backed up in any way and not very compact.</p> <p>My initial thoughts is to use 4 SSDs on a Raspberry Pi 5 using a Radxa Penta SATA HAT due to it's compactness, but the the speeds may suffer due to the RPi's 1 Gbit speeds.  Do I actually need more than 1Gbit speeds ?</p>","tags":["about"]},{"location":"apps/adguard-sync/","title":"Adguard Home Sync","text":"<p>AdGuard Home Sync is used to sync settings between my AdGuard Home instances.</p> <p>It is installed only on the primary instance and is scheduled to run once a day, which is scheduled in the config file.</p>","tags":["lxc","proxmox"]},{"location":"apps/adguard-sync/#installation","title":"Installation","text":"<p> Default Port: <code>8080</code></p> <p> Binary path: <code>/usr/local/bin</code></p> <p>Install</p> <pre><code>task install\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/adguard-sync/#config","title":"Config","text":"<p>/etc/systemd/system/adguardhome-sync.service</p> Automatic <p>```shell cat &gt; /etc/systemd/system/adguardhome-sync.service &lt;&lt;EOF [Unit] Description = AdGuardHome Sync After = network.target</p> <p>[Service]         ExecStart = /usr/local/bin/adguardhome-sync --config ${HOME}/git/nicholaswilde/homelab/pve/adguardhome-sync/adguardhome-sync.yaml run</p> <pre><code>    [Install]\n    WantedBy = multi-user.target\n    EOF\n    ```\n\n=== \"Download\"\n\n    ```shell\n    wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/adguardhome-sync/adguardhome-sync.service -O /etc/systemd/system/adguardhome-sync.service\n    ```\n\n=== \"Manual\"\n\n    ```ini title=\"/opt/adguardhome-sync/adguardhome-sync.service\"\n    [Unit]\n    Description = AdGuardHome Sync\n    After = network.target\n\n    [Service]\n    ExecStart = /usr/local/bin/adguardhome-sync --config ${HOME}/git/nicholaswilde/homelab/pve/adguardhome-sync/adguardhome-sync.yaml run\n\n    [Install]\n    WantedBy = multi-user.target\n    ```\n</code></pre> <p>Enable service</p> <p><code>shell (   cp /opt/adguardhome-sync/adguardhome-sync.service /etc/systemd/system/ &amp;&amp; \\  systemctl enable adguardhome-sync.service &amp;&amp; \\  systemctl start adguardhome-sync.service &amp;&amp; \\  systemctl status adguardhome-sync.service )</code></p>","tags":["lxc","proxmox"]},{"location":"apps/adguard-sync/#upgrade","title":"Upgrade","text":"<pre><code>task update\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/adguard-sync/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* bootstrap:             Bootstrap adguardhome-sync\n* decrypt:               Decrypt sensitive configuration files using SOPS.\n* default:               List all available tasks.\n* enable:                Enable the application's systemd service.\n* encrypt:               Encrypt sensitive configuration files using SOPS.\n* export:                Export the task list to `task-list.txt`.\n* init:                  Initialize the application's environment and configuration files.\n* install:               Install adguardhome-sync\n* install-service:       Install the application's systemd service.\n* reload:                Reload the application's systemd service.\n* restart:               Restart the application's systemd service.\n* start:                 Start the application's systemd service.\n* status:                Get the service status\n* stop:                  Stop the application's systemd service.\n* update:                Update adguardhome-sync\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/adguard-sync/#references","title":"References","text":"<ul> <li>https://github.com/bakito/adguardhome-sync</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/adguard/","title":"AdGuard Home","text":"<p>AdGuard Home (AGH) is used to filter ads and as my DNS rewites (assign hostnames to IP addresses).</p> <p>I have two instances of AGH running: one as an LXC and one on a bare metal Raspberry Pi 2.</p> <p>Syncing between the instances are done using AdGuard Home Sync</p>","tags":["lxc","proxmox"]},{"location":"apps/adguard/#installation","title":"Installation","text":"<p> Default Port: <code>3000</code></p> <p> Configuration path: <code>/opt/AdGuardHome</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/adguard.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/adguard.sh)\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/adguard/#config","title":"Config","text":"<p>/opt/AdGuardHome/AdGuardHome.yaml</p> <pre><code>rewrites:\n    - domain: adguard02.l.nicholaswilde.io\n      answer: 192.168.3.250\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/adguard/#upgrade","title":"Upgrade","text":"<p>Upgrading the app is done via the web GUI.</p>","tags":["lxc","proxmox"]},{"location":"apps/adguard/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* enable:        Enable the application's systemd service.\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list to `task-list.txt`.\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Resart service\n* start:         Start service\n* status:        Check the status of the application's systemd service.\n* stop:          Stop service\n* upgrade:       upgrade\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/adguard/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=adguard</li> <li>https://pimox-scripts.com/scripts?id=adguard</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/apache-guacamole/","title":"Apache Guacamole","text":"<p>Apache Guacamole is used to remote into GUI based systems, such as Windows 11</p>","tags":["lxc","proxmox"]},{"location":"apps/apache-guacamole/#installation","title":"Installation","text":"<p> Default Port: <code>8080</code></p> <p> Url: <code>http://ip-address:8080/guacamole</code></p> <p> Configuration path: <code>/etc/guacamole/guacd.conf</code></p> <p> Default username: <code>guacadmin</code></p> <p> Default uassword: <code>guacadmin</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/apache-guacamole.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/apache-guacamole.sh)\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/apache-guacamole/#config","title":"Config","text":"","tags":["lxc","proxmox"]},{"location":"apps/apache-guacamole/#windows-11","title":"Windows 11","text":"<p>Connections</p> Edit ConnectionNetworkAuthentication <p>Name: <code>w11</code></p> <p>Location: <code>Root</code></p> <p>Protocol: <code>RDP</code></p> <p>Hostname: <code>192.168.2.154</code></p> <p>Port: <code>3389</code></p> <p>Username: <code>username</code></p> <p>Password: <code>password</code></p> <p>Domain: <code>W11</code></p> <p>Info</p> <p>Domain should match the hostname of the W11 computer.</p>","tags":["lxc","proxmox"]},{"location":"apps/apache-guacamole/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/apache-guacamole.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    apache-guacamole:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`guac.l.nicholaswilde.io`)\"\n      middlewares:\n        - guacamole-add-prefix\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: apache-guacamole\n#endregion\n#region services\n  services:\n    apache-guacamole:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.156:8080\"\n        passHostHeader: true\n#endregion\n  middlewares:\n    guacamole-add-prefix:\n      addprefix:\n        prefix: \"/guacamole\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/apache-guacamole/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* enable:        Enable service\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Resart service\n* start:         Start service\n* status:        Service status\n* stop:          Stop service\n* update:        Update running containers\n* upgrade:       Upgrade app\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/apache-guacamole/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=apache-guacamole</li> <li>https://pimox-scripts.com/scripts?id=apache-guacamole</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/aptcacherng/","title":"Apt-Cacher NG","text":"<p>Apt-Cacher NG is used as a cache system for the debian based apt management system.</p>","tags":["lxc","proxmox"]},{"location":"apps/aptcacherng/#installation","title":"Installation","text":"<p> Default Interface: <code>3142/acng-report.html</code></p> <p> Configuration path: <code>/etc/apt-cacher-ng</code></p> AMD64ARM64apt <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/apt-cacher-ng.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/apt-cacher-ng.sh)\"\n</code></pre> <pre><code>apt install apt-cacher-ng\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/aptcacherng/#config","title":"Config","text":"<p>Warning</p> <p>For some reason, apt-cacher-ng doesn't work when the <code>acng.conf</code> file is symlinked to the repo directly and so the config file needs to be manually synced.</p> <p>/etc/apt-cacher-ng/acng.conf</p> Manual <pre><code>CacheDir: /mnt/storage/aptcache\n</code></pre> <p>/mnt/storage/aptcache</p> <pre><code>(\n  chown -R apt-cacher-ng:apt-cacher-ng /mnt/storage/aptcache\n  systemctl restart apt-cacher-ng.service\n  systemctl status apt-cacher-ng.service\n  journalctl -xeu apt-cacher-ng.service\n)\n</code></pre> <pre><code>http://aptcache.l.nicholaswilde.io:3142/acng-report.html\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/aptcacherng/#client","title":"Client","text":"<p>/etc/apt/apt.conf.d/00aptproxy</p> AutomatedManual <pre><code>(\n  echo 'Acquire::http::Proxy \"http://aptcache.l.nicholaswilde.io:3142\";' | tee /etc/apt/apt.conf.d/00aptproxy &amp;&amp; \\\n  apt update\n)\n</code></pre> <pre><code>Acquire::http::Proxy \"http://192.168.2.40:3142\";\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/aptcacherng/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/aptcache.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    aptcache:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`aptcache.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: aptcache\n\n#endregion\n#region services\n  services:\n    aptcache:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.40:3142\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/aptcacherng/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make symlinks\n* restart:       Restart service\n* start:         Start service\n* stop:          Stop service\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/aptcacherng/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=apt-cacher-ng</li> <li>https://pimox-scripts.com/scripts?id=Apt-Cacher-NG</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/aria2/","title":"aria2","text":"","tags":["lxc","proxmox"]},{"location":"apps/aria2/#installation","title":"Installation","text":"<p> Default Port: <code>6880</code></p> <p> Within the LXC console, run <code>cat rpc.secret</code> to display the rpc-secret. Copy this token and paste it into the Aria2 RPC Secret Token box within the AriaNG Settings. Then, click the reload AriaNG button.</p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/aria2.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/aria2.sh)\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/aria2/#config","title":"Config","text":"<p>Make symlinks to repo.</p>","tags":["lxc","proxmox"]},{"location":"apps/aria2/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/aria2.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    aria2:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`aria2.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: aria2\n    aria2s:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`aria2s.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: aria2s\n#endregion\n#region services\n  services:\n    aria2:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.21:6880\"\n        passHostHeader: true\n    aria2s:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.21:6800\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/aria2/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* enable:        Enable service\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Resart service\n* start:         Start service\n* status:        Service status\n* stop:          Stop service\n* update:        Update running containers\n* upgrade:       Upgrade app\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/aria2/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=aria2</li> <li>https://pimox-scripts.com/scripts?id=aria2</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/authentik/","title":"authentik","text":"<p>authentik is used as a single sign on provider. This is so I don't have different logins for different applications.</p>","tags":["lxc","proxmox"]},{"location":"apps/authentik/#installation","title":"Installation","text":"<p> Default Port: <code>9000</code></p> AMD64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/authentik.sh)\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/authentik/#config","title":"Config","text":"<p>WIP</p>","tags":["lxc","proxmox"]},{"location":"apps/authentik/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* enable:        Enable service\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Resart service\n* start:         Start service\n* status:        Service status\n* stop:          Stop service\n* update:        Update running containers\n* upgrade:       Upgrade app\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/authentik/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=authentik</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/beszel/","title":"Beszel","text":"<p>Beszel is used as a monitoring tool for my homelab.</p>","tags":["lxc","proxmox"]},{"location":"apps/beszel/#installation","title":"Installation","text":"<p> Hub Port: <code>8090</code></p> <p> Agent Port: <code>45876</code></p> hubagent <pre><code>curl -sL https://raw.githubusercontent.com/henrygd/beszel/main/supplemental/scripts/install-hub.sh -o install-hub.sh &amp;&amp; chmod +x install-hub.sh &amp;&amp; ./install-hub.sh\n</code></pre> <pre><code>curl -sL https://raw.githubusercontent.com/henrygd/beszel/main/supplemental/scripts/install-agent.sh -o  install-agent.sh &amp;&amp; chmod +x install-agent.sh &amp;&amp; ./install-agent.sh\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/beszel/#config","title":"Config","text":"<p>Make symlinks to repo.</p>","tags":["lxc","proxmox"]},{"location":"apps/beszel/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/beszel.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    beszel:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`beszel.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: beszel\n#endregion\n#region services\n  services:\n    beszel:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.35:8090\"\n        passHostHeader: true\n#endregion\n  middlewares:\n    https-redirectscheme:\n      redirectScheme:\n        scheme: https\n        permanent: true\n    default-headers:\n      headers:\n        frameDeny: true\n        browserXssFilter: true\n        contentTypeNosniff: true\n        forceSTSHeader: true\n        stsIncludeSubdomains: true\n        stsPreload: true\n        stsSeconds: 15552000\n        customFrameOptionsValue: SAMEORIGIN\n        customRequestHeaders:\n          X-Forwarded-Proto: https\n\n    default-whitelist:\n      ipAllowList:\n        sourceRange:\n        - \"10.0.0.0/8\"\n        - \"192.168.0.0/16\"\n        - \"172.16.0.0/12\"\n\n    secured:\n      chain:\n        middlewares:\n        - default-whitelist\n        - default-headers\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/beszel/#notifications","title":"Notifications","text":"<ol> <li>mailrise via <code>smtp</code>.</li> <li>ntfy via webhook.</li> <li>Gotify via webhook.</li> </ol>","tags":["lxc","proxmox"]},{"location":"apps/beszel/#usage","title":"Usage","text":"<p>WIP</p>","tags":["lxc","proxmox"]},{"location":"apps/beszel/#upgrade","title":"Upgrade","text":"TaskManual <pre><code>task update\n</code></pre> <pre><code>./beszel update\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/beszel/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Restart service\n* start:         Start service\n* status:        Status\n* stop:          Stop service\n* upgrade:       upgrade\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/beszel/#references","title":"References","text":"","tags":["lxc","proxmox"]},{"location":"apps/changedetection/","title":"Change Detection","text":"<p>Change Detection is used to monitor websites and send notifications for when the websites have changed. I typically use this to be notified of when a new release of an OS image is released.</p>","tags":["lxc","proxmox"]},{"location":"apps/changedetection/#installation","title":"Installation","text":"<p> Default Port: <code>5000</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/changedetection.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/changedetection.sh)\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/changedetection/#config","title":"Config","text":"<pre><code>apt install apprise\n</code></pre> <p>Test</p> <pre><code>apprise -vv -t 'my title' -b 'my notification body' 'mailto://user:passkey@gmail.com'\n</code></pre> <p>Notification URL List</p> <pre><code>mailto://user:passkey@gmail.com\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/changedetection/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/changedetection.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    changedetection:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`cd.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: changedetection\n\n#endregion\n#region services\n  services:\n    changedetection:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.83:5000\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/changedetection/#upgrade","title":"Upgrade","text":"<pre><code>(\n  echo 'bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/changedetection.sh)\"' | tee -a ~/.bash_aliases &amp;&amp; \\\n  source ~/.bashrc &amp;&amp; \\\n  update\n)\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/changedetection/#notifications","title":"Notifications","text":"<ol> <li>Apprise</li> <li>ntfy</li> <li>Gotify</li> </ol>","tags":["lxc","proxmox"]},{"location":"apps/changedetection/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* backup:        Backup ChangeDetection\n* clean:         Clean node_modules\n* decrypt:       Decrypt scan.db using SOPS\n* deps:          Install dependencies\n* encrypt:       Encrypt scan.db using SOPS\n* export:        Export the task list\n* init:          Init app\n* mklinks:       Make symlinks\n* restart:       Restart ChangeDetection service\n* start:         Start ChangeDetection service\n* stop:          Stop changedetection service\n* update:        Update ChangeDetection\n* upgrade:       Upgrade ChangeDetection\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/changedetection/#references","title":"References","text":"<ul> <li>https://github.com/caronc/apprise</li> <li>https://pimox-scripts.com/scripts?id=Change+Detection</li> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=changedetection</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/convertx/","title":"ConvertX","text":"<p>ConvertX is a self-hosted online file convert. Supports 1000+ formats.</p>","tags":["lxc","proxmox","docker"]},{"location":"apps/convertx/#installation","title":"Installation","text":"<p> Default Port: <code>3000</code></p> <p><code>homelab/docker/convertx</code></p> TaskDocker Compose <pre><code>task up\n</code></pre> <pre><code>docker compose up\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/convertx/#config","title":"Config","text":"<p><code>homelab/docker/convertx/.env</code></p> <pre><code>CONTAINER_NAME=convertx\nJWT_SECRET=\n\n# -- age backup --\n# AGE_PUBLIC_KEYS=age123456\n</code></pre> <code>homelab/docker/convertx/compose.yaml</code> <pre><code>---\nservices:\n  convertx:\n    container_name: \"${CONTAINER_NAME}\"\n    image: \"ghcr.io/c4illin/convertx:v0.14.1\"\n    env_file:\n      - .env\n    ports:\n      - '3000:3000'\n    restart: always\n    environment:\n      - HTTP_ALLOWED=true\n      - ALLOW_UNAUTHENTICATED=true\n      # - \"JWT_SECRET=${JWT_SECRET}\"\n    volumes:\n      - data:/app/data\n  # https://offen.github.io/docker-volume-backup/\n  backup: &amp;backup_service\n    image: offen/docker-volume-backup:v2.44.0\n    environment: &amp;backup_environment\n      BACKUP_FILENAME: backup-%Y-%m-%dT%H-%M-%S.tar.gz\n      BACKUP_LATEST_SYMLINK: backup-latest.tar.gz\n      BACKUP_PRUNING_PREFIX: backup-\n      BACKUP_RETENTION_DAYS: '14'\n      AGE_PUBLIC_KEYS: \"${AGE_PUBLIC_KEYS}\"\n      BACKUP_STOP_DURING_BACKUP_LABEL: service\n    volumes:\n      - data:/backup/my-app-backup:ro\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      - ${HOME}/backups:/archive\n      # - /mnt/storage/backup/reactive-resume:/archive\n      - /etc/timezone:/etc/timezone:ro\n      - /etc/localtime:/etc/localtime:ro\n\nvolumes:\n  data:\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/convertx/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/convertx.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    convertx:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`convertx.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: convertx\n#endregion\n#region services\n  services:\n    convertx:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.144:3000\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/convertx/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* backup:        Backup the application's volume data.\n* decrypt:       Decrypt sensitive configuration files using SOPS.\n* default:       List all available tasks.\n* encrypt:       Encrypt sensitive configuration files using SOPS.\n* export:        Export the task list to `task-list.txt`.\n* init:          Initialize the application's environment and configuration files.\n* pull:          Pull Docker images for the application.\n* restart:       Restart the application's Docker containers.\n* status:        Check the status of the application's Docker containers.\n* stop:          Stop the application's Docker containers.\n* up:            Run Docker Compose in the foreground.\n* up-d:          Run Docker Compose in the background.\n* update:        Update the application or its running containers.\n* upgrade:       Upgrade the application by pulling the latest changes and updating.\n* watch:         Watch the application's Docker container logs.\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/convertx/#references","title":"References","text":"<ul> <li>https://github.com/C4illin/ConvertX</li> </ul>","tags":["lxc","proxmox","docker"]},{"location":"apps/cyberkeygen/","title":"CyberKeyGen","text":"<p>CyberKeyGen is used as a simple password generator.</p>","tags":["lxc","proxmox","docker"]},{"location":"apps/cyberkeygen/#installation","title":"Installation","text":"<p> Default Port: <code>8080</code></p> <p> Configuration path: <code>/opt/cyberkeygen</code></p> <p>For this installation of CyberKeyGen, the LXC is used to both build and serve the static site. The reason for this to make it easier to build and deploy the site after an update.</p> <p><code>npm</code> and <code>vite</code> are used to build the site and an nginx Docker container is used to serve the site.</p> <pre><code>(\n  apt install npm\n  git clone https://github.com/karthik558/CyberKeyGen.git /opt/cyberkeygen\n  npm install --prefix /opt/cyberkeygen -D vite\n  npm run --prefix /opt/cyberkeygen build\n  docker run -it --rm -d -p 8080:80 --name web -v /opt/cyberkeygen/dist:/usr/share/nginx/html nginx\n)\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/cyberkeygen/#config","title":"Config","text":"<p>They CyberKeyGen source repo is stored in the <code>/opt/cyberkeygen</code> directory and the distribution files are stored in the <code>/opt/cyberkeygen/dist</code> directory after build.</p> <p><code>homelab/docker/cyberkeygen/.env</code></p> <pre><code>CONFIG_DIR=/opt/cyberkeygen/dist\nINSTALL_DIR=/opt/cyberkeygen\nCONTAINER_NAME=cyberkeygen\n</code></pre> <code>homelab/docker/cyberkeygen/compose.yaml</code> <pre><code>---\nservices:\n  cyberkeygen:\n    container_name: \"${CONTAINER_NAME}\"\n    image: \"nginx:1.28.0\"\n    env_file:\n      - .env\n    ports:\n      - '8080:80'\n    restart: always\n    volumes:\n      - \"${CONFIG_DIR}:/usr/share/nginx/html\"\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/cyberkeygen/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/cyberkeygen.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    cyberkeygen:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`cyberkeygen.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: cyberkeygen\n#endregion\n#region services\n  services:\n    cyberkeygen:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.104:8080\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/cyberkeygen/#upgrade","title":"Upgrade","text":"<p>To upgrade the CyberKeyGen app, the source repo is pulled and then rebuilt.</p> <p>The <code>nginx</code> Docker image is managed by Renovate and so and so after a Renovate PR is merged into this repo, this repo is pulled and the Docker container is pulled and restarted.</p> <p>Warning</p> <p>The below commands purge any unused Docker images! Use at your own risk!</p> <p><code>homelab/docker/cyberkeygen</code></p> TaskManual <pre><code>task upgrade\n</code></pre> <pre><code>(\n  git pull origin\n  git -C /opt/cyberkeygen pull origin\n  npm run --prefix /opt/cyberkeygen build\n  docker compose up --force-recreate --build -d\n  docker image prune -a -f\n)\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/cyberkeygen/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* build:          Build\n* decrypt:        Decrypt sensitive configuration files using SOPS.\n* default:        List all available tasks.\n* deps:           Install dependencies\n* encrypt:        Encrypt sensitive configuration files using SOPS.\n* export:         Export the task list to `task-list.txt`.\n* init:           Init everything\n* init-env:       Initialize the application's environment file.\n* pull:           Pull Docker images for the application.\n* restart:        Restart the application's Docker containers.\n* status:         Check the status of the application's Docker containers.\n* stop:           Stop the application's Docker containers.\n* up:             Run Docker Compose in the foreground.\n* up-d:           Run Docker Compose in the background.\n* update:         Update the application or its running containers.\n* upgrade:        Upgrade the application by pulling the latest changes and updating.\n* watch:          Watch the application's Docker container logs.\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/cyberkeygen/#references","title":"References","text":"<ul> <li>https://github.com/karthik558/CyberKeyGen</li> </ul>","tags":["lxc","proxmox","docker"]},{"location":"apps/excalidraw/","title":"Excalidraw","text":"<p>Excalidraw is used as a whiteboard to sketch ideas.</p>","tags":["lxc","proxmox","docker"]},{"location":"apps/excalidraw/#installation","title":"Installation","text":"<p> Default Port: <code>5000</code></p> <p><code>homelab/docker/excalidraw</code></p> TaskDocker Compose <pre><code>task up\n</code></pre> <pre><code>docker compose up\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/excalidraw/#config","title":"Config","text":"<p><code>homelab/docker/excalidraw/.env</code></p> <pre><code>CONTAINER_NAME=excalidraw\n</code></pre> <code>homelab/docker/excalidraw/compose.yaml</code> <pre><code>---\nservices:\n  excalidraw:\n    container_name: ${CONTAINER_NAME}\n    image: excalidraw/excalidraw:latest\n    env_file:\n      - .env\n    ports:\n      - '5000:80'\n    restart: always\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/excalidraw/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/excalidraw.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    excalidraw:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`draw.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: excalidraw\n#endregion\n#region services\n  services:\n    excalidraw:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.91:5000\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/excalidraw/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt sensitive configuration files using SOPS.\n* default:       List all available tasks.\n* encrypt:       Encrypt sensitive configuration files using SOPS.\n* export:        Export the task list to `task-list.txt`.\n* init:          Initialize the application's environment and configuration files.\n* pull:          Pull Docker images for the application.\n* restart:       Restart the application's Docker containers.\n* status:        Check the status of the application's Docker containers.\n* stop:          Stop the application's Docker containers.\n* up:            Run Docker Compose in the foreground.\n* up-d:          Run Docker Compose in the background.\n* update:        Update the application or its running containers.\n* upgrade:       Upgrade the application by pulling the latest changes and updating.\n* watch:         Watch the application's Docker container logs.\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/excalidraw/#references","title":"References","text":"","tags":["lxc","proxmox","docker"]},{"location":"apps/filebrowser/","title":"File Browser","text":"<p>File Browser is a web file browser.</p>","tags":["lxc","vm","proxmox"]},{"location":"apps/filebrowser/#installation","title":"Installation","text":"<p> Default Port: <code>8080</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/filebrowser.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/filebrowser.sh)\"\n</code></pre>","tags":["lxc","vm","proxmox"]},{"location":"apps/filebrowser/#config","title":"Config","text":"<p>Make symlinks to repo.</p>","tags":["lxc","vm","proxmox"]},{"location":"apps/filebrowser/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/filebrowser.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    filebrowser:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`fb.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: filebrowser\n#endregion\n#region services\n  services:\n    filebrowser:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.98:8095\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","vm","proxmox"]},{"location":"apps/filebrowser/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* backup:        Backup the application's volume data.\n* decrypt:       Decrypt sensitive configuration files using SOPS.\n* default:       List all available tasks.\n* encrypt:       Encrypt sensitive configuration files using SOPS.\n* export:        Export the task list to `task-list.txt`.\n* init:          Initialize the application's environment and configuration files.\n* pull:          Pull Docker images for the application.\n* restart:       Restart the application's Docker containers.\n* rm:            Remove container\n* shell:         Shell\n* status:        Check the status of the application's Docker containers.\n* stop:          Stop the application's Docker containers.\n* up:            Run Docker Compose in the foreground.\n* up-d:          Run Docker Compose in the background.\n* update:        Update the application or its running containers.\n* upgrade:       Upgrade the application by pulling the latest changes and updating.\n* watch:         Watch the application's Docker container logs.\n</code></pre>","tags":["lxc","vm","proxmox"]},{"location":"apps/filebrowser/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=filebrowser</li> <li>https://pimox-scripts.com/scripts?id=filebrowser</li> </ul>","tags":["lxc","vm","proxmox"]},{"location":"apps/frame-fi/","title":"FrameFi","text":"<p>FrameFi is an application used to display pictures on my digital picture frame using a LILYGO T-Dongle S3. This documentation focuses on how to download images from a Google Photos album using <code>rclone</code> so that the photos can then be synced with the frame.</p>","tags":["lxc","proxmox","rclone"]},{"location":"apps/frame-fi/#workflow","title":"Workflow","text":"<ol> <li>Add pictures to Google Photos album.</li> <li>Download pictures from album to homelab.</li> <li>Sync photos from homelab to digital picture frame via FrameFi (FTP).</li> </ol>","tags":["lxc","proxmox","rclone"]},{"location":"apps/frame-fi/#installation","title":"Installation","text":"<p>See rclone for <code>rclone</code> installation and FrameFi for how to setup FrameFi on your LILYGO T-Dongle S3.</p> <p> Configuration path: <code>/opt/frame-fi</code></p>","tags":["lxc","proxmox","rclone"]},{"location":"apps/frame-fi/#config","title":"Config","text":"<p>Before running the download script, you need to configure the <code>.env</code> file and <code>rclone</code>.</p> <p>Copy the <code>.env.tmpl</code> to <code>.env</code> and then edit the following variables:</p> <p><code>homelab/pve/frame-fi/.env</code></p> <pre><code>CONFIG_DIR=/etc/frame-fi\nINSTALL_DIR=/opt/frame-fi\nSERVICE_NAME=frame-fi\nRCLONE_GPHOTOS_CLIENT_ID=\"your_client_id\"\nRCLONE_GPHOTOS_CLIENT_SECRET=\"your_client_secret\"\nRCLONE_GPHOTOS_ALBUM_NAME=\"\"\nRCLONE_DOWNLOAD_DESTINATION=\"${INSTALL_DIR}/images\"\n\n# Mailrise Notification Settings (Optional)\nMAILRISE_HOST=\"smtp://smtp.l.nicholaswilde.io\"\nMAILRISE_PORT=\"8025\"\nMAILRISE_API_KEY=\"\"\nMAILRISE_FROM=\"test@example.com\"\nMAILRISE_TO=\"email@mailrise.xyz\"\n</code></pre> <ul> <li><code>RCLONE_GPHOTOS_CLIENT_ID</code>: Your Google API client ID for rclone.</li> <li><code>RCLONE_GPHOTOS_CLIENT_SECRET</code>: Your Google API client secret for rclone.</li> <li><code>RCLONE_GPHOTOS_ALBUM_NAME</code>: The exact name of the Google Photos album you wish to download.</li> <li><code>RCLONE_DOWNLOAD_DESTINATION</code>: The local directory where the downloaded images will be stored. Defaults to <code>${INSTALL_DIR}/images</code>.</li> </ul>","tags":["lxc","proxmox","rclone"]},{"location":"apps/frame-fi/#rclone-configuration","title":"Rclone Configuration","text":"<p>The <code>download.sh</code> script assumes an <code>rclone</code> remote named <code>gphotos</code> is configured to access Google Photos. If it's not already set up, you will need to configure it interactively using <code>rclone config</code>.</p> <p>Warning</p> <p>While the script sets the client ID and secret as environment variables, <code>rclone</code> typically requires an authenticated token for Google Photos. It is highly recommended to run <code>rclone config</code> interactively to set up the <code>gphotos</code> remote and obtain the necessary token.</p> <p>Warning</p> <p>Rclone can only download photos from albums that were created by rclone itself. It cannot download from albums created directly in Google Photos or by other applications.</p>","tags":["lxc","proxmox","rclone"]},{"location":"apps/frame-fi/#creating-google-photos-albums-with-rclone","title":"Creating Google Photos Albums with Rclone","text":"<p>To create a new Google Photos album that rclone can later download from, use the following command:</p> <p>Create Album</p> <pre><code>rclone mkdir gphotos:album/\"Your New Album Name\"\n</code></pre> <p>Replace <code>\"Your New Album Name\"</code> with the desired name for your album. Once created, you can upload photos to this album using rclone or manually via the Google Photos interface.</p>","tags":["lxc","proxmox","rclone"]},{"location":"apps/frame-fi/#usage","title":"Usage","text":"<p>To download images from your configured Google Photos album, simply run the <code>download</code> task:</p> <p>Download Images</p> TaskManual <pre><code>task download\n</code></pre> <pre><code>./download.sh\n</code></pre> <p>This will execute the <code>download.sh</code> script, which will:</p> <ol> <li> <p>Check for <code>rclone</code> dependency.</p> </li> <li> <p>Load environment variables from <code>.env</code>.</p> </li> <li> <p>Verify or attempt to configure the <code>gphotos</code> rclone remote.</p> </li> <li> <p>Create the Google Photos album if it does not already exist.</p> </li> <li> <p>Create the local destination directory if it doesn't exist.</p> </li> <li> <p>Use <code>rclone sync</code> to download images from the specified Google Photos album to the local destination.</p> </li> </ol>","tags":["lxc","proxmox","rclone"]},{"location":"apps/frame-fi/#automated-downloads-crontab","title":"Automated Downloads (Crontab)","text":"<p>To automate the daily download of images, a crontab job can be created using the <code>create-crontab.sh</code> script.</p>","tags":["lxc","proxmox","rclone"]},{"location":"apps/frame-fi/#create-crontab-job","title":"Create Crontab Job","text":"<p>Run the following command to create a daily crontab job that executes the <code>download.sh</code> script at 3:00 AM.</p> <p>Create Crontab Job</p> <pre><code>./create-crontab.sh\n</code></pre>","tags":["lxc","proxmox","rclone"]},{"location":"apps/frame-fi/#verify-crontab-job","title":"Verify Crontab Job","text":"<p>To verify that the crontab job has been successfully added, you can list your current crontab entries:</p> <p>List Crontab Jobs</p> <pre><code>crontab -l\n</code></pre>","tags":["lxc","proxmox","rclone"]},{"location":"apps/frame-fi/#remove-crontab-job","title":"Remove Crontab Job","text":"<p>If you need to remove the crontab job, you can edit your crontab and delete the relevant line:</p> <p>Edit Crontab Jobs</p> <pre><code>crontab -e\n</code></pre> <p>Locate and delete the line containing <code>download.sh</code>.</p>","tags":["lxc","proxmox","rclone"]},{"location":"apps/frame-fi/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* clean:                Remove all downloaded images from the local destination.\n* create-crontab:       Create a daily crontab job to download images.\n* decrypt:              Decrypt sensitive configuration files using SOPS.\n* default:              List all available tasks.\n* download:             Download images from Google Photos album.\n* enable:               Enable the application's systemd service.\n* encrypt:              Encrypt sensitive configuration files using SOPS.\n* export:               Export the task list to `task-list.txt`.\n* init:                 Initialize the application's environment and configuration files.\n* install:              Install the FrameFi application and set up its environment.\n* mklinks:              Create symbolic links for configuration files.\n* restart:              Restart the application's systemd service.\n* start:                Start the application's systemd service.\n* status:               Check the status of the application's systemd service.\n* stop:                 Stop the application's systemd service.\n* update:               Update the application or its running containers.\n* upgrade:              Upgrade the application by pulling the latest changes and updating.\n</code></pre>","tags":["lxc","proxmox","rclone"]},{"location":"apps/frame-fi/#references","title":"References","text":"<ul> <li>https://rclone.org/googlephotos/</li> <li>https://rclone.org/</li> </ul>","tags":["lxc","proxmox","rclone"]},{"location":"apps/gitea/","title":"Gitea","text":"<p>Gitea is used to have local git repos. I typically use it as a backup (mirror) of my GitHub repos.</p>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#installation","title":"Installation","text":"<p> Default Port: <code>3000</code></p> <p> Configuration path: <code>/etc/gitea/</code></p> <p> Custom path: <code>/var/lib/gitea/custom/</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/gitea.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/gitea.sh)\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#config","title":"Config","text":"","tags":["lxc","proxmox"]},{"location":"apps/gitea/#catppuccin","title":"Catppuccin","text":"<p>Info</p> <p>Gitea 1.20 or newer is required for this theme.</p> <ol> <li>Download the latest GitHub release.</li> <li>Place the CSS files inside Gitea's configuration directory:</li> <li>Gitea 1.21.0 or newer: <code>$GITEA_CUSTOM/public/assets/css</code></li> <li>Otherwise: <code>$GITEA_CUSTOM/public/css</code></li> <li>Add the themes to your <code>app.ini</code>. For further information on customizing Gitea, see the Gitea documentation.</li> <li>Restart your Gitea instance.</li> <li>Select the theme in <code>Gitea &gt; Account &gt; Settings &gt; Appearance</code>.</li> </ol>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#flavor-accent","title":"Flavor-Accent","text":"<p><code>/etc/gitea/app.ini</code></p> Manual <pre><code>[ui]\nTHEMES = catppuccin-latte-rosewater,catppuccin-latte-flamingo,catppuccin-latte-pink,catppuccin-latte-mauve,catppuccin-latte-red,catppuccin-latte-maroon,catppuccin-latte-peach,catppuccin-latte-yellow,catppuccin-latte-green,catppuccin-latte-teal,catppuccin-latte-sky,catppuccin-latte-sapphire,catppuccin-latte-blue,catppuccin-latte-lavender,catppuccin-frappe-rosewater,catppuccin-frappe-flamingo,catppuccin-frappe-pink,catppuccin-frappe-mauve,catppuccin-frappe-red,catppuccin-frappe-maroon,catppuccin-frappe-peach,catppuccin-frappe-yellow,catppuccin-frappe-green,catppuccin-frappe-teal,catppuccin-frappe-sky,catppuccin-frappe-sapphire,catppuccin-frappe-blue,catppuccin-frappe-lavender,catppuccin-macchiato-rosewater,catppuccin-macchiato-flamingo,catppuccin-macchiato-pink,catppuccin-macchiato-mauve,catppuccin-macchiato-red,catppuccin-macchiato-maroon,catppuccin-macchiato-peach,catppuccin-macchiato-yellow,catppuccin-macchiato-green,catppuccin-macchiato-teal,catppuccin-macchiato-sky,catppuccin-macchiato-sapphire,catppuccin-macchiato-blue,catppuccin-macchiato-lavender,catppuccin-mocha-rosewater,catppuccin-mocha-flamingo,catppuccin-mocha-pink,catppuccin-mocha-mauve,catppuccin-mocha-red,catppuccin-mocha-maroon,catppuccin-mocha-peach,catppuccin-mocha-yellow,catppuccin-mocha-green,catppuccin-mocha-teal,catppuccin-mocha-sky,catppuccin-mocha-sapphire,catppuccin-mocha-blue,catppuccin-mocha-lavender\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#auto","title":"Auto","text":"<p>This ensures that the theme automatically switches between light (latte) and dark (mocha) mode.</p> <p><code>/etc/gitea/app.ini</code></p> Manual <pre><code>[ui]\nTHEMES = catppuccin-rosewater-auto,catppuccin-flamingo-auto,catppuccin-pink-auto,catppuccin-mauve-auto,catppuccin-red-auto,catppuccin-maroon-auto,catppuccin-peach-auto,catppuccin-yellow-auto,catppuccin-green-auto,catppuccin-teal-auto,catppuccin-sky-auto,catppuccin-sapphire-auto,catppuccin-blue-auto,catppuccin-lavender-auto\n</code></pre> <p>Code</p> <pre><code>(\n  [ -d /var/lib/gitea/custom/public/assets/css ] || mkdir -p /var/lib/gitea/custom/public/assets/css\n  wget https://github.com/catppuccin/gitea/releases/latest/download/catppuccin-gitea.tar.gz -O /tmp/catppuccin-gitea.tar.gz &amp;&amp; \\\n  tar -xvf /tmp/catppuccin-gitea.tar.gz -C /var/lib/gitea/custom/public/assets/css &amp;&amp; \\\n  systemctl restart gitea.service\n)\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#email-notifications","title":"Email Notifications","text":"<p>Enable email notifications using mailrise.</p> <p>/etc/gitea/app.ini</p> <pre><code>[mailer]\nENABLED        = true\nFROM           = gitea@nicholaswilde.io\nPROTOCOL       = smtp\nSMTP_ADDR      = smtp.l.nicholaswilde.io\nSMTP_PORT      = 8025\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#send-a-test-email","title":"Send a test email","text":"<ol> <li> <p>Open your Git server (Gitea, GitHub, GitLab, etc.) in a web browser.</p> </li> <li> <p>Go to your \"Site Administration\".</p> </li> <li> <p>Find the \"Configuration -&gt; Summary\" (or similar) section.</p> </li> <li> <p>Under \"Mailer Configuration\", enter <code>email@mailrize.xyz</code> and click the \"Send\" button.</p> </li> </ol>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#ssh-domain","title":"SSH Domain","text":"<p>To be able to pull the gitea repo using a domain name rather than an IP address, change the following:</p> <p>/etc/gitea/app.ini</p> <pre><code>[server]\nSSH_DOMAIN = gitea-ssh.l.nicholaswilde.io\nDOMAIN = gitea.l.nicholaswilde.io\nHTTP_PORT = 3000\nROOT_URL = https://gitea.l.nicholaswilde.io/\nAPP_DATA_PATH = /var/lib/gitea/data\nDISABLE_SSH = false\nSSH_PORT = 22\n</code></pre> <p>The gitea repo should now show the <code>SSH_DOMAIN</code> in the <code>Code</code> button under <code>SSH</code> in the web GUI.</p> SSH <pre><code>gitea@gitea-ssh.l.nicholaswilde.io:nicholas/homelab.git\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#adguardhome-dns-rewrite","title":"AdGuardHome DNS Rewrite","text":"<p>In AdGuardHome DNS Rewrites, add an entry that forwards the <code>SSH_DOMAIN</code> directly to your gitea LXC.</p> <ul> <li>Domain: <code>gitea-ssh.l.nicholaswilde.io</code></li> <li>Answer: <code>192.168.2.20</code></li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#add-your-remote-machines-public-key-to-your-git-server","title":"Add Your Remote Machine's Public Key to Your Git Server","text":"<p>Your remote machine needs to be \"authorized\" to access your Git server. You do this by giving the server your machine's public key.</p> <ol> <li>Display the public key on your remote machine and copy it to your clipboard.</li> </ol> <p>Remote LXC</p> <pre><code>cat ~/.ssh/id_rsa.pub\n# Or, if you made an ed25519 key:\ncat ~/.ssh/id_ed25519.pub\n</code></pre> <p>The output will look something like <code>ssh-ed25519 AAAAC3... your_email@example.com</code>.</p> <ol> <li> <p>Open your Git server (Gitea, GitHub, GitLab, etc.) in a web browser.</p> </li> <li> <p>Go to your user Settings.</p> </li> <li> <p>Find the \"SSH / GPG Keys\" (or similar) section.</p> </li> <li> <p>Click \"Add Key\" and paste the public key you just copied.</p> </li> </ol>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#usage","title":"Usage","text":"<p>You can then clone a repo using the hostname rather than the gitea IP address.</p> <p>remote machine</p> <pre><code>git clone gitea@gitea-ssh.l.nicholaswilde.io:nicholas/homelab.git\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/gitea.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    gitea:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`gitea.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: gitea\n\n#endregion\n#region services\n  services:\n    gitea:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.20:3000\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Restart service\n* status:        Status\n* stop:          Stop service\n* update:        Update running containers\n* upgrade:       Upgrade app\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/gitea/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=homepage</li> <li>https://pimox-scripts.com/scripts?id=Homepage</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/gotify/","title":"Gotify","text":"<p>Gotify is a simple server for sending and receiving messages</p>","tags":["lxc","notifications","proxmox"]},{"location":"apps/gotify/#installation","title":"Installation","text":"<p> Default Port: <code>80</code></p> <p> Configuration path: <code>/opt/gotify/config.yml</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/gotify.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/gotify.sh)\"\n</code></pre>","tags":["lxc","notifications","proxmox"]},{"location":"apps/gotify/#config","title":"Config","text":"<p><code>homelab/docker/gotify/.env</code></p> <pre><code>CONFIG_DIR=/opt/gotify\nINSTALL_DIR=/opt/gotify\nSERVICE_NAME=gotify\n</code></pre> <code>homelab/pve/gotify/config.yml</code> <pre><code># Example configuration file for the server.\n# Save it to `config.yml` when edited\n\nserver:\n  keepaliveperiodseconds: 0 # 0 = use Go default (15s); -1 = disable keepalive; set the interval in which keepalive packets will be sent. Only change this value if you know what you are doing.\n  listenaddr: \"\" # the address to bind on, leave empty to bind on all addresses. Prefix with \"unix:\" to create a unix socket. Example: \"unix:/tmp/gotify.sock\".\n  port: 80 # the port the HTTP server will listen on\n\n  ssl:\n    enabled: false # if https should be enabled\n    redirecttohttps: true # redirect to https if site is accessed by http\n    listenaddr: \"\" # the address to bind on, leave empty to bind on all addresses. Prefix with \"unix:\" to create a unix socket. Example: \"unix:/tmp/gotify.sock\".\n    port: 443 # the https port\n    certfile: # the cert file (leave empty when using letsencrypt)\n    certkey: # the cert key (leave empty when using letsencrypt)\n    letsencrypt:\n      enabled: false # if the certificate should be requested from letsencrypt\n      accepttos: false # if you accept the tos from letsencrypt\n      cache: data/certs # the directory of the cache from letsencrypt\n      hosts: # the hosts for which letsencrypt should request certificates\n#      - mydomain.tld\n#      - myotherdomain.tld\n\n  responseheaders: # response headers are added to every response (default: none)\n#    X-Custom-Header: \"custom value\"\n#\n  trustedproxies: # IPs or IP ranges of trusted proxies. Used to obtain the remote ip via the X-Forwarded-For header. (configure 127.0.0.1 to trust sockets)\n#   - 127.0.0.1/32\n#   - ::1\n\n  cors: # Sets cors headers only when needed and provides support for multiple allowed origins. Overrides Access-Control-* Headers in response headers.\n    alloworigins:\n#      - \".+.example.com\"\n#      - \"otherdomain.com\"\n    allowmethods:\n#      - \"GET\"\n#      - \"POST\"\n    allowheaders:\n#      - \"Authorization\"\n#      - \"content-type\"\n  stream:\n    pingperiodseconds: 45 # the interval in which websocket pings will be sent. Only change this value if you know what you are doing.\n    allowedorigins: # allowed origins for websocket connections (same origin is always allowed)\n#      - \".+.example.com\"\n#      - \"otherdomain.com\"\n\ndatabase: # for database see (configure database section)\n  dialect: sqlite3\n  connection: data/gotify.db\n\ndefaultuser: # on database creation, gotify creates an admin user\n  name: admin # the username of the default user\n  pass: admin # the password of the default user\npassstrength: 10 # the bcrypt password strength (higher = better but also slower)\nuploadedimagesdir: data/images # the directory for storing uploaded images\npluginsdir: data/plugins # the directory where plugin resides\nregistration: false # enable registrations\n</code></pre>","tags":["lxc","notifications","proxmox"]},{"location":"apps/gotify/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* enable:        Enable service\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Resart service\n* start:         Start service\n* status:        Service status\n* stop:          Stop service\n* update:        Update running containers\n* upgrade:       upgrade\n</code></pre>","tags":["lxc","notifications","proxmox"]},{"location":"apps/gotify/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=gotify</li> <li>https://pimox-scripts.com/scripts?id=gotify</li> </ul>","tags":["lxc","notifications","proxmox"]},{"location":"apps/home-assistant-os/","title":"Home Assistant OS","text":"<p>My current setup consists of running Docker containers on my NUC. </p> <p>Evaluating if I want to convert to a VM running HAOS to better support add ons like Matter.</p> <p>I am not that familiar with HAOS and I don't know how else to back it up other than the entire VM. Also concerned about latency but perhaps I integrate redis, if I am not already.</p>","tags":["vm","proxmox"]},{"location":"apps/home-assistant-os/#installation","title":"Installation","text":"<p> Default Port: <code>8123</code></p> AMD64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/vm/haos-vm.sh)\"\n</code></pre>","tags":["vm","proxmox"]},{"location":"apps/home-assistant-os/#config","title":"Config","text":"<p>Make symlinks to repo.</p>","tags":["vm","proxmox"]},{"location":"apps/home-assistant-os/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=haos-vm</li> </ul>","tags":["vm","proxmox"]},{"location":"apps/homepage/","title":"homepage","text":"<p>homepage is my landing \ud83d\udeec page for my most frequented sites as well as my internal web pages.</p> <p>I don't show service statistics to keep things a bit cleaner and simple.</p> <p>I make this my \ud83c\udfe0 button as well as my new tab in Chrome so that it launches every time I launch Chrome, open a new tab, or click the home \ud83c\udfe0 button. I use the New Tab Redirect extension to redirect my new tab to homepage.</p>","tags":["lxc","proxmox"]},{"location":"apps/homepage/#installation","title":"Installation","text":"<p> Default Port: <code>3000</code></p> <p> Configuration (bookmarks.yaml, services.yaml, widgets.yaml) path: <code>/opt/homepage/config/</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/homepage.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/homepage.sh)\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/homepage/#config","title":"Config","text":"","tags":["lxc","proxmox"]},{"location":"apps/homepage/#symlinks","title":"Symlinks","text":"<p><code>/opt/homepage/config/</code></p> TaskManual <pre><code>task mklinks\n</code></pre> <pre><code>(\n  ln -s /root/git/nicholaswilde/homelab/pve/homepage/config/bookmarks.yaml /opt/homepage/config/\n  ln -s /root/git/nicholaswilde/homelab/pve/homepage/config/custom.css /opt/homepage/config/\n  ln -s /root/git/nicholaswilde/homelab/pve/homepage/config/custom.js /opt/homepage/config/\n  ln -s /root/git/nicholaswilde/homelab/pve/homepage/config/docker.yaml /opt/homepage/config/\n  ln -s /root/git/nicholaswilde/homelab/pve/homepage/config/kubernetes.yaml /opt/homepage/config/\n  ln -s /root/git/nicholaswilde/homelab/pve/homepage/config/services.yaml /opt/homepage/config/\n  ln -s /root/git/nicholaswilde/homelab/pve/homepage/config/settings.yaml /opt/homepage/config/\n  ln -s /root/git/nicholaswilde/homelab/pve/homepage/config/widgets.yaml /opt/homepage/config/\n  ls /opt/homepage/config/\n)\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/homepage/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/homepage.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    homepage:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`home.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: homepage  \n#endregion\n#region services\n  services:\n    homepage:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.47:3000\"\n        passHostHeader: true\n#endregion\n  middlewares:\n    https-redirectscheme:\n      redirectScheme:\n        scheme: https\n        permanent: true\n    default-headers:\n      headers:\n        frameDeny: true\n        browserXssFilter: true\n        contentTypeNosniff: true\n        forceSTSHeader: true\n        stsIncludeSubdomains: true\n        stsPreload: true\n        stsSeconds: 15552000\n        customFrameOptionsValue: SAMEORIGIN\n        customRequestHeaders:\n          X-Forwarded-Proto: https\n\n    default-whitelist:\n      ipAllowList:\n        sourceRange:\n        - \"10.0.0.0/8\"\n        - \"192.168.0.0/16\"\n        - \"172.16.0.0/12\"\n\n    secured:\n      chain:\n        middlewares:\n        - default-whitelist\n        - default-headers\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/homepage/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* enable:        Enable service\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Resart service\n* start:         Start service\n* status:        Service status\n* stop:          Stop service\n* update:        Update running containers\n* upgrade:       Upgrade app\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/homepage/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=homepage</li> <li>https://pimox-scripts.com/scripts?id=Homepage</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/immich-go/","title":"Immich-Go","text":"<p>Immich-Go is an open-source tool designed to streamline uploading large photo collections to your self-hosted Immich server.</p>","tags":["vm","proxmox"]},{"location":"apps/immich-go/#installation","title":"Installation","text":"installer <pre><code>curl -s https://installer.l.nicholaswilde.io/simulot/immich-go! | bash\n</code></pre>","tags":["vm","proxmox"]},{"location":"apps/immich-go/#config","title":"Config","text":"<p>~/.bash_exports</p> Manual <pre><code>export API_KEY='key'\nexport IMMICH_SERVER='https://server.xyz'\n</code></pre>","tags":["vm","proxmox"]},{"location":"apps/immich-go/#usage","title":"Usage","text":"<pre><code>immich-go upload from-google-photos takeout-20250216T024307Z-005.zip -k ${API_KEY} -s ${IMMICH_SERVER}\n</code></pre>","tags":["vm","proxmox"]},{"location":"apps/immich-go/#references","title":"References","text":"","tags":["vm","proxmox"]},{"location":"apps/immich/","title":"Immich","text":"<p>Immich photos is an open source alternative to Google Photos.</p> <p>Immich Go is a command line utility to assist with importing photos to Immich.</p>","tags":["vm","proxmox","docker"]},{"location":"apps/immich/#installation","title":"Installation","text":"<p> Default Port: <code>2283</code></p> <p><code>homelab/docker/immich</code></p> TaskDocker Compose <pre><code>task up\n</code></pre> <pre><code>docker compose up\n</code></pre>","tags":["vm","proxmox","docker"]},{"location":"apps/immich/#config","title":"Config","text":"<p><code>homelab/docker/immich/.env</code></p> <pre><code>UPLOAD_LOCATION=/mnt/storage/immich\nDB_DATA_LOCATION=./postgres\nDB_PASSWORD=password\nDB_USERNAME=postgres\nDB_DATABASE_NAME=immich\n</code></pre> <code>homelab/docker/immich/compose.yaml</code> <pre><code>---\nname: immich\n\nservices:\n  immich-server:\n    container_name: immich_server\n    image: ghcr.io/immich-app/immich-server:v1.142.1\n    # user: \"1000:1000\"\n    # extends:\n    #   file: hwaccel.transcoding.yml\n    #   service: cpu # set to one of [nvenc, quicksync, rkmpp, vaapi, vaapi-wsl] for accelerated transcoding\n    volumes:\n      # Do not edit the next line. If you want to change the media storage location on your system, edit the value of UPLOAD_LOCATION in the .env file\n      - ${UPLOAD_LOCATION}:/usr/src/app/upload\n      - /etc/localtime:/etc/localtime:ro\n    env_file:\n      - .env\n    ports:\n      - '2283:2283'\n    depends_on:\n      - redis\n      - database\n    restart: always\n    healthcheck:\n      disable: false\n\n  immich-machine-learning:\n    container_name: immich_machine_learning\n    # For hardware acceleration, add one of -[armnn, cuda, openvino] to the image tag.\n    # Example tag: ${IMMICH_VERSION:-release}-cuda\n    image: ghcr.io/immich-app/immich-machine-learning:v1.142.1\n    # extends: # uncomment this section for hardware acceleration - see https://immich.app/docs/features/ml-hardware-acceleration\n    #   file: hwaccel.ml.yml\n    #   service: cpu # set to one of [armnn, cuda, openvino, openvino-wsl] for accelerated inference - use the `-wsl` version for WSL2 where applicable\n    volumes:\n      - model-cache:/cache\n    env_file:\n      - .env\n    restart: always\n    healthcheck:\n      disable: false\n\n  redis:\n    container_name: immich_redis\n    image: docker.io/redis:7.4-alpine@sha256:02419de7eddf55aa5bcf49efb74e88fa8d931b4d77c07eff8a6b2144472b6952\n    healthcheck:\n      test: redis-cli ping || exit 1\n    restart: always\n\n  database:\n    container_name: immich_postgres\n    image: docker.io/tensorchord/pgvecto-rs:pg14-v0.2.0@sha256:739cdd626151ff1f796dc95a6591b55a714f341c737e27f045019ceabf8e8c52\n    environment:\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n      POSTGRES_USER: ${DB_USERNAME}\n      POSTGRES_DB: ${DB_DATABASE_NAME}\n      POSTGRES_INITDB_ARGS: '--data-checksums'\n    volumes:\n      # Do not edit the next line. If you want to change the database storage location on your system, edit the value of DB_DATA_LOCATION in the .env file\n      - ${DB_DATA_LOCATION}:/var/lib/postgresql/data\n    healthcheck:\n      test: &gt;-\n        pg_isready --dbname=\"$${POSTGRES_DB}\" --username=\"$${POSTGRES_USER}\" || exit 1;\n        Chksum=\"$$(psql --dbname=\"$${POSTGRES_DB}\" --username=\"$${POSTGRES_USER}\" --tuples-only --no-align\n        --command='SELECT COALESCE(SUM(checksum_failures), 0) FROM pg_stat_database')\";\n        echo \"checksum failure count is $$Chksum\";\n        [ \"$$Chksum\" = '0' ] || exit 1\n      interval: 5m\n      start_interval: 30s\n      start_period: 5m\n    command: &gt;-\n      postgres\n      -c shared_preload_libraries=vectors.so\n      -c 'search_path=\"$$user\", public, vectors'\n      -c logging_collector=on\n      -c max_wal_size=2GB\n      -c shared_buffers=512MB\n      -c wal_compression=on\n    restart: always\n\nvolumes:\n  model-cache:\n</code></pre>","tags":["vm","proxmox","docker"]},{"location":"apps/immich/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/immich.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    immich:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`photos.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: immich  \n#endregion\n#region services\n  services:\n    immich:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.27:2283\"\n        passHostHeader: true\n#endregion\n  middlewares:\n    https-redirectscheme:\n      redirectScheme:\n        scheme: https\n        permanent: true\n    default-headers:\n      headers:\n        frameDeny: true\n        browserXssFilter: true\n        contentTypeNosniff: true\n        forceSTSHeader: true\n        stsIncludeSubdomains: true\n        stsPreload: true\n        stsSeconds: 15552000\n        customFrameOptionsValue: SAMEORIGIN\n        customRequestHeaders:\n          X-Forwarded-Proto: https\n\n    default-whitelist:\n      ipAllowList:\n        sourceRange:\n        - \"10.0.0.0/8\"\n        - \"192.168.0.0/16\"\n        - \"172.16.0.0/12\"\n\n    secured:\n      chain:\n        middlewares:\n        - default-whitelist\n        - default-headers\n</code></pre>","tags":["vm","proxmox","docker"]},{"location":"apps/immich/#upgrade","title":"Upgrade","text":"<p>Warning</p> <p>The below commands purge any unused Docker images! Use at your own risk!</p> <p><code>homelab/docker/immich</code></p> TaskManual <pre><code>task upgrade\n</code></pre> <pre><code>(\n  git pull origin\n  docker compose up --force-recreate --build -d\n  docker image prune -a -f\n)\n</code></pre>","tags":["vm","proxmox","docker"]},{"location":"apps/immich/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt sensitive configuration files using SOPS.\n* default:       List all available tasks.\n* encrypt:       Encrypt sensitive configuration files using SOPS.\n* export:        Export the task list to `task-list.txt`.\n* init:          Initialize the application's environment and configuration files.\n* restart:       Restart the application's Docker containers.\n* up:            Run Docker Compose in the foreground.\n* up-d:          Run Docker Compose in the background.\n* update:        Update the application or its running containers.\n* upgrade:       Upgrade the application by pulling the latest changes and updating.\n* watch:         Watch the docker logs\n</code></pre>","tags":["vm","proxmox","docker"]},{"location":"apps/immich/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=immich</li> <li>https://pimox-scripts.com/scripts?id=Immich</li> </ul>","tags":["vm","proxmox","docker"]},{"location":"apps/installer/","title":"Installer","text":"<p>Installer is used to quickly install pre-compiled binaries from Github releases.</p> <p>For setup apps that have are not supported by apt package manager, such as task,  this method is used to install and update them. It makes it easier to install and update the apps without having to manually download them or install a another package system in the container, such as npm, pip, or homebrew.</p>","tags":["lxc","proxmox"]},{"location":"apps/installer/#installation","title":"Installation","text":"<p> Default Port: <code>3000</code></p> <pre><code>curl -s https://i.jpillora.com/installer! | bash\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/installer/#config","title":"Config","text":"<p>Install location</p> <pre><code>/usr/local/bin/installer\n</code></pre> <p>/etc/systemd/system/installer.service</p> Manual <pre><code>[Unit]\nDescription=Quickly install pre-compiled binaries from Github releases\n\n[Service]\nType=simple\nExecStart=/usr/local/bin/installer\nRestart=on-failure\nExecReload=/bin/kill -USR1 $MAINPID\nStandardOutput=append:/var/log/installer.log\nStandardError=inherit\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/installer/#usage","title":"Usage","text":"<p>install user/repo from github</p> <pre><code>curl https://i.jpillora.com/&lt;user&gt;/&lt;repo&gt;@&lt;release&gt;! | bash\n</code></pre> <p>search web for github repo query</p> <pre><code>curl https://i.jpillora.com/&lt;query&gt;! | bash\n</code></pre> <p>Or you can use <code>wget -qO- url | bash</code></p> <p>Path API</p> <ul> <li><code>user</code> Github user (defaults to @jpillora, customisable if you host your own, searches the web to pick most relevant <code>user</code> when <code>repo</code> not found)</li> <li><code>repo</code> Github repository belonging to <code>user</code> (required)</li> <li><code>release</code> Github release name (defaults to the latest release)</li> <li><code>!</code> When provided, downloads binary directly into <code>/usr/local/bin/</code> (defaults to working directory)</li> </ul> <p>Query Params</p> <ul> <li><code>?type=</code> Force the return type to be one of: <code>script</code> or <code>homebrew</code><ul> <li><code>type</code> is normally detected via <code>User-Agent</code> header</li> <li><code>type=homebrew</code> is not working at the moment</li> </ul> </li> <li><code>?insecure=1</code> Force <code>curl</code>/<code>wget</code> to skip certificate checks</li> <li><code>?as=</code> Force the binary to be named as this parameter value</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/installer/#examples","title":"Examples","text":"<ul> <li>https://i.jpillora.com/serve</li> <li>https://i.jpillora.com/cloud-torrent</li> <li>https://i.jpillora.com/yudai/gotty@v0.0.12</li> <li>https://i.jpillora.com/mholt/caddy</li> <li>https://i.jpillora.com/caddy</li> <li>https://i.jpillora.com/rclone</li> <li> <p>https://i.jpillora.com/ripgrep?as=rg</p> <pre><code>$ curl -s i.jpillora.com/mholt/caddy! | bash\nDownloading mholt/caddy v0.8.2 (https://github.com/mholt/caddy/releases/download/v0.8.2/caddy_darwin_amd64.zip)\n######################################################################## 100.0%\nDownloaded to /usr/local/bin/caddy\n$ caddy --version\nCaddy 0.8.2\n</code></pre> </li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/installer/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/installer.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    installer:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`installer.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: installer  \n#endregion\n#region services\n  services:\n    installer:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.26:3000\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/installer/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* enable:        Enable service\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Resart service\n* start:         Start service\n* status:        Service status\n* stop:          Stop service\n* upgrade:       upgrade\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/installer/#references","title":"References","text":"","tags":["lxc","proxmox"]},{"location":"apps/it-tools/","title":"IT-TOOLS","text":"","tags":["lxc","proxmox","docker"]},{"location":"apps/it-tools/#installation","title":"Installation","text":"<p> Default Port: <code>8080</code></p> Docker <pre><code>docker run -d --name it-tools --restart unless-stopped -p 8080:80 ghcr.io/corentinth/it-tools:latest\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/it-tools/#config","title":"Config","text":"<p>Make symlinks to repo.</p>","tags":["lxc","proxmox","docker"]},{"location":"apps/it-tools/#upgrade","title":"Upgrade","text":"<p>Warning</p> <p>The below commands purge any unused Docker images! Use at your own risk!</p> <p><code>homelab/docker/it-tools</code></p> TaskManual <pre><code>task upgrade\n</code></pre> <pre><code>(\n  git pull origin\n  docker compose up --force-recreate --build -d\n  docker image prune -a -f\n)\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/it-tools/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/it-tools.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    it-tools:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`it-tools.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: it-tools\n#endregion\n#region services\n  services:\n    it-tools:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.52:8080\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/it-tools/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt sensitive configuration files using SOPS.\n* default:       List all available tasks.\n* encrypt:       Encrypt sensitive configuration files using SOPS.\n* export:        Export the task list to `task-list.txt`.\n* init:          Initialize the application's environment and configuration files.\n* pull:          Pull Docker images for the application.\n* restart:       Restart the application's Docker containers.\n* status:        Check the status of the application's Docker containers.\n* stop:          Stop the application's Docker containers.\n* up:            Run Docker Compose in the foreground.\n* up-d:          Run Docker Compose in the background.\n* update:        Update the application or its running containers.\n* upgrade:       Upgrade the application by pulling the latest changes and updating.\n* watch:         Watch the application's Docker container logs.\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/it-tools/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=alpine-it-tools</li> </ul>","tags":["lxc","proxmox","docker"]},{"location":"apps/mailrise/","title":"mailrise","text":"<p>mailrise An SMTP gateway for Apprise notifications.</p>","tags":["lxc","notifications","proxmox","docker"]},{"location":"apps/mailrise/#installation","title":"Installation","text":"<p> Default Port: <code>8025</code></p> <p><code>homelab/docker/mailrise</code></p> TaskDocker Compose <pre><code>task up\n</code></pre> <pre><code>docker compose up\n</code></pre>","tags":["lxc","notifications","proxmox","docker"]},{"location":"apps/mailrise/#config","title":"Config","text":"<p><code>homelab/docker/mailrise/.env</code></p> <pre><code>EMAIL_URL=mailto://user:password@gmail.com\nNFTY_URL=ntfy://ntfy.l.nicholaswilde.io/topic\nGOTIFY_URL=gotify://gotify.l.nicholaswilde.io/token\n</code></pre> <code>homelab/docker/mailrise/compose.yaml</code> <pre><code>---\nservices:\n  mailrise:\n    image: yoryan/mailrise:latest\n    container_name: mailrise\n    env_file:\n      - .env\n    ports:\n      - \"8025:8025\"  # Map container port 8025 to host port 8025\n    volumes:\n      - ./mailrise.yaml:/etc/mailrise.conf  # Mount your config file\n    command: -vvv /etc/mailrise.conf\n    restart: unless-stopped\n</code></pre> <code>homelab/docker/mailrise/mailrise.yaml</code> <pre><code>---\nconfigs:\n  email:\n    urls:\n      - !env_var EMAIL_URL\n    mailrise:\n      title_template: \"${subject}\"\n      body_template: \"${body}\"\n      body_format: text\n  ntfy:\n    urls:\n      - !env_var NTFY_URL\n    mailrise:\n      title_template: \"${subject}\"\n      body_template: \"${body}\"\n      body_format: text\n  gotify:\n    urls:\n      - !env_var GOTIFY_URL\n    mailrise:\n      title_template: \"${subject}\"\n      body_template: \"${body}\"\n      body_format: text\n  all:\n    urls:\n      - !env_var EMAIL_URL\n      - !env_var NTFY_URL\n      - !env_var GOTIFY_URL\n    mailrise:\n      title_template: \"${subject}\"\n      body_template: \"${body}\"\n      body_format: text\n\n# smtp:\n#   auth:\n#     basic:\n#       username: password\n</code></pre>","tags":["lxc","notifications","proxmox","docker"]},{"location":"apps/mailrise/#test","title":"Test","text":"<p>Code</p> curlswaks <pre><code>curl \\\n    --url 'smtp://smtp.l.nicholaswilde.io:8025' \\\n    --mail-from 'test@example.com' \\\n    --mail-rcpt 'email@mailrise.xyz' \\\n    --upload-file - &lt;&lt;EOF\nFrom: Test Sender &lt;test@example.com&gt;\nTo: email@mailrise.xyz\nSubject: This is a test email\n\nThis is the body of the test email from curl.\nEOF\n</code></pre> <pre><code>swaks \\\n    --to email@mailrise.xyz \\\n    --server smtp.l.nicholaswilde.io:8025 \\\n    --body \"this is the body\" \\\n    --header \"Subject: subject\"'\n</code></pre>","tags":["lxc","notifications","proxmox","docker"]},{"location":"apps/mailrise/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/mailrise.yaml</code> <pre><code># ---\n# tcp:\n # #region routers\n  # routers:\n    # mailrise:\n      # entryPoints:\n        # - \"mailsecure\"\n      # rule: \"HostSNI(`smtp.l.nicholaswilde.io`)\"\n      # service: mailrise\n      # tls:\n        # passthrough: true\n# #endregion\n# #region services\n  # services:\n    # mailrise:\n      # loadBalancer:\n        # servers:\n          # - address: \"192.168.2.62:8025\"\n# #endregion\n</code></pre>","tags":["lxc","notifications","proxmox","docker"]},{"location":"apps/mailrise/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:           Decrypt sensitive configuration files using SOPS.\n* default:           List all available tasks.\n* encrypt:           Encrypt sensitive configuration files using SOPS.\n* export:            Export the task list to `task-list.txt`.\n* init:              Initialize the application's environment and configuration files.\n* mklinks:           Create symbolic links for configuration files.\n* restart:           Restart the application's Docker containers.\n* status:            Check the status of the application's service or Docker containers.\n* stop:              Stop the application's Docker containers.\n* test:              Send a test email\n* test-remote:       Send a test email to remote address\n* up:                Run Docker Compose in the foreground.\n* up-d:              Run Docker Compose in the background.\n* update:            Update the application or its running containers.\n* upgrade:           Upgrade the application by pulling the latest changes and updating.\n* watch:             Watch the application's Docker container logs.\n</code></pre>","tags":["lxc","notifications","proxmox","docker"]},{"location":"apps/mailrise/#references","title":"References","text":"<ul> <li>https://github.com/YoRyan/mailrise</li> </ul>","tags":["lxc","notifications","proxmox","docker"]},{"location":"apps/mcp-server/","title":"MCP Server","text":"<p>An MCP server that serves custom AGENTS.md files and bash scripts.</p> <p>This is a Python project designed to serve as an MCP (Multi-Cloud Platform) server. It utilizes FastAPI for the web framework and Uvicorn as the ASGI server. The project also includes an agents-library for managing agent-related rules and prompts.</p>","tags":["lxc","proxmox","docker"]},{"location":"apps/mcp-server/#installation","title":"Installation","text":"<p> Default Port: <code>8080</code></p> <p><code>homelab/docker/mcp-server</code></p> TaskDocker Compose <pre><code>task up\n</code></pre> <pre><code>docker compose up\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/mcp-server/#config","title":"Config","text":"<p><code>homelab/docker/mcp-server/.env</code></p> <pre><code>CONTAINER_NAME=mcp-server\n\n# -- age backup --\n# AGE_PUBLIC_KEYS=age123456\n</code></pre> <code>homelab/docker/mcp-server/compose.yaml</code> <pre><code>---\nservices:\n  mcp-server:\n    container_name: ${CONTAINER_NAME}\n    image: ghcr.io/nicholaswilde/mcp-server:0.10.0\n    env_file:\n      - .env\n    ports:\n      - '8080:8080'\n    volumes:\n      - ./agents-library:/app/agents-library\n      - /etc/timezone:/etc/timezone:ro\n      - /etc/localtime:/etc/localtime:ro\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n    environment:\n      - PUID=${PUID:-1000}\n      - PGID=${PGID:-1000}\n    restart: always\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 5s\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/mcp-server/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/mcp-server.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    mcp-server:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`mcp-server.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: mcp-server\n#endregion\n#region services\n  services:\n    mcp-server:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.177:8080\"\n        passHostHeader: true\n#endregion\n  middlewares:\n    https-redirectscheme:\n      redirectScheme:\n        scheme: https\n        permanent: true\n    default-headers:\n      headers:\n        frameDeny: true\n        browserXssFilter: true\n        contentTypeNosniff: true\n        forceSTSHeader: true\n        stsIncludeSubdomains: true\n        stsPreload: true\n        stsSeconds: 15552000\n        customFrameOptionsValue: SAMEORIGIN\n        customRequestHeaders:\n          X-Forwarded-Proto: https\n\n    default-whitelist:\n      ipAllowList:\n        sourceRange:\n        - \"10.0.0.0/8\"\n        - \"192.168.0.0/16\"\n        - \"172.16.0.0/12\"\n\n    secured:\n      chain:\n        middlewares:\n        - default-whitelist\n        - default-headers\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/mcp-server/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* backup:        Backup the application's volume data.\n* decrypt:       Decrypt sensitive configuration files using SOPS.\n* default:       List all available tasks.\n* encrypt:       Encrypt sensitive configuration files using SOPS.\n* export:        Export the task list to `task-list.txt`.\n* init:          Initialize the application's environment and configuration files.\n* pull:          Pull Docker images for the application.\n* restart:       Restart the application's Docker containers.\n* status:        Check the status of the application's Docker containers.\n* stop:          Stop the application's Docker containers.\n* up:            Run Docker Compose in the foreground.\n* up-d:          Run Docker Compose in the background.\n* update:        Update the application or its running containers.\n* upgrade:       Upgrade the application by pulling the latest changes and updating.\n* watch:         Watch the application's Docker container logs.\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/mcp-server/#references","title":"References","text":"<ul> <li>https://github.com/nicholaswilde/mcp-server</li> </ul>","tags":["lxc","proxmox","docker"]},{"location":"apps/myspeed/","title":"MySpeed","text":"<p>MySpeed is used to test internet download and upload speeds.</p>","tags":["lxc","proxmox"]},{"location":"apps/myspeed/#installation","title":"Installation","text":"<p> Default Port: <code>5216</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/myspeed.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/myspeed.sh)\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/myspeed/#config","title":"Config","text":"<p>Make symlinks to repo.</p>","tags":["lxc","proxmox"]},{"location":"apps/myspeed/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/myspeed.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    myspeed:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`myspeed.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: myspeed\n\n#endregion\n#region services\n  services:\n    myspeed:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.136:5216\"\n        passHostHeader: true\n# #endregion\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/myspeed/#notifications","title":"Notifications","text":"<ol> <li>Gotify</li> </ol>","tags":["lxc","proxmox"]},{"location":"apps/myspeed/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* enable:        Enable service\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Resart service\n* start:         Start service\n* status:        Service status\n* stop:          Stop service\n* upgrade:       upgrade\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/myspeed/#references","title":"References","text":"","tags":["lxc","proxmox"]},{"location":"apps/netbootxyz/","title":"netboot.xyz","text":"<p>netboot.xyz enables me to boot into many types of operating systems using lightweight tooling to get you up and running as soon as possible  over my network.</p>","tags":["lxc","proxmox","docker"]},{"location":"apps/netbootxyz/#installation","title":"Installation","text":"<p> Default Port: <code>3000</code></p> <p><code>homelab/docker/netbootxyz</code></p> TaskDocker Compose <pre><code>task up\n</code></pre> <pre><code>docker compose up\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/netbootxyz/#config","title":"Config","text":"<p><code>homelab/docker/netbootxyz/.env</code></p> <pre><code>CONFIG_DIR=\nINSTALL_DIR=\nSERVICE_NAME=docker\n</code></pre> <code>homelab/docker/netbootxyz/compose.yaml</code> <pre><code>---\nservices:\n  netbootxyz:\n    image: ghcr.io/netbootxyz/netbootxyz:0.7.6-nbxyz4\n    container_name: netbootxyz\n    restart: unless-stopped\n    ports:\n      - \"3000:3000\"  # Web configuration interface port\n      - \"69:69/udp\"   # TFTP port\n      - \"8080:80\"    # Optional, maps to NGINX_PORT\n    environment:\n      - MENU_VERSION=2.0.76  # Optional\n      - NGINX_PORT=80        # Optional\n      - WEB_APP_PORT=3000    # Optional\n    volumes:\n      - ./config:/config  # Optional\n      - ./assets:/assets  # Optional\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/netbootxyz/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/netbootxyz.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    netbootxyz:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`netboot.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: netbootxyz\n#endregion\n#region services\n  services:\n    netbootxyz:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.1.222:3000\"\n        passHostHeader: true\n#endregion\n  middlewares:\n    https-redirectscheme:\n      redirectScheme:\n        scheme: https\n        permanent: true\n    default-headers:\n      headers:\n        frameDeny: true\n        browserXssFilter: true\n        contentTypeNosniff: true\n        forceSTSHeader: true\n        stsIncludeSubdomains: true\n        stsPreload: true\n        stsSeconds: 15552000\n        customFrameOptionsValue: SAMEORIGIN\n        customRequestHeaders:\n          X-Forwarded-Proto: https\n\n    default-whitelist:\n      ipAllowList:\n        sourceRange:\n        - \"10.0.0.0/8\"\n        - \"192.168.0.0/16\"\n        - \"172.16.0.0/12\"\n\n    secured:\n      chain:\n        middlewares:\n        - default-whitelist\n        - default-headers\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/netbootxyz/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt sensitive configuration files using SOPS.\n* default:       List all available tasks.\n* encrypt:       Encrypt sensitive configuration files using SOPS.\n* export:        Export the task list to `task-list.txt`.\n* init:          Initialize the application's environment and configuration files.\n* mklinks:       Create symbolic links for configuration files.\n* restart:       Restart the application's Docker containers.\n* status:        Check the status of the application's service or Docker containers.\n* stop:          Stop the application's Docker containers.\n* up:            Run Docker Compose in the foreground.\n* up-d:          Run Docker Compose in the background.\n* update:        Update the application or its running containers.\n* upgrade:       Upgrade the application by pulling the latest changes and updating.\n* watch:         Watch the application's Docker container logs.\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/netbootxyz/#references","title":"References","text":"","tags":["lxc","proxmox","docker"]},{"location":"apps/ntfy/","title":"ntfy","text":"<p>ntfy is a simple HTTP-based pub-sub notification service. It allows you to send notifications to your phone or desktop via scripts from any computer, and/or using a REST API.</p>","tags":["lxc","notifications","proxmox"]},{"location":"apps/ntfy/#installation","title":"Installation","text":"<p> Default Port: <code>80</code></p> <p> Configuration path: <code>/etc/ntfy/</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/ntfy.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/ntfy.sh)\"\n</code></pre>","tags":["lxc","notifications","proxmox"]},{"location":"apps/ntfy/#config","title":"Config","text":"","tags":["lxc","notifications","proxmox"]},{"location":"apps/ntfy/#server","title":"Server","text":"<p><code>homelab/docker/ntfy/.env</code></p> <pre><code>CONFIG_DIR=/etc/ntfy\nINSTALL_DIR=/opt/ntfy\nSERVICE_NAME=ntfy\n</code></pre> <code>homelab/pve/ntfy/server.yml</code> <pre><code># ntfy server config file\n#\n# Please refer to the documentation at https://ntfy.sh/docs/config/ for details.\n# All options also support underscores (_) instead of dashes (-) to comply with the YAML spec.\n# Public facing base URL of the service (e.g. https://ntfy.sh or https://ntfy.example.com)\n#\n# This setting is required for any of the following features:\n# - attachments (to return a download URL)\n# - e-mail sending (for the topic URL in the email footer)\n# - iOS push notifications for self-hosted servers (to calculate the Firebase poll_request topic)\n# - Matrix Push Gateway (to validate that the pushkey is correct)\n#\n# base-url:\n# Listen address for the HTTP &amp; HTTPS web server. If \"listen-https\" is set, you must also\n# set \"key-file\" and \"cert-file\". Format: [&lt;ip&gt;]:&lt;port&gt;, e.g. \"1.2.3.4:8080\".\n#\n# To listen on all interfaces, you may omit the IP address, e.g. \":443\".\n# To disable HTTP, set \"listen-http\" to \"-\".\n#\n# listen-http: \":80\"\n# listen-https:\n# Listen on a Unix socket, e.g. /var/lib/ntfy/ntfy.sock\n# This can be useful to avoid port issues on local systems, and to simplify permissions.\n#\n# listen-unix: &lt;socket-path&gt;\n# listen-unix-mode: &lt;linux permissions, e.g. 0700&gt;\n# Path to the private key &amp; cert file for the HTTPS web server. Not used if \"listen-https\" is not set.\n#\n# key-file: &lt;filename&gt;\n# cert-file: &lt;filename&gt;\n# If set, also publish messages to a Firebase Cloud Messaging (FCM) topic for your app.\n# This is optional and only required to save battery when using the Android app.\n#\n# firebase-key-file: &lt;filename&gt;\n# If \"cache-file\" is set, messages are cached in a local SQLite database instead of only in-memory.\n# This allows for service restarts without losing messages in support of the since= parameter.\n#\n# The \"cache-duration\" parameter defines the duration for which messages will be buffered\n# before they are deleted. This is required to support the \"since=...\" and \"poll=1\" parameter.\n# To disable the cache entirely (on-disk/in-memory), set \"cache-duration\" to 0.\n# The cache file is created automatically, provided that the correct permissions are set.\n#\n# The \"cache-startup-queries\" parameter allows you to run commands when the database is initialized,\n# e.g. to enable WAL mode (see https://phiresky.github.io/blog/2020/sqlite-performance-tuning/)).\n# Example:\n#    cache-startup-queries: |\n#       pragma journal_mode = WAL;\n#       pragma synchronous = normal;\n#       pragma temp_store = memory;\n#       pragma busy_timeout = 15000;\n#       vacuum;\n#\n# The \"cache-batch-size\" and \"cache-batch-timeout\" parameter allow enabling async batch writing\n# of messages. If set, messages will be queued and written to the database in batches of the given\n# size, or after the given timeout. This is only required for high volume servers.\n#\n# Debian/RPM package users:\n#   Use /var/cache/ntfy/cache.db as cache file to avoid permission issues. The package\n#   creates this folder for you.\n#\n# Check your permissions:\n#   If you are running ntfy with systemd, make sure this cache file is owned by the\n#   ntfy user and group by running: chown ntfy.ntfy &lt;filename&gt;.\n#\n# cache-file: &lt;filename&gt;\n# cache-duration: \"12h\"\n# cache-startup-queries:\n# cache-batch-size: 0\n# cache-batch-timeout: \"0ms\"\n# If set, access to the ntfy server and API can be controlled on a granular level using\n# the 'ntfy user' and 'ntfy access' commands. See the --help pages for details, or check the docs.\n#\n# - auth-file is the SQLite user/access database; it is created automatically if it doesn't already exist\n# - auth-default-access defines the default/fallback access if no access control entry is found; it can be\n#   set to \"read-write\" (default), \"read-only\", \"write-only\" or \"deny-all\".\n# - auth-startup-queries allows you to run commands when the database is initialized, e.g. to enable\n#   WAL mode. This is similar to cache-startup-queries. See above for details.\n#\n# Debian/RPM package users:\n#   Use /var/lib/ntfy/user.db as user database to avoid permission issues. The package\n#   creates this folder for you.\n#\n# Check your permissions:\n#   If you are running ntfy with systemd, make sure this user database file is owned by the\n#   ntfy user and group by running: chown ntfy.ntfy &lt;filename&gt;.\n#\n# auth-file: &lt;filename&gt;\n# auth-default-access: \"read-write\"\n# auth-startup-queries:\n# If set, the X-Forwarded-For header is used to determine the visitor IP address\n# instead of the remote address of the connection.\n#\n# WARNING: If you are behind a proxy, you must set this, otherwise all visitors are rate limited\n#          as if they are one.\n#\n# behind-proxy: false\n# If enabled, clients can attach files to notifications as attachments. Minimum settings to enable attachments\n# are \"attachment-cache-dir\" and \"base-url\".\n#\n# - attachment-cache-dir is the cache directory for attached files\n# - attachment-total-size-limit is the limit of the on-disk attachment cache directory (total size)\n# - attachment-file-size-limit is the per-file attachment size limit (e.g. 300k, 2M, 100M)\n# - attachment-expiry-duration is the duration after which uploaded attachments will be deleted (e.g. 3h, 20h)\n#\n# attachment-cache-dir:\n# attachment-total-size-limit: \"5G\"\n# attachment-file-size-limit: \"15M\"\n# attachment-expiry-duration: \"3h\"\n# If enabled, allow outgoing e-mail notifications via the 'X-Email' header. If this header is set,\n# messages will additionally be sent out as e-mail using an external SMTP server.\n#\n# As of today, only SMTP servers with plain text auth (or no auth at all), and STARTLS are supported.\n# Please also refer to the rate limiting settings below (visitor-email-limit-burst &amp; visitor-email-limit-burst).\n#\n# - smtp-sender-addr is the hostname:port of the SMTP server\n# - smtp-sender-from is the e-mail address of the sender\n# - smtp-sender-user/smtp-sender-pass are the username and password of the SMTP user (leave blank for no auth)\n#\n# smtp-sender-addr:\n# smtp-sender-from:\n# smtp-sender-user:\n# smtp-sender-pass:\n# If enabled, ntfy will launch a lightweight SMTP server for incoming messages. Once configured, users can send\n# emails to a topic e-mail address to publish messages to a topic.\n#\n# - smtp-server-listen defines the IP address and port the SMTP server will listen on, e.g. :25 or 1.2.3.4:25\n# - smtp-server-domain is the e-mail domain, e.g. ntfy.sh\n# - smtp-server-addr-prefix is an optional prefix for the e-mail addresses to prevent spam. If set to \"ntfy-\",\n#   for instance, only e-mails to ntfy-$topic@ntfy.sh will be accepted. If this is not set, all emails to\n#   $topic@ntfy.sh will be accepted (which may obviously be a spam problem).\n#\n# smtp-server-listen:\n# smtp-server-domain:\n# smtp-server-addr-prefix:\n# Web Push support (background notifications for browsers)\n#\n# If enabled, allows the ntfy web app to receive push notifications, even when the web app is closed. When enabled, users\n# can enable background notifications in the web app. Once enabled, ntfy will forward published messages to the push\n# endpoint, which will then forward it to the browser.\n#\n# You must configure web-push-public/private key, web-push-file, and web-push-email-address below to enable Web Push.\n# Run \"ntfy webpush keys\" to generate the keys.\n#\n# - web-push-public-key is the generated VAPID public key, e.g. AA1234BBCCddvveekaabcdfqwertyuiopasdfghjklzxcvbnm1234567890\n# - web-push-private-key is the generated VAPID private key, e.g. AA2BB1234567890abcdefzxcvbnm1234567890\n# - web-push-file is a database file to keep track of browser subscription endpoints, e.g. /var/cache/ntfy/webpush.db\n# - web-push-email-address is the admin email address send to the push provider, e.g. sysadmin@example.com\n# - web-push-startup-queries is an optional list of queries to run on startup`\n# - web-push-expiry-warning-duration defines the duration after which unused subscriptions are sent a warning (default is 55d`)\n# - web-push-expiry-duration defines the duration after which unused subscriptions will expire (default is 60d)\n#\n# web-push-public-key:\n# web-push-private-key:\n# web-push-file:\n# web-push-email-address:\n# web-push-startup-queries:\n# web-push-expiry-warning-duration: \"55d\"\n# web-push-expiry-duration: \"60d\"\n# If enabled, ntfy can perform voice calls via Twilio via the \"X-Call\" header.\n#\n# - twilio-account is the Twilio account SID, e.g. AC12345beefbeef67890beefbeef122586\n# - twilio-auth-token is the Twilio auth token, e.g. affebeef258625862586258625862586\n# - twilio-phone-number is the outgoing phone number you purchased, e.g. +18775132586\n# - twilio-verify-service is the Twilio Verify service SID, e.g. VA12345beefbeef67890beefbeef122586\n#\n# twilio-account:\n# twilio-auth-token:\n# twilio-phone-number:\n# twilio-verify-service:\n# Interval in which keepalive messages are sent to the client. This is to prevent\n# intermediaries closing the connection for inactivity.\n#\n# Note that the Android app has a hardcoded timeout at 77s, so it should be less than that.\n#\n# keepalive-interval: \"45s\"\n# Interval in which the manager prunes old messages, deletes topics\n# and prints the stats.\n#\n# manager-interval: \"1m\"\n# Defines topic names that are not allowed, because they are otherwise used. There are a few default topics\n# that cannot be used (e.g. app, account, settings, ...). To extend the default list, define them here.\n#\n# Example:\n#   disallowed-topics:\n#     - about\n#     - pricing\n#     - contact\n#\n# disallowed-topics:\n# Defines the root path of the web app, or disables the web app entirely.\n#\n# Can be any simple path, e.g. \"/\", \"/app\", or \"/ntfy\". For backwards-compatibility reasons,\n# the values \"app\" (maps to \"/\"), \"home\" (maps to \"/app\"), or \"disable\" (maps to \"\") to disable\n# the web app entirely.\n#\n# web-root: /\n# Various feature flags used to control the web app, and API access, mainly around user and\n# account management.\n#\n# - enable-signup allows users to sign up via the web app, or API\n# - enable-login allows users to log in via the web app, or API\n# - enable-reservations allows users to reserve topics (if their tier allows it)\n#\n# enable-signup: false\n# enable-login: false\n# enable-reservations: false\n# Server URL of a Firebase/APNS-connected ntfy server (likely \"https://ntfy.sh\").\n#\n# iOS users:\n#   If you use the iOS ntfy app, you MUST configure this to receive timely notifications. You'll like want this:\n#   upstream-base-url: \"https://ntfy.sh\"\n#\n# If set, all incoming messages will publish a \"poll_request\" message to the configured upstream server, containing\n# the message ID of the original message, instructing the iOS app to poll this server for the actual message contents.\n# This is to prevent the upstream server and Firebase/APNS from being able to read the message.\n#\n# - upstream-base-url is the base URL of the upstream server. Should be \"https://ntfy.sh\".\n# - upstream-access-token is the token used to authenticate with the upstream server. This is only required\n#   if you exceed the upstream rate limits, or the uptream server requires authentication.\n#\n# upstream-base-url:\n# upstream-access-token:\n# Configures message-specific limits\n#\n# - message-size-limit defines the max size of a message body. Please note message sizes &gt;4K are NOT RECOMMENDED,\n#   and largely untested. If FCM and/or APNS is used, the limit should stay 4K, because their limits are around that size.\n#   If you increase this size limit regardless, FCM and APNS will NOT work for large messages.\n# - message-delay-limit defines the max delay of a message when using the \"Delay\" header.\n#\n# message-size-limit: \"4k\"\n# message-delay-limit: \"3d\"\n# Rate limiting: Total number of topics before the server rejects new topics.\n#\n# global-topic-limit: 15000\n# Rate limiting: Number of subscriptions per visitor (IP address)\n#\n# visitor-subscription-limit: 30\n# Rate limiting: Allowed GET/PUT/POST requests per second, per visitor:\n# - visitor-request-limit-burst is the initial bucket of requests each visitor has\n# - visitor-request-limit-replenish is the rate at which the bucket is refilled\n# - visitor-request-limit-exempt-hosts is a comma-separated list of hostnames, IPs or CIDRs to be\n#   exempt from request rate limiting. Hostnames are resolved at the time the server is started.\n#   Example: \"1.2.3.4,ntfy.example.com,8.7.6.0/24\"\n#\n# visitor-request-limit-burst: 60\n# visitor-request-limit-replenish: \"5s\"\n# visitor-request-limit-exempt-hosts: \"\"\n# Rate limiting: Hard daily limit of messages per visitor and day. The limit is reset\n# every day at midnight UTC. If the limit is not set (or set to zero), the request\n# limit (see above) governs the upper limit.\n#\n# visitor-message-daily-limit: 0\n# Rate limiting: Allowed emails per visitor:\n# - visitor-email-limit-burst is the initial bucket of emails each visitor has\n# - visitor-email-limit-replenish is the rate at which the bucket is refilled\n#\n# visitor-email-limit-burst: 16\n# visitor-email-limit-replenish: \"1h\"\n# Rate limiting: Attachment size and bandwidth limits per visitor:\n# - visitor-attachment-total-size-limit is the total storage limit used for attachments per visitor\n# - visitor-attachment-daily-bandwidth-limit is the total daily attachment download/upload traffic limit per visitor\n#\n# visitor-attachment-total-size-limit: \"100M\"\n# visitor-attachment-daily-bandwidth-limit: \"500M\"\n# Rate limiting: Enable subscriber-based rate limiting (mostly used for UnifiedPush)\n#\n# If subscriber-based rate limiting is enabled, messages published on UnifiedPush topics** (topics starting with \"up\")\n# will be counted towards the \"rate visitor\" of the topic. A \"rate visitor\" is the first subscriber to the topic.\n#\n# Once enabled, a client subscribing to UnifiedPush topics via HTTP stream, or websockets, will be automatically registered as\n# a \"rate visitor\", i.e. the visitor whose rate limits will be used when publishing on this topic. Note that setting the rate visitor\n# requires **read-write permission** on the topic.\n#\n# If this setting is enabled, publishing to UnifiedPush topics will lead to a HTTP 507 response if\n# no \"rate visitor\" has been previously registered. This is to avoid burning the publisher's \"visitor-message-daily-limit\".\n#\n# visitor-subscriber-rate-limiting: false\n# Payments integration via Stripe\n#\n# - stripe-secret-key is the key used for the Stripe API communication. Setting this values\n#   enables payments in the ntfy web app (e.g. Upgrade dialog). See https://dashboard.stripe.com/apikeys.\n# - stripe-webhook-key is the key required to validate the authenticity of incoming webhooks from Stripe.\n#   Webhooks are essential up keep the local database in sync with the payment provider. See https://dashboard.stripe.com/webhooks.\n# - billing-contact is an email address or website displayed in the \"Upgrade tier\" dialog to let people reach\n#   out with billing questions. If unset, nothing will be displayed.\n#\n# stripe-secret-key:\n# stripe-webhook-key:\n# billing-contact:\n# Metrics\n#\n# ntfy can expose Prometheus-style metrics via a /metrics endpoint, or on a dedicated listen IP/port.\n# Metrics may be considered sensitive information, so before you enable them, be sure you know what you are\n# doing, and/or secure access to the endpoint in your reverse proxy.\n#\n# - enable-metrics enables the /metrics endpoint for the default ntfy server (i.e. HTTP, HTTPS and/or Unix socket)\n# - metrics-listen-http exposes the metrics endpoint via a dedicated [IP]:port. If set, this option implicitly\n#   enables metrics as well, e.g. \"10.0.1.1:9090\" or \":9090\"\n#\n# enable-metrics: false\n# metrics-listen-http:\n# Profiling\n#\n# ntfy can expose Go's net/http/pprof endpoints to support profiling of the ntfy server. If enabled, ntfy will listen\n# on a dedicated listen IP/port, which can be accessed via the web browser on http://&lt;ip&gt;:&lt;port&gt;/debug/pprof/.\n# This can be helpful to expose bottlenecks, and visualize call flows. See https://pkg.go.dev/net/http/pprof for details.\n#\n# profile-listen-http:\n# Logging options\n#\n# By default, ntfy logs to the console (stderr), with an \"info\" log level, and in a human-readable text format.\n# ntfy supports five different log levels, can also write to a file, log as JSON, and even supports granular\n# log level overrides for easier debugging. Some options (log-level and log-level-overrides) can be hot reloaded\n# by calling \"kill -HUP $pid\" or \"systemctl reload ntfy\".\n#\n# - log-format defines the output format, can be \"text\" (default) or \"json\"\n# - log-file is a filename to write logs to. If this is not set, ntfy logs to stderr.\n# - log-level defines the default log level, can be one of \"trace\", \"debug\", \"info\" (default), \"warn\" or \"error\".\n#   Be aware that \"debug\" (and particularly \"trace\") can be VERY CHATTY. Only turn them on briefly for debugging purposes.\n# - log-level-overrides lets you override the log level if certain fields match. This is incredibly powerful\n#   for debugging certain parts of the system (e.g. only the account management, or only a certain visitor).\n#   This is an array of strings in the format:\n#      - \"field=value -&gt; level\" to match a value exactly, e.g. \"tag=manager -&gt; trace\"\n#      - \"field -&gt; level\" to match any value, e.g. \"time_taken_ms -&gt; debug\"\n#   Warning: Using log-level-overrides has a performance penalty. Only use it for temporary debugging.\n#\n# Check your permissions:\n#   If you are running ntfy with systemd, make sure this log file is owned by the\n#   ntfy user and group by running: chown ntfy.ntfy &lt;filename&gt;.\n#\n# Example (good for production):\n#   log-level: info\n#   log-format: json\n#   log-file: /var/log/ntfy.log\n#\n# Example level overrides (for debugging, only use temporarily):\n#   log-level-overrides:\n#      - \"tag=manager -&gt; trace\"\n#      - \"visitor_ip=1.2.3.4 -&gt; debug\"\n#      - \"time_taken_ms -&gt; debug\"\n#\n# log-level: info\n# log-level-overrides:\n# log-format: text\n# log-file:\n{}\n</code></pre>","tags":["lxc","notifications","proxmox"]},{"location":"apps/ntfy/#client","title":"Client","text":"<code>homelab/pve/ntfy/client.yml</code> <pre><code># ntfy client config file\n# Base URL used to expand short topic names in the \"ntfy publish\" and \"ntfy subscribe\" commands.\n# If you self-host a ntfy server, you'll likely want to change this.\n#\n# default-host: https://ntfy.sh\n# Default credentials will be used with \"ntfy publish\" and \"ntfy subscribe\" if no other credentials are provided.\n# You can set a default token to use or a default user:password combination, but not both. For an empty password,\n# use empty double-quotes (\"\").\n#\n# To override the default user:password combination or default token for a particular subscription (e.g., to send\n# no Authorization header), set the user:pass/token for the subscription to empty double-quotes (\"\").\n# default-token:\n# default-user:\n# default-password:\n# Default command will execute after \"ntfy subscribe\" receives a message if no command is provided in subscription below\n# default-command:\n# Subscriptions to topics and their actions. This option is primarily used by the systemd service,\n# or if you cann \"ntfy subscribe --from-config\" directly.\n#\n# Example:\n#     subscribe:\n#       - topic: mytopic\n#         command: /usr/local/bin/mytopic-triggered.sh\n#       - topic: myserver.com/anothertopic\n#         command: 'echo \"$message\"'\n#         if:\n#             priority: high,urgent\n#       - topic: secret\n#         command: 'notify-send \"$m\"'\n#         user: phill\n#         password: mypass\n#       - topic: token_topic\n#         token: tk_AgQdq7mVBoFD37zQVN29RhuMzNIz2\n#\n# Variables:\n#     Variable        Aliases               Description\n#     --------------- --------------------- -----------------------------------\n#     $NTFY_ID        $id                   Unique message ID\n#     $NTFY_TIME      $time                 Unix timestamp of the message delivery\n#     $NTFY_TOPIC     $topic                Topic name\n#     $NTFY_MESSAGE   $message, $m          Message body\n#     $NTFY_TITLE     $title, $t            Message title\n#     $NTFY_PRIORITY  $priority, $prio, $p  Message priority (1=min, 5=max)\n#     $NTFY_TAGS      $tags, $tag, $ta      Message tags (comma separated list)\n#     $NTFY_RAW       $raw                  Raw JSON message\n#\n# Filters ('if:'):\n#     You can filter 'message', 'title', 'priority' (comma-separated list, logical OR)\n#     and 'tags' (comma-separated list, logical AND). See https://ntfy.sh/docs/subscribe/api/#filter-messages.\n#\n# subscribe:\n{}\n</code></pre>","tags":["lxc","notifications","proxmox"]},{"location":"apps/ntfy/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/ntfy.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    ntfy:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`ntfy.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: ntfy\n#endregion\n#region services\n  services:\n    ntfy:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.160\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","notifications","proxmox"]},{"location":"apps/ntfy/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt config files using SOPS\n* enable:        Enable service\n* encrypt:       Encrypt config files using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Resart service\n* start:         Start service\n* status:        Service status\n* stop:          Stop service\n* update:        Update app\n* upgrade:       Upgrade\n</code></pre>","tags":["lxc","notifications","proxmox"]},{"location":"apps/ntfy/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=ntfy</li> <li>https://pimox-scripts.com/scripts?id=ntfy</li> </ul>","tags":["lxc","notifications","proxmox"]},{"location":"apps/openmediavault/","title":"OpenMediaVault","text":"<p>OpenMediaVault is my NAS that serves both NFS and SAMBA shares to my network. It runs on VM on the system that is directly connected to my external hard drive.</p>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#installation","title":"Installation","text":"","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#download-iso-into-proxmox","title":"Download ISO into Proxmox","text":"<p>pve</p> <pre><code>(\n  cd /var/lib/vz/template/iso &amp;&amp; \\\n  wget $(curl -s https://sourceforge.net/projects/openmediavault/rss?path=/iso | \\\n  grep -oP '&lt;link&gt;https://sourceforge.net/projects/openmediavault/files/iso/[^&lt;]+&lt;/link&gt;' | \\\n  head -n 1 | \\\n  sed 's/&lt;link&gt;//; s/&lt;\\/link&gt;//'| \\\n  sed 's/\\/download$//')\n)\n</code></pre>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#create-new-vm","title":"Create new VM","text":"<p>General</p> <p>Name: <code>omv</code></p> <p>Start at boot: </p> <p>OS</p> <p>ISO image: <code>*.iso</code></p> <p>Disks</p> <p>Bus/Device: <code>SATA</code></p> <p>Disk size (GiB): <code>16</code></p> <p>CPU</p> <p>Cores: <code>2</code></p> <p>Memory</p> <p>Memory (MiB): <code>4096</code></p> <p>Look for disk</p> <pre><code>lsblk\n</code></pre>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#install-omv-into-vm","title":"Install omv into VM.","text":"","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#default-access","title":"Default Access","text":"<p> Port: <code>80</code></p> <p> Username: <code>admin</code></p> <p> Password: <code>openmediavault</code></p>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#change-password","title":"Change Password","text":"<p>Top right person icon -&gt; Change Password</p>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#new-user","title":"New User","text":"<p>Users -&gt; Users</p> <p> Groups: <code>openmediavault-admin,users</code></p>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#reinstall","title":"Reinstall","text":"<p>Recover drive</p> <p>Mounted after reinstall and not before.</p> <p>Remount</p> <pre><code>omv-firstaid\n</code></pre>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#static-ip","title":"Static IP","text":"","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#gui","title":"GUI","text":"<p>Network -&gt; Interfaces -&gt; ens18</p> <p>Method: <code>Static</code></p> <p>Address: <code>192.168.2.19</code></p> <p>Netmask: <code>255.255.0.0</code></p> <p>Gateway: <code>192.168.0.0</code></p>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#nfs","title":"NFS","text":"<p>Server</p> <p>Client: <code>192.168.2.0/24</code></p> <p>Permission: <code>Read/Write</code></p> <p>Extra options: <code>subtree_check,insecure,no_root_squash</code></p>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#client","title":"Client","text":"<p>Installation</p> <pre><code>apt install autofs\n</code></pre> <p>/etc/auto.master</p> AutomatedManual <pre><code>echo \"/mnt /etc/auto.nfs --ghost --timeout=60\" | tee -a /etc/auto.master\n</code></pre> <pre><code>+auto.master\n/mnt /etc/auto.nfs --ghost --timeout=60\n</code></pre> <p>/etc/auto.nfs</p> AutomatedManual <pre><code>echo \"storage -fstype=nfs4,rw,insecure 192.168.2.19:/storage\" | tee /etc/auto.nfs\n</code></pre> <pre><code>storage -fstype=nfs4,rw,insecure 192.168.2.19:/storage\n</code></pre> <p>Test</p> <pre><code>showmount -e 192.168.2.19\n</code></pre> <p>Mount</p> <pre><code>(\n  systemctl restart autofs.service &amp;&amp; \\\n  systemctl status autofs.service\n)\n</code></pre>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#nfs-failure-notification-script","title":"NFS Failure Notification Script","text":"<p>A simple utility to send a notification to mailrise on an NFS service failure.</p>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#installation_1","title":"Installation","text":"taskAutomaticManual <pre><code>task create-nfs-override\n</code></pre> <pre><code>sudo bash -c '\nmkdir -p /etc/systemd/system/nfs-server.service.d/\ncat &lt;&lt;EOF &gt; /etc/systemd/system/nfs-server.service.d/override.conf\n[Service]\nOnFailure=/root/git/nicholaswilde/homelab/vm/openmediavault/notify-nfs-failure.sh\nEOF\n</code></pre> <pre><code>mkdir -p /etc/systemd/system/nfs-server.service.d/\n</code></pre> /etc/systemd/system/nfs-server.service.d/override.conf<pre><code>[Service]\nOnFailure=/root/git/nicholaswilde/homelab/vm/openmediavault/notify-nfs-failure.sh\n</code></pre> homelab/vm/openmediavault/notify-nfs-failure.sh <pre><code>#!/usr/bin/env bash\n\n################################################################################\n#\n# notify-nfs-failure\n# ----------------\n# A simple utility to send a notification to mailrise on an NFS service failure.\n#\n# @author Nicholas Wilde, 0xb299a622\n# @date 06 Jul 22025\n# @version 0.1.0\n#\n################################################################################\n\nset -e\nset -o pipefail\n\n# Variables\nSMTP_SERVER=\"smtp://smtp.l.nicholaswilde.io:8025\"\nTO_ADDRESS=\"all@mailrise.xyz\"\n\nreadonly SMTP_SERVER\nreadonly NFS_SERVICE\nreadonly TO_ADDRESS\n\nfunction set_vars(){\n  HOSTNAME=$(hostname)\n  UNIT_NAME=\"%n\" # systemd variable for the unit name that failed\n}\n\nfunction send_notification(){\n  # NFS service is down, send notification\n  MESSAGE=\"NFS service on $HOSTNAME is DOWN! Check OpenMediaVault immediately.\"\n  TITLE=\"\ud83d\udea8 OMV NFS DOWN! \ud83d\udea8\"\n  TAGS=\"warning,nfs,omv,down\"\n  PRIORITY=\"urgent\" # Priority 5 for urgent (highest)\n\n  curl -fsSL \\\n      --url 'smtp://smtp.l.nicholaswilde.io:8025' \\\n      --mail-from 'nfs@omv.com' \\\n      --mail-rcpt ${TO_ADDRESS} \\\n      --upload-file - &lt;&lt;EOF\nFrom: OMV NFS &lt;nfs@omv.com&gt;\nTo: ${TO_ADDRESS}\nSubject: ${TITLE}\n\n${MESSAGE} (Unit: ${UNIT_NAME})\nEOF\n  # Log to syslog for historical record on the OMV server\n  logger -t \"notify-nfs-failure\" \"NFS service on $HOSTNAME is DOWN. Sent notification.\"\n}\n\nfunction main(){\n  set_vars\n  send_notification\n}\n\nmain \"@\"\n</code></pre> <p>WIP</p>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#upgrade","title":"Upgrade","text":"<p>Code</p> TaskManual <pre><code>task upgrade\n</code></pre> <pre><code>omv-upgrade\n</code></pre>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* create-nfs-override:       Creates or updates the systemd override file for nfs-server.service\n* decrypt:                   Decrypt .env using SOPS\n* enable:                    Enable service\n* encrypt:                   Encrypt .env using SOPS\n* export:                    Export the task list\n* id-nfs-service:            Identify NFS service\n* init:                      Init\n* mklinks:                   Make client symlinks\n* restart:                   Resart service\n* start:                     Start service\n* status:                    Service status\n* stop:                      Stop service\n* update:                    Update vm\n* upgrade:                   Upgrade app\n</code></pre>","tags":["vm","proxmox"]},{"location":"apps/openmediavault/#references","title":"References","text":"<ul> <li>https://www.youtube.com/watch?v=Bce7VT3kJ4g</li> </ul>","tags":["vm","proxmox"]},{"location":"apps/pinchflat/","title":"Pinchflat","text":"<p>Pinchflat is a self-hosted app for downloading YouTube content built using <code>yt-dlp</code>.</p> <p>This app is being used to automatically download videos from YouTube and store them on my NFS share so that I can stream the videos to my Apple TV via Infuse without having to watch commercials and take up bandwidth every time a video is rewatched.</p>","tags":["lxc","vm","proxmox","docker"]},{"location":"apps/pinchflat/#installation","title":"Installation","text":"<p> Default Port: 8945</p> <p><code>homelab/docker/pinchflat</code></p> TaskDocker Compose <pre><code>task up\n</code></pre> <pre><code>docker compose up\n</code></pre>","tags":["lxc","vm","proxmox","docker"]},{"location":"apps/pinchflat/#config","title":"Config","text":"<p>I am currently investigating how to format the metadata for Infuse to properly pickup the video automatically. I also need to figure out how to setup Infuse.</p> <p><code>homelab/docker/pinchflat/.env</code></p> <pre><code>CONTAINER_NAME=pinchflat\n</code></pre> <code>homelab/docker/pinchflat/compose.yaml</code> <pre><code>---\n\nservices:\n  pinchflat:\n    container_name: pinchflat\n    image: ghcr.io/kieraneglin/pinchflat:v2025.6.6\n    env_file:\n      - .env\n    environment:\n      - TZ=America/Los_Angeles\n    ports:\n      - '8945:8945'\n    restart: always\n    volumes:\n      - /root/git/nicholaswilde/homelab/docker/pinchflat/config:/config\n      - /mnt/storage/youtube:/downloads\n</code></pre>","tags":["lxc","vm","proxmox","docker"]},{"location":"apps/pinchflat/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/pinchflat.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    pinchflat:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`pinchflat.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: pinchflat\n#endregion\n#region services\n  services:\n    pinchflat:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.138:8945\"\n        passHostHeader: true\n</code></pre>","tags":["lxc","vm","proxmox","docker"]},{"location":"apps/pinchflat/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt sensitive configuration files using SOPS.\n* default:       List all available tasks.\n* encrypt:       Encrypt sensitive configuration files using SOPS.\n* export:        Export the task list to `task-list.txt`.\n* init:          Initialize the application's environment and configuration files.\n* pull:          Pull Docker images for the application.\n* restart:       Restart the application's Docker containers.\n* status:        Check the status of the application's Docker containers.\n* stop:          Stop the application's Docker containers.\n* up:            Run Docker Compose in the foreground.\n* up-d:          Run Docker Compose in the background.\n* update:        Update the application or its running containers.\n* upgrade:       Upgrade the application by pulling the latest changes and updating.\n* watch:         Watch the application's Docker container logs.\n</code></pre>","tags":["lxc","vm","proxmox","docker"]},{"location":"apps/pinchflat/#references","title":"References","text":"","tags":["lxc","vm","proxmox","docker"]},{"location":"apps/proxmox/","title":"Proxmox","text":"<p>Proxmox is the hypervisor that I am using on most of my hardware.</p> <p>I am using it over Portainer and kubernetes for ease of use and feature set.</p>","tags":["proxmox"]},{"location":"apps/proxmox/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/proxmox.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    proxmox01:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`pve01.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: proxmox01\n    proxmox02:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`pve02.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: proxmox02\n    proxmox03:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`pve03.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: proxmox03\n    proxmox04:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`pve04.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: proxmox04\n\n#endregion\n#region services\n  services:\n    proxmox01:\n      loadBalancer:\n        servers:\n          - url: \"https://192.168.2.128:8006\"\n        passHostHeader: true\n    proxmox02:\n      loadBalancer:\n        servers:\n          - url: \"https://192.168.2.88:8006\"\n        passHostHeader: true\n    proxmox03:\n      loadBalancer:\n        servers:\n          - url: \"https://192.168.2.143:8006\"\n        passHostHeader: true\n    proxmox04:\n      loadBalancer:\n        servers:\n          - url: \"https://192.168.2.67:8006\"\n        passHostHeader: true\n\n\n#endregion\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#post-installation","title":"Post Installation","text":"<p> Default Port: <code>8006</code></p> <p>Post Install</p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/misc/post-pve-install.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/misc/post-pve-install.sh)\"\n</code></pre> <p>Add LXC IP Tag</p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/misc/add-lxc-iptag.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/misc/add-lxc-iptag.sh)\"\n</code></pre> <p>Update</p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/misc/update-lxcs.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/misc/add-lxc-iptag.sh)\"\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#datacenter-nfs-volumes","title":"Datacenter NFS Volumes","text":"<p>GUI: <code>Datacenter -&gt; Storage -&gt; Add -&gt; NFS</code></p> <p>pve-backups</p> <p>ID: <code>pve-backups</code></p> <p>Server: <code>omv.l.nicholaswilde.io</code></p> <p>Export: <code>/export/pve-backups</code></p> <p>pve-shared</p> <p>ID: <code>pve-shared</code></p> <p>Server: <code>omv.l.nicholaswilde.io</code></p> <p>Export: <code>/export/pve-shared</code></p>","tags":["proxmox"]},{"location":"apps/proxmox/#reset-cluster-info","title":"Reset Cluster Info","text":"<p>How to reset cluster. Useful if the node IP isn't matching during join.</p> <p>node</p> <pre><code>(\n  systemctl stop pve-cluster corosync &amp;&amp; \\\n  pmxcfs -l\n)\n</code></pre> <p>node</p> <pre><code>(\n  rm -rf /etc/corosync/*\n  rm -rf /etc/pve/corosync.conf \n  killall pmxcfs\n  systemctl start pve-cluster\n)\n</code></pre> <p>The node is now separated from the cluster. You can deleted it from any remaining node of the cluster</p> <pre><code>pvecm delnode oldnode\n</code></pre> <p>If the command fails due to a loss of quorum in the remaining node, set the <code>expected</code> votes to <code>1</code> as a workaround</p> <pre><code>pvecm expected 1\n</code></pre> <p>And then repeat the <code>pvecm delnode</code> command.</p> <p>Now switch back to the separated node and delete all the remaining cluster files on it. This ensures that the node can be added to another cluster again without problems.</p> <p>Separated node</p> <pre><code>rm -rf /var/lib/corosync/*\n</code></pre> <p>As the configuration files from the other nodes are still in the cluster file system, you may want to clean those up too. After making absolutely sure that you have the correct node name, you can simply remove the entire directory recursively from <code>/etc/pve/nodes/NODENAME</code>.</p> <p>Code</p> <pre><code>rm -rf /etc/pve/nodes/NODENAME\n</code></pre> <p>Warning</p> <p>The node\u2019s SSH keys will remain in the authorized_key file. This means that the nodes can still connect to each other with public key authentication. You should fix this by removing the respective keys from the <code>/etc/pve/priv/authorized_keys</code> file.</p>","tags":["proxmox"]},{"location":"apps/proxmox/#static-ip","title":"Static IP","text":"","tags":["proxmox"]},{"location":"apps/proxmox/#node","title":"Node","text":"<p>WIP</p>","tags":["proxmox"]},{"location":"apps/proxmox/#container","title":"Container","text":"<p>WIP</p>","tags":["proxmox"]},{"location":"apps/proxmox/#vm","title":"VM","text":"<p>WIP</p>","tags":["proxmox"]},{"location":"apps/proxmox/#authentik","title":"authentik","text":"<p>Proxmox GUI</p> <p><code>Datacenter -&gt; Permissions -&gt; Realms</code></p> <p>Issuer URL: <code>http://authentik.l.nicholaswilde.io/application/o/proxmox</code></p> <p>Realm: <code>authentik</code></p> <p>Client ID: <code>from authentik</code></p> <p>Client Key: <code>from authentik</code></p> <p>Autocreate Users: </p> <p>Username Claim: <code>username</code></p>","tags":["proxmox"]},{"location":"apps/proxmox/#create-a-volume-group","title":"Create a Volume Group","text":"<p>Create a partition</p> <pre><code>sgdisk -N 1 /dev/sdb\n</code></pre> <p>Create a [P]hysical [V]olume (PV) without confirmation and 250K metadatasize.</p> <pre><code>pvcreate --metadatasize 250k -y -ff /dev/sdb1\n</code></pre> <p>Create a volume group named <code>vmdata</code> on /dev/sdb1</p> <pre><code>vgcreate vmdata /dev/sdb1\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#create-a-lvm-thin-pool","title":"Create a LVM-thin pool","text":"<pre><code>lvcreate -L 80G -T -n vmstore vmdata\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#resize-lxc-disks","title":"Resize LXC Disks","text":"<p>Tip</p> <p>This can be done from the GUI, but sometimes the LXC doesn't register the change.</p> <p>From node</p> <p>Stop the LXC</p> <pre><code>pct stop 108\n</code></pre> <p>Increase the absolute size to 20G</p> <pre><code>pct resize 108 rootfs 20G\n</code></pre> <p>Check the file system</p> <pre><code>e2fsck -f /dev/pve/vm-108-disk-0\n</code></pre> <p>Resize the file system (optional)</p> <pre><code>resize2fs /dev/pve/vm-108-disk-0\n</code></pre> <p>Start the LXC</p> <pre><code>pct start 108\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#resize-vm-disks","title":"Resize VM Disks","text":"","tags":["proxmox"]},{"location":"apps/proxmox/#step-1-increaseresize-disk-from-gui-console","title":"Step 1: Increase/resize disk from GUI console","text":"","tags":["proxmox"]},{"location":"apps/proxmox/#step-2-extend-physical-drive-partition","title":"Step 2: Extend physical drive partition","text":"<p>check free space</p> <pre><code>fdisk -l\n</code></pre> <p>Extend physical drive partition</p> <pre><code>growpart /dev/sda 3\n</code></pre> <p>See physical drive</p> rootsudo <pre><code>pvdisplay\n</code></pre> <pre><code>sudo pvdisplay\n</code></pre> Output<pre><code>  --- Physical volume ---\n  PV Name               /dev/sda3\n  VG Name               ubuntu-vg\n  PV Size               &lt;30.25 GiB / not usable 16.50 KiB\n  Allocatable           yes\n  PE Size               4.00 MiB\n  Total PE              7743\n  Free PE               2048\n  Allocated PE          5695\n  PV UUID               nE8Q94-dVYI-8ZP3-VEar-vONW-Vday-L0JofP\n</code></pre> <p>Instruct LVM that disk size has changed</p> <pre><code>pvresize /dev/sda3\n</code></pre> <p>Check physical drive if has changed</p> <pre><code>pvdisplay\n</code></pre> Output<pre><code>\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#step-3-extend-logical-volume","title":"Step 3: Extend Logical volume","text":"<p>View starting LV</p> <pre><code>lvdisplay\n</code></pre> <p>Resize LV</p> <pre><code>lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv\n</code></pre> <p>View changed LV</p> <pre><code>lvdisplay\n</code></pre> Output<pre><code>\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#step-4-resize-filesystem","title":"Step 4: Resize Filesystem","text":"<p>Resize Filesystem</p> <pre><code>resize2fs /dev/ubuntu-vg/ubuntu-lv\n</code></pre> <p>Confirm results</p> <pre><code>fdisk -l\n</code></pre> Output<pre><code>\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#private-key-rootsshid_rsa-contents-do-not-match","title":"private key /root/.ssh/id_rsa contents do not match","text":"<p>Run on all nodes</p> <pre><code>(\n  cd /root/.ssh &amp;&amp; \\\n  mv id_rsa id_rsa.bak &amp;&amp; \\\n  mv id_rsa.pub id_rsa.pub.bak &amp;&amp; \\\n  mv config config.bak\n)\n</code></pre> <p>Run on all nodes</p> <pre><code>pvecm updatecerts\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#pass-disk-to-vm","title":"Pass Disk to VM","text":"<p>List the disks by ID</p> <pre><code>ls -n /dev/disk/by-id/\n</code></pre> <p>Attach the disk to the VM</p> <pre><code>/sbin/qm set [VM-ID] -virtio2 /dev/disk/by-id/[DISK-ID]\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#kill-backup-job","title":"Kill Backup Job","text":"<pre><code>vzdump -stop\n</code></pre> <pre><code>ps awxf | grep vzdump\n</code></pre> Output<pre><code>2444287 ?        Ds     0:00 task UPID:server_name:00254BFF:06D36C31:63BB7524:vzdump::root@pam:\n</code></pre> <pre><code>kill -9 &lt;process id&gt;\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#email-notifications-using-gmail","title":"Email Notifications using Gmail","text":"<p>Install dependencies</p> <pre><code>(\n  apt update\n  apt install -y libsasl2-modules mailutils\n)\n</code></pre> <p>Enable 2FA for the gmail account that will be used by going to security settings.</p> <p>Create app password for the account.</p> <ol> <li>Go to App Passwords</li> <li>Select app: <code>Mail</code></li> <li>Select device: <code>Other</code></li> <li>Type in: <code>Proxmox</code> or whatever you want here</li> </ol> <p>Write gmail credentials to file and hash it</p> <pre><code>echo \"smtp.gmail.com youremail@gmail.com:yourpassword\" &gt; /etc/postfix/sasl_passwd\n</code></pre> <p>Set file permissions to u=rw</p> <pre><code>chmod 600 /etc/postfix/sasl_passwd\n</code></pre> <p>Generate <code>/etc/postfix/sasl_passwd.db</code></p> <pre><code>postmap hash:/etc/postfix/sasl_passwd\n</code></pre> <p>Warning</p> <p>Comment out the existing line containing just <code>relayhost=</code> since we are using this key in our configuration we just pasted in.</p> <p>Append the following to the end of the file: <code>/etc/postfix/main.cf</code> and comment out <code>relayhost=</code></p> <pre><code>mydestination = $myhostname, localhost.$mydomain, localhost\n# relayhost = \nmynetworks = 127.0.0.0/8\ninet_interfaces = loopback-only\nrecipient_delimiter = +\n\ncompatibility = 2\n\nrelayhost = smtp.gmail.com:587\nsmtp_use_tls = yes\nsmtp_sasl_auth_enable = yes\nsmtp_sasl_security_options =\nsmtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd\nsmtp_tls_CAfile = /etc/ssl/certs/Entrust_Root_Certification_Authority.pem\nsmtp_tls_session_cache_database = btree:/var/lib/postfix/smtp_tls_session_cache\nsmtp_tls_session_cache_timeout = 3600s\n</code></pre> Example Screenshot <p></p> <p>Reload postfix</p> <pre><code>postfix reload\n</code></pre> <p>Test to make sure everything is hunky-dory</p> <pre><code>echo \"sample message\" | mail -s \"sample subject\" anotheremail@gmail.com\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#smtp-setup","title":"SMTP Setup","text":"<p>Proxmox GUI</p> <p>Server: <code>smtp.gmail.com</code></p> <p>Encryption: <code>STARTTLS</code></p> <p>Port: <code>587</code></p> <p>Authenticate: </p> <p>Username: <code>username@gmail.com</code></p> <p>Password: <code>password</code></p> <p>From Address: <code>username@gmail.com</code></p> <p>Recipient(s): <code>root@pam</code></p> <p>Addtional Recipient(s): <code>email@gmail.com</code></p> <p></p> <code>/etc/pve/notifications.cfg</code> <pre><code>smtp: example\n        mailto-user root@pam\n        mailto-user admin@pve\n        mailto max@example.com\n        from-address pve1@example.com\n        username pve1\n        server mail.example.com\n        mode starttls\n</code></pre> The matching entry in <code>/etc/pve/priv/notifications.cfg</code>, containing the secret token <pre><code>smtp: example\n        password somepassword\n</code></pre>","tags":["proxmox"]},{"location":"apps/proxmox/#targets-to-notify","title":"Targets to notify","text":"<p>WIP</p>","tags":["proxmox"]},{"location":"apps/proxmox/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=homepage</li> <li>https://pimox-scripts.com/scripts?id=Homepage</li> <li>https://pve.proxmox.com/wiki/</li> </ul>","tags":["proxmox"]},{"location":"apps/qbittorrent/","title":"qBittorrent","text":"<p>qBittorent is used to download torrents.</p>","tags":["lxc","proxmox"]},{"location":"apps/qbittorrent/#installation","title":"Installation","text":"<p> Default Port: <code>8090</code></p> <p> Username: <code>admin</code></p> <p> Password: <code>changeme</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/qbittorrent.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/qbittorrent.sh)\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/qbittorrent/#config","title":"Config","text":"<p>Make symlinks to repo.</p>","tags":["lxc","proxmox"]},{"location":"apps/qbittorrent/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/qbittorrent.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    qbittorrent:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`qbittorrent.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: qbittorrent\n\n#endregion\n#region services\n  services:\n    qbittorrent:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.57:8090\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/qbittorrent/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* enable:        Enable service\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Resart service\n* start:         Start service\n* status:        Service status\n* stop:          Stop service\n* update:        Update running containers\n* upgrade:       upgrade\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/qbittorrent/#references","title":"References","text":"","tags":["lxc","proxmox"]},{"location":"apps/reactive-resume/","title":"Reactive Resume","text":"<p>Reactive Resume is a one-of-a-kind resume builder that keeps your privacy in mind.</p>","tags":["lxc","proxmox","docker"]},{"location":"apps/reactive-resume/#installation","title":"Installation","text":"<p> Default Port: <code>3000</code></p> <p><code>homelab/docker/reactive-resume</code></p> TaskDocker Compose <pre><code>task up\n</code></pre> <pre><code>docker compose up\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/reactive-resume/#config","title":"Config","text":"<p><code>homelab/docker/reactive-resume/.env</code></p> <pre><code>CONTAINER_NAME=reactive-resume\n\n# -- Postgress --\nPOSTGRES_USER=postgres\nPOSTGRES_PASSWORD=postgres\n\n# -- Minio --\nMINIO_ROOT_USER=minioadmin\nMINIO_ROOT_PASSWORD=minioadmin\n\n# -- Auth --\nACCESS_TOKEN_SECRET=access_token_secret\nREFRESH_TOKEN_SECRET=refresh_token_secret\n\n# -- Storage (Minio) --\nSTORAGE_ACCESS_KEY=minioadmin\nSTORAGE_SECRET_KEY=minioadmin\n\n# -- Chrome --\nCHROME_TOKEN=chrome_token\n\n# -- age backup --\n# AGE_PUBLIC_KEYS=age123456\n</code></pre> <code>homelab/docker/reactive-resume/compose.yaml</code> <pre><code>---\nservices:\n  # Database (Postgres)\n  postgres:\n    image: postgres:16-alpine\n    restart: unless-stopped\n    env_file:\n      - .env\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    environment:\n      POSTGRES_DB: postgres\n      POSTGRES_USER: \"${POSTGRES_USER}\"\n      POSTGRES_PASSWORD: \"${POSTGRES_PASSWORD}\"\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${POSTGRES_PASSWORD} -d postgres\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  # Storage (for image uploads)\n  minio:\n    image: minio/minio:RELEASE.2025-05-24T17-08-30Z\n    restart: unless-stopped\n    command: server /data\n    ports:\n      - \"9000:9000\"\n    volumes:\n      - minio_data:/data\n    environment:\n      MINIO_ROOT_USER: \"${MINIO_ROOT_USER}\"\n      MINIO_ROOT_PASSWORD: \"${MINIO_ROOT_PASSWORD}\"\n\n  # Chrome Browser (for printing and previews)\n  chrome:\n    image: ghcr.io/browserless/chromium:v2.18.0 # Upgrading to newer versions causes issues\n    restart: unless-stopped\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    environment:\n      TIMEOUT: 10000\n      CONCURRENT: 10\n      TOKEN: \"${CHROME_TOKEN}\"\n      EXIT_ON_HEALTH_FAILURE: true\n      PRE_REQUEST_HEALTH_CHECK: true\n\n  # https://offen.github.io/docker-volume-backup/\n  backup_postgres: &amp;backup_service\n    image: offen/docker-volume-backup:v2.44.0\n    environment: &amp;backup_environment\n      BACKUP_FILENAME: backup-%Y-%m-%dT%H-%M-%S.tar.gz\n      BACKUP_LATEST_SYMLINK: backup-postgres-latest.tar.gz\n      BACKUP_PRUNING_PREFIX: backup-postgres-\n      BACKUP_RETENTION_DAYS: '14'\n      AGE_PUBLIC_KEYS: \"${AGE_PUBLIC_KEYS}\"\n      BACKUP_STOP_DURING_BACKUP_LABEL: service-postgres\n    volumes:\n      - postgres_data:/backup/my-app-backup:ro\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      # - ${HOME}/backups:/archive\n      - /mnt/storage/backup/reactive-resume:/archive\n      - /etc/timezone:/etc/timezone:ro\n      - /etc/localtime:/etc/localtime:ro\n\n  backup_minio:\n    &lt;&lt;: *backup_service\n    environment:\n      &lt;&lt;: *backup_environment\n      BACKUP_FILENAME: backup2-%Y-%m-%dT%H-%M-%S.tar.gz\n      BACKUP_LATEST_SYMLINK: backup-minio-latest.tar.gz\n      BACKUP_PRUNING_PREFIX: backup-minio-\n      BACKUP_STOP_DURING_BACKUP_LABEL: service-minio\n    volumes:\n      - minio_data:/backup/my-app-backup:ro\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      # - ${HOME}/backups:/archive\n      - /mnt/storage/backup/reactive-resume:/archive\n      - /etc/timezone:/etc/timezone:ro\n      - /etc/localtime:/etc/localtime:ro\n\n  reactive-resume:\n    container_name: \"${CONTAINER_NAME}\"\n    image: ghcr.io/amruthpillai/reactive-resume:v4.4.6\n    restart: unless-stopped\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      - postgres\n      - minio\n      - chrome\n    env_file:\n      - .env\n    environment:\n      # -- Environment Variables --\n      PORT: 3000\n      NODE_ENV: production\n\n      # -- URLs --\n      PUBLIC_URL: http://192.168.2.147:3000\n      STORAGE_URL: http://192.168.2.147:9000/default\n\n      # -- Printer (Chrome) --\n      CHROME_TOKEN: \"${CHROME_TOKEN}\"\n      CHROME_URL: ws://chrome:3000\n\n      # -- Database (Postgres) --\n      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/postgres\n\n      # -- Auth --\n      ACCESS_TOKEN_SECRET: ${ACCESS_TOKEN_SECRET}\n      REFRESH_TOKEN_SECRET: ${REFRESH_TOKEN_SECRET}\n\n      # -- Emails --\n      MAIL_FROM: noreply@localhost\n      # SMTP_URL: smtp://user:pass@smtp:587 # Optional\n\n      # -- Storage (Minio) --\n      STORAGE_ENDPOINT: minio\n      STORAGE_PORT: 9000\n      STORAGE_REGION: us-west-1 # Optional\n      STORAGE_BUCKET: default\n      STORAGE_ACCESS_KEY: \"${STORAGE_ACCESS_KEY}\"\n      STORAGE_SECRET_KEY: \"${STORAGE_SECRET_KEY}\"\n      STORAGE_USE_SSL: false\n      STORAGE_SKIP_BUCKET_CHECK: false\n\n      # -- Crowdin (Optional) --\n      # CROWDIN_PROJECT_ID:\n      # CROWDIN_PERSONAL_TOKEN:\n\n      # -- Email (Optional) --\n      # DISABLE_SIGNUPS: \"false\"\n      # DISABLE_EMAIL_AUTH: \"false\"\n\n      # -- GitHub (Optional) --\n      # GITHUB_CLIENT_ID: github_client_id\n      # GITHUB_CLIENT_SECRET: github_client_secret\n      # GITHUB_CALLBACK_URL: http://localhost:3000/api/auth/github/callback\n\n      # -- Google (Optional) --\n      # GOOGLE_CLIENT_ID: google_client_id\n      # GOOGLE_CLIENT_SECRET: google_client_secret\n      # GOOGLE_CALLBACK_URL: http://localhost:3000/api/auth/google/callback\n\n      # -- OpenID (Optional) --\n      # VITE_OPENID_NAME: OpenID\n      # OPENID_AUTHORIZATION_URL:\n      # OPENID_CALLBACK_URL: http://localhost:3000/api/auth/openid/callback\n      # OPENID_CLIENT_ID:\n      # OPENID_CLIENT_SECRET:\n      # OPENID_ISSUER:\n      # OPENID_SCOPE: openid profile email\n      # OPENID_TOKEN_URL:\n      # OPENID_USER_INFO_URL:\n\nvolumes:\n  minio_data:\n  postgres_data:\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/reactive-resume/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/reactive-resume.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    reactive-resume:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`resume.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: reactive-resume\n#endregion\n#region services\n  services:\n    reactive-resume:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.147:3000\"\n        passHostHeader: true\n#endregion\n  middlewares:\n    https-redirectscheme:\n      redirectScheme:\n        scheme: https\n        permanent: true\n    default-headers:\n      headers:\n        frameDeny: true\n        browserXssFilter: true\n        contentTypeNosniff: true\n        forceSTSHeader: true\n        stsIncludeSubdomains: true\n        stsPreload: true\n        stsSeconds: 15552000\n        customFrameOptionsValue: SAMEORIGIN\n        customRequestHeaders:\n          X-Forwarded-Proto: https\n\n    default-whitelist:\n      ipAllowList:\n        sourceRange:\n        - \"10.0.0.0/8\"\n        - \"192.168.0.0/16\"\n        - \"172.16.0.0/12\"\n\n    secured:\n      chain:\n        middlewares:\n        - default-whitelist\n        - default-headers\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/reactive-resume/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* backup:        Backup the application's volume data.\n* decrypt:       Decrypt sensitive configuration files using SOPS.\n* default:       List all available tasks.\n* encrypt:       Encrypt sensitive configuration files using SOPS.\n* export:        Export the task list to `task-list.txt`.\n* init:          Initialize the application's environment and configuration files.\n* pull:          Pull Docker images for the application.\n* restart:       Restart the application's Docker containers.\n* status:        Check the status of the application's Docker containers.\n* stop:          Stop the application's Docker containers.\n* up:            Run Docker Compose in the foreground.\n* up-d:          Run Docker Compose in the background.\n* update:        Update the application or its running containers.\n* upgrade:       Upgrade the application by pulling the latest changes and updating.\n* watch:         Watch the application's Docker container logs.\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/reactive-resume/#references","title":"References","text":"<ul> <li>https://github.com/AmruthPillai/Reactive-Resume</li> </ul>","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/","title":"Registry","text":"<p>Registry is a being used as a Docker pull through cache for my network.</p>","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/#installation","title":"Installation","text":"<p> Default Port: <code>5000</code></p> <p> Configuration path: <code>/etc/docker</code></p> <p><code>homelab/docker/registry</code></p> TaskDocker Compose <pre><code>task up\n</code></pre> <pre><code>docker compose up\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/#upgrade","title":"Upgrade","text":"<p>Warning</p> <p>The below commands purge any unused Docker images! Use at your own risk!</p> <p><code>homelab/docker/registry</code></p> TaskManual <pre><code>task upgrade\n</code></pre> <pre><code>(\n  git pull origin\n  docker compose up --force-recreate --build -d\n  docker image prune -a -f\n)\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/#config","title":"Config","text":"","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/#server","title":"Server","text":"<p>Init .env</p> TaskManual <pre><code>task init\n</code></pre> <pre><code>cp .env.tmpl .env\n</code></pre> <p><code>homelab/docker/registry/.env</code></p> <pre><code>\n</code></pre> <code>homelab/docker/registry/compose.yaml</code> AutomaticManual <pre><code>cat &lt;&lt; EOF &gt; ./docker/registry/compose.yaml\n---\nservices:\n  registry:\n    container_name: registry\n    image: library/registry:3.0.0\n    environment:\n      - REGISTRY_STORAGE_DELETE_ENABLED=true\n      - REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY=/var/lib/registry\n      - REGISTRY_PROXY_REMOTEURL=\"https://registry-1.docker.io\"\n      - REGISTRY_PROXY_USERNAME=$DOCKER_USER\n      - REGISTRY_PROXY_PASSWORD=$DOCKER_TOKEN\n    env_file:\n      - .env\n    ports:\n      - '5000:5000'\n    volumes:\n      - ${REGISTRY_DIR:-/var/lib/registry}:/var/lib/registry\n    restart: always\n\nEOF\n</code></pre> <pre><code>---\nservices:\n  registry:\n    container_name: registry\n    image: library/registry:3.0.0\n    environment:\n      - REGISTRY_STORAGE_DELETE_ENABLED=true\n      - REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY=/var/lib/registry\n      - REGISTRY_PROXY_REMOTEURL=\"https://registry-1.docker.io\"\n      - REGISTRY_PROXY_USERNAME=$DOCKER_USER\n      - REGISTRY_PROXY_PASSWORD=$DOCKER_TOKEN\n    env_file:\n      - .env\n    ports:\n      - '5000:5000'\n    volumes:\n      - ${REGISTRY_DIR:-/var/lib/registry}:/var/lib/registry\n    restart: always\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/#client","title":"Client","text":"<p>Tip</p> <p><code>registry-mirrors</code> must start with <code>http</code> or <code>https</code> else an error will be thrown when trying to restart the docker service.</p> <p><code>/etc/docker/daemon.json</code></p> AutomaticDownloadManual <pre><code>cat &lt;&lt;EOF &gt; /etc/docker/daemon.json\n{\n  \"log-driver\": \"journald\",\n  \"insecure-registries\": [ \"192.168.2.81:5000\" ],\n  \"registry-mirrors\": [ \"https://registry.l.nicholaswilde.io\" ]\n}\n\nEOF\n</code></pre> <pre><code>(\n  [ ! -d /etc/docker ] &amp;&amp; mkdir -p /etc/docker\n  wget https://raw.githubusercontent.com/nicholaswilde/homelab/refs/heads/main/docker/registry/daemon.json -O /etc/docker/daemon.json\n)\n</code></pre> <pre><code>{\n  \"log-driver\": \"journald\",\n  \"insecure-registries\": [ \"192.168.2.81:5000\" ],\n  \"registry-mirrors\": [ \"https://registry.l.nicholaswilde.io\" ]\n}\n</code></pre> <p>Restart the Docker service</p> TaskManual <pre><code>task restart\n</code></pre> <pre><code>(\n  systemctl daemon-reload\n  systemctl restart docker.service\n)\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/registry.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    registry:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`registry.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: registry\n#endregion\n#region services\n  services:\n    registry:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.81:5000\"\n        passHostHeader: true\n#endregion\n  middlewares:\n    https-redirectscheme:\n      redirectScheme:\n        scheme: https\n        permanent: true\n    default-headers:\n      headers:\n        frameDeny: true\n        browserXssFilter: true\n        contentTypeNosniff: true\n        forceSTSHeader: true\n        stsIncludeSubdomains: true\n        stsPreload: true\n        stsSeconds: 15552000\n        customFrameOptionsValue: SAMEORIGIN\n        customRequestHeaders:\n          X-Forwarded-Proto: https\n\n    default-whitelist:\n      ipAllowList:\n        sourceRange:\n        - \"10.0.0.0/8\"\n        - \"192.168.0.0/16\"\n        - \"172.16.0.0/12\"\n\n    secured:\n      chain:\n        middlewares:\n        - default-whitelist\n        - default-headers\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/#usage","title":"Usage","text":"","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/#client_1","title":"Client","text":"Pull ThroughSecure pull from localInsecure pull from local <pre><code>docker pull ubuntu\n</code></pre> <pre><code>docker pull https://registry.l.nicholaswilde.io/library/ubuntu\n</code></pre> <pre><code>docker pull 192.168.2.81:5000/library/ubuntu\n</code></pre> <p>WIP</p>","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/#upgrade_1","title":"Upgrade","text":"<p>Warning</p> <p>The below commands purge any unused Docker images! Use at your own risk!</p> <p><code>homelab/docker/registry</code></p> TaskManual <pre><code>task upgrade\n</code></pre> <pre><code>(\n  git pull origin\n  docker compose up --force-recreate --build -d\n  docker image prune -a -f\n)\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt sensitive configuration files using SOPS.\n* default:       List all available tasks.\n* encrypt:       Encrypt sensitive configuration files using SOPS.\n* export:        Export the task list to `task-list.txt`.\n* init:          Initialize the application's environment and configuration files.\n* mklinks:       Create symbolic links for configuration files.\n* restart:       Restart the application's Docker containers.\n* status:        Check the status of the application's service or Docker containers.\n* stop:          Stop the application's Docker containers.\n* up:            Run Docker Compose in the foreground.\n* up-d:          Run Docker Compose in the background.\n* update:        Update the application or its running containers.\n* upgrade:       Upgrade the application by pulling the latest changes and updating.\n* watch:         Watch the application's Docker container logs.\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/#troubleshooting","title":"Troubleshooting","text":"<p>Watch the logs on the server during a pull to ensure that the image is being pulled through the local registry.</p> <p><code>homelab/docker/registry</code></p> TaskManual <pre><code>task logs\n</code></pre> <pre><code>docker logs registry -f\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"apps/registry/#references","title":"References","text":"<ul> <li>https://docs.docker.com/docker-hub/image-library/mirror/</li> <li>https://youtu.be/Bm7g0saAC9k</li> </ul>","tags":["lxc","proxmox","docker"]},{"location":"apps/reprepro/","title":"reprepro","text":"<p>reprepro is used as a local repository for deb packages.</p> <p>Some apps, like SOPS, release deb files, but are not a part of the normal repository. Hosting them locally, allows me to download the package once and then easily update on all other containers.</p>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#installation","title":"Installation","text":"<pre><code>apt install reprepro apache2 gpg\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#config","title":"Config","text":"","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#apache","title":"Apache","text":"<p>/etc/apache2/apache2.conf</p> AutomatedManual <pre><code>echo \"ServerName localhost\" | tee -a /etc/apache2/apache2.conf\n</code></pre> <pre><code>ServerName localhost\n</code></pre> <p>/etc/apache2/conf-availabe/repos.conf</p> AutomatedDownloadManual <pre><code>cat &lt;&lt;EOF &gt; /etc/apache2/conf-availabe/repos.conf \n# /etc/apache2/conf.available/repos.conf\n# Apache HTTP Server 2.4\n\nAlias /repos/apt/debian /srv/reprepro/debian\n\n&lt;Directory /srv/reprepro/ &gt;\n        # We want the user to be able to browse the directory manually\n        Options Indexes FollowSymLinks Multiviews\n        Require all granted\n&lt;/Directory&gt;\n\n# This syntax supports several repositories, e.g. one for Debian, one for Ubuntu.\n# Replace * with debian, if you intend to support one distribution only.\n&lt;Directory \"/srv/reprepro/*/db/\"&gt;\n        Require all denied\n&lt;/Directory&gt;\n\n&lt;Directory \"/srv/reprepro/*/conf/\"&gt;\n        Require all denied\n&lt;/Directory&gt;\n\n&lt;Directory \"/srv/reprepro/*/incoming/\"&gt;\n        Require all denied\n&lt;/Directory&gt;\n\nEOF\n</code></pre> <pre><code>wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/apache2/conf-available/repos.conf -O /etc/apache2/conf-availabe/repos.conf\n</code></pre> <pre><code># /etc/apache2/conf.available/repos.conf\n# Apache HTTP Server 2.4\n\nAlias /repos/apt/debian /srv/reprepro/debian\n\n&lt;Directory /srv/reprepro/ &gt;\n        # We want the user to be able to browse the directory manually\n        Options Indexes FollowSymLinks Multiviews\n        Require all granted\n&lt;/Directory&gt;\n\n# This syntax supports several repositories, e.g. one for Debian, one for Ubuntu.\n# Replace * with debian, if you intend to support one distribution only.\n&lt;Directory \"/srv/reprepro/*/db/\"&gt;\n        Require all denied\n&lt;/Directory&gt;\n\n&lt;Directory \"/srv/reprepro/*/conf/\"&gt;\n        Require all denied\n&lt;/Directory&gt;\n\n&lt;Directory \"/srv/reprepro/*/incoming/\"&gt;\n        Require all denied\n&lt;/Directory&gt;\n</code></pre> <p>Enable and test</p> <pre><code>(\n    a2enconf repos &amp;&amp; \\\n    apache2ctl configtest &amp;&amp; \\\n    service apache2 restart\n)\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#config_1","title":"Config","text":"","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#repository","title":"Repository","text":"<p>Make directories</p> <p><code>shell (   [ -d /srv/reprepro/debian/conf ] || mkdir -p /srv/reprepro/debian/conf   [ -d /srv/reprepro/ubuntu/conf ] || mkdir -p /srv/reprepro/ubuntu/conf  )</code></p> <p>Generate new gpg keys</p> <pre><code>gpg --full-generate-key\n</code></pre> <pre><code>gpg --list-keys  \n pub  2048R/489CD644 2014-07-15  \n uid         Your Name &lt;noreply@email.com&gt;  \n sub  2048R/870B8E2D 2014-07-15\n</code></pre> <p>Get short fingerprint</p> <pre><code>gpg -k noreply@email.com | sed -n '2p'| sed 's/ //g' | tail -c 9\n</code></pre> <p>short fingerprint</p> <pre><code>089C9FAF\n</code></pre> <p>Export public gpg key</p> <pre><code>gpg --export-options export-minimal -a --export 089C9FAF | sudo tee /srv/reprepro/public.gpg.key\n</code></pre> <p>/srv/reprepo/&lt;dist&gt;/conf/distributions</p> AutomatedSymlinksDownloadDebian ManualUbuntu Manual <pre><code>(\n  cat &lt;&lt;EOF &gt; /srv/reprepo/debian/conf/distributions\n  Origin: Debian  \n  Label: Bookworm apt repository  \n  Codename: bookworm\n  Architectures: i386 amd64 arm64 armhf\n  Components: main  \n  Description: Apt repository for Debian stable - Bookworm  \n  DebOverride: override.bookworm\n  DscOverride: override.bookworm\n  SignWith: 089C9FAF \n\n  Origin: Debian  \n  Label: Bullseye apt repository\n  Codename: bullseye\n  Architectures: i386 amd64 arm64 armhf\n  Components: main  \n  Description: Apt repository for Debian stable - Bullseye  \n  DebOverride: override.bullseye\n  DscOverride: override.bullseye\n  SignWith: 089C9FAF\n\n  Origin: Debian\n  Label: Trixie apt repository\n  Codename: trixie\n  Architectures: i386 amd64 arm64 armhf\n  Components: main\n  Description: Apt repository for Debian stable - Trixie\n  DebOverride: override.trixie\n  DscOverride: override.trixie\n  SignWith: 089C9FAF\n\n  EOF\n  cat &lt;&lt;EOF &gt; /srv/reprepo/ubuntu/conf/distributions\n  Origin: Ubuntu\n  Label: Questing apt repository\n  Codename: questing\n  Architectures: amd64 arm64 armhf\n  Components: main  \n  Description: Apt repository for Ubuntu stable - Questing\n  DebOverride: override.questing\n  DscOverride: override.questing\n  SignWith: 089C9FAF \n\n  Origin: Ubuntu\n  Label: Plucky apt repository\n  Codename: plucky\n  Architectures: amd64 arm64 armhf\n  Components: main  \n  Description: Apt repository for Ubuntu stable - Plucky\n  DebOverride: override.plucky\n  DscOverride: override.plucky\n  SignWith: 089C9FAF \n\n  Origin: Ubuntu\n  Label: Oracular apt repository\n  Codename: oracular\n  Architectures: amd64 arm64 armhf\n  Components: main  \n  Description: Apt repository for Ubuntu stable - Oracular\n  DebOverride: override.oracular\n  DscOverride: override.oracular\n  SignWith: 089C9FAF \n\n  Origin: Ubuntu\n  Label: Noble apt repository\n  Codename: noble\n  Architectures: amd64 arm64 armhf\n  Components: main  \n  Description: Apt repository for Ubuntu stable - Noble\n  DebOverride: override.noble\n  DscOverride: override.noble\n  SignWith: 089C9FAF \n\n  Origin: Ubuntu\n  Label: Jammy apt repository\n  Codename: jammy\n  Architectures: amd64 arm64 armhf\n  Components: main  \n  Description: Apt repository for Ubuntu stable - Jammy\n  DebOverride: override.jammy\n  DscOverride: override.jammy\n  SignWith: 089C9FAF \n\n  EOF\n)\n</code></pre> <pre><code>(\n  ln -s /root/git/nicholaswilde/homelab/pve/reprepro/debian/conf/distributions /srv/reprepro/debian/conf/distributions\n  ln -s /root/git/nicholaswilde/homelab/pve/reprepro/ubuntu/conf/distributions /srv/reprepro/ubuntu/conf/distributions\n)\n</code></pre> <pre><code>(\n  wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/debian/conf/distributions -O /srv/reprepro/debian/conf/distributions\n  wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/ubuntu/conf/distributions -O /srv/reprepro/ubuntu/conf/distributions\n)\n</code></pre> <pre><code>Origin: Debian  \nLabel: Bookworm apt repository  \nCodename: bookworm\nArchitectures: i386 amd64 arm64 armhf\nComponents: main  \nDescription: Apt repository for Debian stable - Bookworm  \nDebOverride: override.bookworm\nDscOverride: override.bookworm\nSignWith: 089C9FAF \n\nOrigin: Debian  \nLabel: Bullseye apt repository\nCodename: bullseye\nArchitectures: i386 amd64 arm64 armhf\nComponents: main  \nDescription: Apt repository for Debian stable - Bullseye  \nDebOverride: override.bullseye\nDscOverride: override.bullseye\nSignWith: 089C9FAF\n\nOrigin: Debian\nLabel: Trixie apt repository\nCodename: trixie\nArchitectures: i386 amd64 arm64 armhf\nComponents: main\nDescription: Apt repository for Debian stable - Trixie\nDebOverride: override.trixie\nDscOverride: override.trixie\nSignWith: 089C9FAF\n</code></pre> <pre><code>Origin: Ubuntu\nLabel: Questing apt repository\nCodename: questing\nArchitectures: amd64 arm64 armhf\nComponents: main  \nDescription: Apt repository for Ubuntu stable - Questing\nDebOverride: override.questing\nDscOverride: override.questing\nSignWith: 089C9FAF \n\nOrigin: Ubuntu\nLabel: Plucky apt repository\nCodename: plucky\nArchitectures: amd64 arm64 armhf\nComponents: main  \nDescription: Apt repository for Ubuntu stable - Plucky\nDebOverride: override.plucky\nDscOverride: override.plucky\nSignWith: 089C9FAF \n\nOrigin: Ubuntu\nLabel: Oracular apt repository\nCodename: oracular\nArchitectures: amd64 arm64 armhf\nComponents: main  \nDescription: Apt repository for Ubuntu stable - Oracular\nDebOverride: override.oracular\nDscOverride: override.oracular\nSignWith: 089C9FAF \n\nOrigin: Ubuntu\nLabel: Noble apt repository\nCodename: noble\nArchitectures: amd64 arm64 armhf\nComponents: main  \nDescription: Apt repository for Ubuntu stable - Noble\nDebOverride: override.noble\nDscOverride: override.noble\nSignWith: 089C9FAF \n\nOrigin: Ubuntu\nLabel: Jammy apt repository\nCodename: jammy\nArchitectures: amd64 arm64 armhf\nComponents: main  \nDescription: Apt repository for Ubuntu stable - Jammy\nDebOverride: override.jammy\nDscOverride: override.jammy\nSignWith: 089C9FAF \n</code></pre> <p>/srv/reprepo/&lt;dist&gt;/conf/options</p> AutomatedDownloadSymlinksDebian ManualUbuntu Manual <pre><code>cat &lt;&lt;EOF &gt; /srv/reprepo/debian/conf/options\nverbose\nbasedir /srv/reprepro/debian\nask-passphrase\nEOF\ncat &lt;&lt;EOF &gt; /srv/reprepo/ubuntu/conf/options\nverbose\nbasedir /srv/reprepro/ubuntu\nask-passphrase\nEOF\n</code></pre> <pre><code>(\n  wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/debian/conf/options -O /srv/reprepro/debian/conf/options\n  wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/ubuntu/conf/options -O /srv/reprepro/ubuntu/conf/options\n)\n</code></pre> <pre><code>(\n  ln -s /root/git/nicholaswilde/homelab/pve/reprepro/debian/conf/options /srv/reprepro/debian/conf/options\n  ln -s /root/git/nicholaswilde/homelab/pve/reprepro/ubuntu/conf/options /srv/reprepro/ubuntu/conf/options\n)\n</code></pre> <pre><code>verbose\nbasedir /srv/reprepro/debian\nask-passphrase\n</code></pre> <pre><code>verbose\nbasedir /srv/reprepro/ubuntu\nask-passphrase\n</code></pre> <p>/srv/reprepo/&lt;dist&gt;/conf/override.&lt;codename&gt;</p> AutomaticDownloadSymlinksManual <pre><code>task symlinks\n</code></pre> <pre><code>(\n  sudo wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/debian/conf/override.bullseye -O /srv/reprepro/debian/conf/override.bullseye\n  sudo wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/debian/conf/override.bookworm -O /srv/reprepro/debian/conf/override.bookworm\n  sudo wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/debian/conf/override.trixie -O /srv/reprepro/debian/conf/override.trixie\n  sudo wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/ubuntu/conf/override.questing -O /srv/reprepro/ubuntu/conf/override.questing\n  sudo wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/ubuntu/conf/override.plucky -O /srv/reprepro/ubuntu/conf/override.plucky\n  sudo wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/ubuntu/conf/override.oracular -O /srv/reprepro/ubuntu/conf/override.oracular\n  sudo wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/ubuntu/conf/override.noble -O /srv/reprepro/ubuntu/conf/override.noble\n  sudo wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/reprepro/ubuntu/conf/override.jammy -O /srv/reprepro/ubuntu/conf/override.jammy\n)\n</code></pre> <pre><code>(\n  sudo ln -fs /root/git/nicholaswilde/homelab/pve/reprepro/debian/conf/override.bullseye /srv/reprepro/debian/conf/override.bullseye\n  sudo ln -fs /root/git/nicholaswilde/homelab/pve/reprepro/debian/conf/override.bookworm /srv/reprepro/debian/conf/override.bookworm\n  sudo ln -fs /root/git/nicholaswilde/homelab/pve/reprepro/debian/conf/override.trixie /srv/reprepro/debian/conf/override.trixie\n  sudo ln -fs /root/git/nicholaswilde/homelab/pve/reprepro/ubuntu/conf/override.questing /srv/reprepro/ubuntu/conf/override.questing\n  sudo ln -fs /root/git/nicholaswilde/homelab/pve/reprepro/ubuntu/conf/override.plucky /srv/reprepro/ubuntu/conf/override.plucky\n  sudo ln -fs /root/git/nicholaswilde/homelab/pve/reprepro/ubuntu/conf/override.oracular /srv/reprepro/ubuntu/conf/override.oracular\n  sudo ln -fs /root/git/nicholaswilde/homelab/pve/reprepro/ubuntu/conf/override.noble /srv/reprepro/ubuntu/conf/override.noble\n  sudo ln -fs /root/git/nicholaswilde/homelab/pve/reprepro/ubuntu/conf/override.jammy /srv/reprepro/ubuntu/conf/override.jammy\n)\n</code></pre> <pre><code>(\n  sudo touch /srv/reprepro/debian/conf/override.bookworm\n  sudo touch /srv/reprepro/debian/conf/override.bullseye\n  sudo touch /srv/reprepro/debian/conf/override.trixie\n  sudo touch /srv/reprepro/ubuntu/conf/override.questing\n  sudo touch /srv/reprepro/ubuntu/conf/override.plucky\n  sudo touch /srv/reprepro/ubuntu/conf/override.oracular\n  sudo touch /srv/reprepro/ubuntu/conf/override.noble\n  sudo touch /srv/reprepro/ubuntu/conf/override.jammy\n)\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#environmental-file","title":"Environmental File","text":"<p>A <code>.env</code> file is used to set variables that are used with task and scripts.</p> <p><code>homelab/pve/reprepro</code></p> AutomaticManual <pre><code>task init\n</code></pre> <pre><code>cp .env.tmpl .env\n</code></pre> <p>Edit the <code>.env</code> file with your preferred text editor.</p> .env <pre><code># Used by multiple scripts\nGITHUB_TOKEN=\nBASE_DIR=/srv/reprepro\nENABLE_NOTIFICATIONS=\"true\"\nDEBUG=\"false\"\n\n# sync-check.sh\nSYNC_APPS_GITHUB_REPOS=(\"getsops/sops\" \"go-task/task\" \"sharkdp/fd\" \"sharkdp/bat\" \"localsend/localsend\" \"BurntSushi/ripgrep\" \"muesli/duf\" \"charmbracelet/glow\")\n\n# package-neovim.sh\nPACKAGE_APPS=(\"BurntSushi/ripgrep:file_strip:rg:.*-\\K[^-]+(?=-unknown-linux-gnu)\" \"eza-community/eza:all::(?&lt;=_)[^-]*\" \"chmln/sd:file_strip::.*-\\K[^-]+(?=-unknown-linux)\" \"aristocratos/btop:file_path:btop/bin/btop:(?&lt;=btop-)[^-]+(?=-linux-)\")\n\n# Mailrise notifications\nMAILRISE_URL='smtp://smtp.l.nicholaswilde.io:8025'\nMAILRISE_FROM='reprepro@nicholaswilde.io'\nMAILRISE_RCPT='email@mailrise.xyz'\n\n# upload-neovim.sh\nREMOTE_IP=192.168.2.32\nREMOTE_USER=root\nREMOTE_PATH=/root/\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#adding-a-new-release-codename","title":"Adding a New Release Codename","text":"<p>To add a new release codename to reprepro:</p> <ol> <li>Add a new <code>override.&lt;codename&gt;</code> file in <code>/srv/reprepro/&lt;dist&gt;/conf</code>.</li> <li>Add a new entry to <code>/srv/reprepro/&lt;dist&gt;/conf/distributions</code> file.</li> </ol> <p><code>/srv/reprepro/&lt;dist&gt;/conf/distributions</code></p> <pre><code>Origin: Ubuntu\nLabel: Oracular apt repository\nCodename: plucky\nArchitectures: amd64 arm64 armhf\nComponents: main\nDescription: Apt repository for Ubuntu stable - Plucky\nDebOverride: override.plucky\nDscOverride: override.plucky\nSignWith: 089C9FAF\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#usage","title":"Usage","text":"","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#server","title":"Server","text":"<p>Add deb file to reprepro.</p> Manual <pre><code>(\n  sudo reprepro -b /srv/reprepro/debian -C main includedeb bookworm sops_3.9.4_amd64.deb\n  sudo reprepro -b /srv/reprepro/debian -C main includedeb bullseye sops_3.9.4_amd64.deb\n  sudo reprepro -b /srv/reprepro/debian -C main includedeb trixie sops_3.9.4_amd64.deb\n  sudo reprepro -b /srv/reprepro/ubuntu -C main includedeb questing sops_3.9.4_amd64.deb\n  sudo reprepro -b /srv/reprepro/ubuntu -C main includedeb plucky sops_3.9.4_amd64.deb\n  sudo reprepro -b /srv/reprepro/ubuntu -C main includedeb oracular sops_3.9.4_amd64.deb\n  sudo reprepro -b /srv/reprepro/ubuntu -C main includedeb noble sops_3.9.4_amd64.deb\n  sudo reprepro -b /srv/reprepro/ubuntu -C main includedeb jammy sops_3.9.4_amd64.deb\n)\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#client","title":"Client","text":"<p>Download gpg key</p> <pre><code>curl -fsSL http://deb.l.nicholaswilde.io/public.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/reprepro.gpg\n</code></pre> <p>Add repo and install.</p> <p><code>/etc/apt/sources.list.d/reprepro.list</code></p> AutomaticManual <pre><code>(\n  source /etc/os-release &amp;&amp; \\\n  echo \"deb [signed-by=/etc/apt/keyrings/reprepro.gpg] http://deb.l.nicholaswilde.io/${ID} ${VERSION_CODENAME} main\"\n  apt update &amp;&amp; \\\n  apt install sops\n)\n</code></pre> BookwormBullseyeTrixie <pre><code>deb [signed-by=/etc/apt/keyrings/reprepro.gpg] http://deb.l.nicholaswilde.io/debian bookworm main\n</code></pre> <pre><code>apt update &amp;&amp; \\\napt install sops\n</code></pre> <pre><code>deb [signed-by=/etc/apt/keyrings/reprepro.gpg] http://deb.l.nicholaswilde.io/debian bullseye main\n</code></pre> <pre><code>apt update &amp;&amp; \\\napt install sops\n</code></pre> <pre><code>deb [signed-by=/etc/apt/keyrings/reprepro.gpg] http://deb.l.nicholaswilde.io/debian trixie main\n</code></pre> <pre><code>apt update &amp;&amp; \\\napt install sops\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#copy-all-package-from-one-codename-to-another-from-noble-to-questing","title":"Copy all package from one codename to another from <code>noble</code> to <code>questing</code>.","text":"<pre><code>sudo reprepro -b /srv/reprepro/ubuntu/ copymatched questing noble '*'\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#list-all-package-information","title":"List all package information","text":"<pre><code>find /srv/reprepro/ubuntu/dists/noble -name 'Packages.gz' -exec zcat {} +\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#regenerate-the-repository-index","title":"Regenerate the Repository Index","text":"<p>This can fix <code>BADSIG</code> errors shown on remote hosts.</p> <p>The <code>badsig</code> error means the <code>Release.gpg</code> file for that codename does not contain a valid signature for the Release file. The Release file itself contains a list of all other index files (like Packages.gz) and their checksums.</p> <pre><code>sudo reprepro -b /srv/reprepro/debian/ -V export noble\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#scripts","title":"Scripts","text":"<p>Some scripts are provided to help with common tasks.</p>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#update-reprepro","title":"Update Reprepro","text":"<p>The script <code>update-reprepro.sh</code> is used to compare the latest released versions of the apps specified with the  <code>SYNC_APPS_GITHUB_REPOS</code> and <code>PACKAGE_APPS</code> variables in the <code>.env</code> file to the local versions.</p> <p>If out of date, the compressed archives specified in the <code>PACKAGE_APPS</code> variable are downloaded, packaged into deb files, and added to reprepro and deb files located in the <code>SYNC_APPS_GITHUB_REPOS</code> variable are downloaded and add to reprepro.</p> <p><code>homelab/pve/reprepro</code></p> TaskManual <pre><code>task update-reprepro\n</code></pre> <pre><code>sudo ./update-reprepro.sh\n</code></pre> package-apps.sh <pre><code>#!/usr/bin/env bash\n################################################################################\n#\n# Script Name: update-reprepro.sh\n# ----------------\n# Downloads application tar.gz and .deb files, packages them as needed, and\n# adds them to a reprepro repository.\n#\n# Combines the functionality of package-apps.sh and sync-check.sh.\n#\n# @author Nicholas Wilde, 0xb299a622\n# @date 18 Oct 2025\n# @version 1.0.0\n#\n################################################################################\n\n# Options\n# set -e\n# set -o pipefail\n\n# These are constants\nreadonly BLUE=$(tput setaf 4)\nreadonly RED=$(tput setaf 1)\nreadonly YELLOW=$(tput setaf 3)\nreadonly PURPLE=$(tput setaf 5)\nreadonly RESET=$(tput sgr0)\nreadonly SCRIPT_DIR=$( cd -- \"$( dirname -- \"${BASH_SOURCE[0]}\" )\" &amp;&gt; /dev/null &amp;&amp; pwd )\nreadonly DEBIAN_CODENAMES=($(grep -oP '(?&lt;=Codename: ).*' \"${SCRIPT_DIR}/debian/conf/distributions\"))\nreadonly UBUNTU_CODENAMES=($(grep -oP '(?&lt;=Codename: ).*' \"${SCRIPT_DIR}/ubuntu/conf/distributions\"))\n\n# Default variables\nBASE_DIR=\"/srv/reprepro\"\nENABLE_NOTIFICATIONS=\"false\"\nDEBUG=\"false\"\n\nif [ ! -f \"${SCRIPT_DIR}/.env\" ]; then\n  echo \"ERRO[$(date +'%Y-%m-%d %H:%M:%S')] The .env file is missing. Please create it.\" &gt;&amp;2\n  exit 1\nfi\nsource \"${SCRIPT_DIR}/.env\"\n\nAPPS_OUT_OF_DATE=\"false\"\nUPDATE_SUCCESS=\"true\"\nSUCCESSFUL_APPS=()\nFAILED_APPS=()\n\n# Logging function\nfunction log() {\n  local type=\"$1\"\n  local color=\"$RESET\"\n\n  if [ \"${type}\" = \"DEBU\" ] &amp;&amp; [ \"${DEBUG}\" != \"true\" ]; then\n    return 0\n  fi\n\n  case \"$type\" in\n    INFO)\n      color=\"$BLUE\";;\n    WARN)\n      color=\"$YELLOW\";;\n    ERRO)\n      color=\"$RED\";;\n    DEBU)\n      color=\"$PURPLE\";;\n    *)\n      type=\"LOGS\";;\n  esac\n  if [[ -t 0 ]]; then\n    local message=\"$2\"\n    echo -e \"${color}${type}${RESET}[$(date +'%Y-%m-%d %H:%M:%S')] ${message}\"\n  else\n    while IFS= read -r line; do\n      echo -e \"${color}${type}${RESET}[$(date +'%Y-%m-%d %H:%M:%S')] ${line}\"\n    done\n  fi\n}\n\nfunction usage() {\n  cat &lt;&lt;EOF\nUsage: $0 [options]\n\nManages Debian packages in the reprepro repository.\n\nThis script can:\n1. Download application source (tar.gz), package it into a .deb, and add it.\n2. Download pre-compiled .deb packages and add them.\n\nOptions:\n  -d, --debug         Enable debug mode, which prints more info.\n  -r, --remove &lt;pkg&gt;  Remove a package from the repository.\n  -h, --help          Display this help message.\nEOF\n}\n\n# Cleanup function to remove temporary directory\nfunction cleanup() {\n  if [ -d \"${TEMP_PATH}\" ]; then\n    log \"INFO\" \"Cleaning up temporary directory: ${TEMP_PATH}\"\n    rm -rf \"${TEMP_PATH}\"\n  fi\n}\n\n# Checks if a command exists.\nfunction command_exists() {\n  command -v \"$1\" &gt;/dev/null 2&gt;&amp;1\n}\n\nfunction check_dependencies() {\n  if ! command_exists reprepro; then\n    log \"ERRO\" \"reprepro is not installed.\"\n    exit 1\n  fi\n  if ! command_exists curl || ! command_exists jq || ! command_exists dpkg-deb; then\n    log \"ERRO\" \"Required dependencies (curl, jq, dpkg-deb) are not installed.\"\n    exit 1\n  fi\n}\n\nfunction check_root(){\n  if [ \"$UID\" -ne 0 ]; then\n    log \"ERRO\" \"Please run as root or with sudo.\"\n    exit 1\n  fi\n}\n\nfunction make_temp_dir(){\n  export TEMP_PATH=$(mktemp -d)\n  if [ ! -d \"${TEMP_PATH}\" ]; then\n    log \"ERRO\" \"Could not create temp dir\"\n    exit 1\n  fi\n  log \"INFO\" \"Temp path: ${TEMP_PATH}\"\n}\n\nfunction get_latest_version() {\n  local api_url=\"https://api.github.com/repos/${GITHUB_REPO}/releases/latest\"\n  local curl_args=('-s')\n  if [ -n \"${GITHUB_TOKEN}\" ]; then\n    curl_args+=('-H' \"Authorization: Bearer ${GITHUB_TOKEN}\")\n  fi\n\n  export json_response=$(curl \"${curl_args[@]}\" \"${api_url}\")\n\n  if ! echo \"${json_response}\" | jq -e '.tag_name' &gt;/dev/null 2&gt;&amp;1; then\n    log \"ERRO\" \"Failed to get latest version for ${APP_NAME} from GitHub API.\"\n    echo \"${json_response}\"\n    return 1\n  fi\n\n  export TAG_NAME=$(echo \"${json_response}\" | jq -r '.tag_name')\n  export LATEST_VERSION=${TAG_NAME#v}\n  export PUBLISHED_AT=$(echo \"${json_response}\" | jq -r '.published_at')\n  export SOURCE_DATE_EPOCH=$(date -d \"${PUBLISHED_AT}\" +%s)\n  log \"INFO\" \"Latest ${APP_NAME} version: ${LATEST_VERSION} (tag: ${TAG_NAME})\"\n}\n\nfunction get_current_version(){\n  CURRENT_VERSION=$(sudo reprepro --confdir \"${BASE_DIR}/ubuntu/conf/\" list \"${UBUNTU_CODENAMES[0]}\" \"${APP_NAME}\" 2&gt;/dev/null | head -1 | awk '{print $NF}' | sed 's/[-+].*//' || true)\n  export CURRENT_VERSION\n  log \"INFO\" \"Current ${APP_NAME} version in reprepro: ${CURRENT_VERSION}\"\n}\n\nfunction remove_package() {\n  local package_name=$1\n  log \"INFO\" \"Forcefully removing existing '${package_name}' packages from reprepro to ensure a clean state...\"\n  for codename in \"${UBUNTU_CODENAMES[@]}\"; do\n    log \"INFO\" \"Attempting to remove '${package_name}' from Ubuntu ${codename}\"\n    reprepro -b \"${BASE_DIR}/ubuntu\" remove \"${codename}\" \"${package_name}\"  2&gt;&amp;1 | log \"DEBU\" || true\n  done\n  for codename in \"${DEBIAN_CODENAMES[@]}\"; do\n    log \"INFO\" \"Attempting to remove '${package_name}' from Debian ${codename}\"\n    reprepro -b \"${BASE_DIR}/debian\" remove \"${codename}\" \"${package_name}\"  2&gt;&amp;1 | log \"DEBU\" || true\n  done\n\n  log \"INFO\" \"Searching for and removing old '${package_name}' .deb files from the pool...\"\n  find \"${BASE_DIR}/debian/pool/\" -name \"${package_name}_*.deb\" -delete\n  find \"${BASE_DIR}/ubuntu/pool/\" -name \"${package_name}_*.deb\" -delete\n  log \"INFO\" \"Pool cleanup complete.\"\n}\n\nfunction extract_binary() {\n  local extract_type=\"$1\"\n  local tarball_path=\"$2\"\n  local package_dir=\"$3\"\n  local folder_name=\"$4\"\n  local bin_name=\"$5\"\n  local arch_github=\"$7\"\n\n  log \"INFO\" \"Extracting ${APP_NAME} binary using strategy: ${extract_type}\"\n\n  local extract_dest=\"${package_dir}/usr/local/bin/\"\n\n  case \"${extract_type}\" in\n    \"all\")\n      tar -xf \"${tarball_path}\" -C \"${extract_dest}\" 2&gt;&amp;1 | log \"DEBU\" || { log \"ERRO\" \"Failed to extract ${tarball_path}\"; return 1; }\n      ;;\n    \"file_strip\")\n      tar -xf \"${tarball_path}\" -C \"${extract_dest}\" --strip-components=1 \"${folder_name}/${bin_name}\" 2&gt;&amp;1 | log \"DEBU\" || { log \"ERRO\" \"Failed to extract ${tarball_path}\"; return 1; }\n      ;;\n    \"file\")\n      tar -xf \"${tarball_path}\" -C \"${extract_dest}\" \"${bin_name}\"  2&gt;&amp;1 | log \"DEBU\" || { log \"ERRO\" \"Failed to extract ${tarball_path}\"; return 1; }\n      ;;\n    \"file_path\")\n      local full_bin_path=\"${bin_name//\\$\\{ARCH\\}/${arch_github}}\"\n      local dir_path\n      dir_path=$(dirname \"${full_bin_path}\")\n      local strip_components=0\n      if [ \"${dir_path}\" != \".\" ]; then\n        strip_components=$(echo \"${dir_path}\" | awk -F'/' '{print NF}')\n      fi\n\n      tar -xf \"${tarball_path}\" -C \"${extract_dest}\" --strip-components=\"${strip_components}\" \"${full_bin_path}\" 2&gt;&amp;1 | log \"DEBU\" || { log \"ERRO\" \"Failed to extract ${full_bin_path} from ${tarball_path}\"; return 1; }\n\n      local extracted_bin_name\n      extracted_bin_name=$(basename \"${full_bin_path}\")\n      if [ \"${extracted_bin_name}\" != \"${APP_NAME}\" ]; then\n        log \"INFO\" \"Renaming extracted binary from ${extracted_bin_name} to ${APP_NAME}\"\n        mv \"${extract_dest}/${extracted_bin_name}\" \"${extract_dest}/${APP_NAME}\" || { log \"ERRO\" \"Failed to rename binary.\"; return 1; }\n      fi\n      ;;\n    *)\n      log \"ERRO\" \"Unknown extraction type: ${extract_type}\"\n      return 1;;\n  esac\n  return 0\n}\n\nfunction package_and_add() {\n  local arch_github=$1\n  local arch_debian=$2\n  local tarball_name=$3\n  local extract_type=$4\n  local bin_name=$5\n  local folder_name=\"${tarball_name%.tar.gz}\"\n  folder_name=\"${folder_name%.tar.bz2}\"\n  folder_name=\"${folder_name%.tbz}\"\n\n  log \"INFO\" \"Processing architecture: ${arch_github} as ${arch_debian}\"\n\n  local download_url\n  download_url=$(echo \"${json_response}\" | jq -r --arg pkg_name \"$tarball_name\" '.assets[] | select(.name==$pkg_name) | .browser_download_url')\n  if [ -z \"${download_url}\" ]; then\n    log \"ERRO\" \"Failed to get download url for ${tarball_name}\"\n    return 1\n  fi\n\n  local tarball_path=\"${TEMP_PATH}/${tarball_name}\"\n\n  log \"INFO\" \"Downloading ${tarball_name}...\"\n  wget -q \"${download_url}\" -O \"${tarball_path}\" 2&gt;&amp;1 | log \"DEBU\" || { log \"ERRO\" \"Failed to download ${tarball_name}\"; return 1; }\n\n  local package_dir=\"${TEMP_PATH}/${APP_NAME}_${LATEST_VERSION}_${arch_debian}\"\n  mkdir -p \"${package_dir}/usr/local/bin\"\n  mkdir -p \"${package_dir}/DEBIAN\"\n\n  extract_binary \"${extract_type}\" \"${tarball_path}\" \"${package_dir}\" \"${folder_name}\" \"${bin_name}\" \"${arch_github}\" || return 1\n\n  log \"INFO\" \"Creating control file...\"\n  cat &lt;&lt; EOF &gt; \"${package_dir}/DEBIAN/control\"\nPackage: ${APP_NAME}\nVersion: ${LATEST_VERSION}\nSection: utils\nPriority: optional\nArchitecture: ${arch_debian}\nMaintainer: Nicholas Wilde &lt;noreply@email.com&gt;\nDescription: ${DESCRIPTION}\nEOF\n\n  log \"INFO\" \"Building .deb package...\"\n  local deb_file=\"${APP_NAME}_${LATEST_VERSION}_${arch_debian}.deb\"\n  # dpkg-deb --build \"${package_dir}\" \"${TEMP_PATH}/${deb_file}\" 2&gt;&amp;1 | log \"DEBU\" || { log \"ERRO\" \"Failed to build .deb package for ${APP_NAME} ${LATEST_VERSION} ${arch_debian}\"; return 1; }\n  local build_output=$(dpkg-deb --build \"${package_dir}\" \"${TEMP_PATH}/${deb_file}\" 2&gt;&amp;1)\n  local exit_status=$?\n  echo \"${build_output}\" | log \"DEBU\"\n  if [[ ${exit_status} -ne 0 ]]; then\n    log \"ERRO\" \"Failed to build .deb package for ${APP_NAME} ${LATEST_VERSION} ${arch_debian}\"\n    return 1\n  fi\n  log \"INFO\" \"Adding ${deb_file} to reprepro...\"\n  for codename in \"${UBUNTU_CODENAMES[@]}\"; do\n    reprepro -b \"${BASE_DIR}/ubuntu\" -C main includedeb \"${codename}\" \"${TEMP_PATH}/${deb_file}\" 2&gt;&amp;1 | log \"DEBU\" || true\n  done\n  for codename in \"${DEBIAN_CODENAMES[@]}\"; do\n    reprepro -b \"${BASE_DIR}/debian\" -C main includedeb \"${codename}\" \"${TEMP_PATH}/${deb_file}\"  2&gt;&amp;1 | log \"DEBU\" || true\n  done\n}\n\nfunction download_and_add_deb() {\n  local package_name=$1\n\n  log \"INFO\" \"Processing package: ${package_name}\"\n\n  local download_url\n  download_url=$(echo \"${json_response}\" | jq -r --arg pkg_name \"$package_name\" '.assets[] | select(.name==$pkg_name) | .browser_download_url')\n\n  if [ -z \"${download_url}\" ]; then\n    log \"ERRO\" \"Failed to get download url for ${package_name}\"\n    return 1\n  fi\n\n  local package_path=\"${TEMP_PATH}/${package_name}\"\n\n  log \"INFO\" \"Downloading ${package_name}...\"\n  wget -q \"${download_url}\" -O \"${package_path}\" || { log \"ERRO\" \"Failed to download ${package_name}\"; return 1; }\n\n  log \"INFO\" \"Adding ${package_name} to reprepro...\"\n  for codename in \"${UBUNTU_CODENAMES[@]}\"; do\n    reprepro -b \"${BASE_DIR}/ubuntu\" -C main includedeb \"${codename}\" \"${package_path}\" 2&gt;&amp;1 | log \"DEBU\" || true\n  done\n  for codename in \"${DEBIAN_CODENAMES[@]}\"; do\n    reprepro -b \"${BASE_DIR}/debian\" -C main includedeb \"${codename}\" \"${package_path}\" 2&gt;&amp;1 | log \"DEBU\" || true\n  done\n}\n\nfunction update_app_from_source() {\n  local app_name=\"$1\"\n  local github_repo=\"$2\"\n  local extract_type=\"$3\"\n  local bin_name=\"$4\"\n  local arch_regexp=\"$5\"\n  export APP_NAME=\"${app_name}\"\n  export GITHUB_REPO=\"${github_repo}\"\n\n  print_separator \"Processing source package: ${APP_NAME}\"\n\n  get_latest_version || { FAILED_APPS+=(\"${app_name}\"); return 1; }\n  get_current_version\n\n  if [[ \"${LATEST_VERSION}\" == \"${CURRENT_VERSION}\" ]]; then\n    log \"INFO\" \"${APP_NAME} is already up-to-date: ${CURRENT_VERSION}\"\n    return 0\n  fi\n\n  APPS_OUT_OF_DATE=\"true\"\n  log \"INFO\" \"New version available for ${APP_NAME}: ${LATEST_VERSION}\"\n\n  export DESCRIPTION=$(curl -s \"https://api.github.com/repos/${GITHUB_REPO}\" | jq -r '.description' | sed -e 's/:\\w\\+://g' -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')\n\n  local linux_tarballs\n  linux_tarballs=$(echo \"${json_response}\" | jq -r '.assets[] | select(.name | (endswith(\".tar.gz\") or endswith(\".tar.bz2\") or endswith(\".tbz\")) and (contains(\"openbsd\") | not) and (contains(\"darwin\") | not) and (contains(\"freebsd\")| not) and (contains(\"android\") | not) and (contains(\"windows\") | not)) | .name')\n\n  local app_update_failed=\"false\"\n  for tarball in ${linux_tarballs}; do\n    local github_arch\n    github_arch=$(echo \"${tarball}\" | grep -oP \"${arch_regexp}\")\n\n    local debian_arch=\"\"\n    case \"${github_arch}\" in\n      \"amd64\"|\"x86_64\") debian_arch=\"amd64\";;\n      \"arm64\"|\"aarch64\") debian_arch=\"arm64\";;\n      \"armv7\"|\"armhf\"|\"arm\") debian_arch=\"armhf\";;\n      \"386\") debian_arch=\"i386\";;\n      *)\n        log \"WARN\" \"Unsupported architecture for ${APP_NAME}: ${github_arch//$'\\n'/ }. Skipping.\"\n        continue;;\n    esac\n\n    package_and_add \"${github_arch}\" \"${debian_arch}\" \"${tarball}\" \"${extract_type}\" \"${bin_name}\" || { app_update_failed=\"true\"; continue; }\n  done\n\n  get_current_version\n  if [[ \"${LATEST_VERSION}\" != \"${CURRENT_VERSION}\" || \"${app_update_failed}\" == \"true\" ]]; then\n    log \"ERRO\" \"Failed to update ${APP_NAME} to ${LATEST_VERSION}.\"\n    FAILED_APPS+=(\"${app_name}: ${LATEST_VERSION}\")\n    return 1\n  else\n    log \"INFO\" \"Successfully updated ${APP_NAME} to ${LATEST_VERSION}.\"\n    SUCCESSFUL_APPS+=(\"${app_name}: ${LATEST_VERSION}\")\n    return 0\n  fi\n}\n\nfunction update_app_from_deb() {\n  local app_config=\"$1\"\n  local github_repo\n  local app_name\n\n  if [[ \"${app_config}\" == *\"|\"* ]]; then\n    IFS='|' read -r github_repo app_name &lt;&lt;&lt; \"${app_config}\"\n  else\n    github_repo=\"${app_config}\"\n    app_name=$(basename \"${github_repo}\")\n  fi\n\n  export GITHUB_REPO=\"${github_repo}\"\n  export APP_NAME=\"${app_name}\"\n\n  print_separator \"Processing deb package: ${APP_NAME} from ${GITHUB_REPO}\"\n\n  get_latest_version || { FAILED_APPS+=(\"${APP_NAME}\"); return 1; }\n  get_current_version\n\n  if [[ \"${LATEST_VERSION}\" == \"${CURRENT_VERSION}\" ]]; then\n    log \"INFO\" \"${APP_NAME} is already up-to-date: ${CURRENT_VERSION}\"\n    return 0\n  fi\n\n  APPS_OUT_OF_DATE=\"true\"\n  log \"INFO\" \"New version available for ${APP_NAME}: ${LATEST_VERSION}\"\n\n  local linux_debs\n  linux_debs=$(echo \"${json_response}\" | jq -r '.assets[] | select(.name | endswith(\".deb\") and (contains(\"musl\") | not)) | .name')\n\n  local app_update_failed=\"false\"\n  for deb in ${linux_debs}; do\n    download_and_add_deb \"${deb}\" || { app_update_failed=\"true\"; continue; }\n  done\n\n  get_current_version\n  if [[ \"${LATEST_VERSION}\" != \"${CURRENT_VERSION}\" || \"${app_update_failed}\" == \"true\" ]]; then\n    log \"ERRO\" \"Failed to update ${APP_NAME} to ${LATEST_VERSION}.\"\n    FAILED_APPS+=(\"${APP_NAME}: ${LATEST_VERSION}\")\n    return 1\n  else\n    log \"INFO\" \"Successfully updated ${APP_NAME} to ${LATEST_VERSION}.\"\n    SUCCESSFUL_APPS+=(\"${APP_NAME}: ${LATEST_VERSION}\")\n    return 0\n  fi\n}\n\nfunction print_separator(){\n  local msg=$1\n  local header=$(printf '%.0s-' {1..60})\n  log \"INFO\" \"${header}\"\n  log \"INFO\" \"${msg}\"\n  log \"INFO\" \"${header}\"\n}\n\nfunction update_tea() {\n  export GITHUB_REPO=\"gitea/tea\"\n  local binary_name=\"tea\"\n  export APP_NAME=\"gitea-tea\" # This is the package name\n\n  # local header=$(printf '%.0s-' {1..60})\n  # log \"INFO\" \"--------------------------------------------------\"\n  # log \"INFO\" \"${header}\"\n  # log \"INFO\" \"Processing binary package: ${binary_name} from gitea.com as ${APP_NAME}\"\n  print_separator \"Processing binary package: ${binary_name} from gitea.com as ${APP_NAME}\"\n  # log \"INFO\" \"--------------------------------------------------\"\n  # log \"INFO\" \"${header}\"\n\n  local api_url=\"https://gitea.com/api/v1/repos/${GITHUB_REPO}/releases/latest\"\n  export json_response=$(curl -s \"${api_url}\")\n\n  if ! echo \"${json_response}\" | jq -e '.tag_name' &gt;/dev/null 2&gt;&amp;1; then\n    log \"ERRO\" \"Failed to get latest version for ${APP_NAME} from Gitea API.\"\n    echo \"${json_response}\"\n    FAILED_APPS+=(\"${APP_NAME}\")\n    return 1\n  fi\n\n  export TAG_NAME=$(echo \"${json_response}\" | jq -r '.tag_name')\n  export LATEST_VERSION=${TAG_NAME#v}\n  export PUBLISHED_AT=$(echo \"${json_response}\" | jq -r '.published_at')\n  export SOURCE_DATE_EPOCH=$(date -d \"${PUBLISHED_AT}\" +%s)\n  log \"INFO\" \"Latest ${APP_NAME} version: ${LATEST_VERSION} (tag: ${TAG_NAME})\"\n\n  get_current_version\n\n  if [[ \"${LATEST_VERSION}\" == \"${CURRENT_VERSION}\" ]]; then\n    log \"INFO\" \"${APP_NAME} is already up-to-date: ${CURRENT_VERSION}\"\n    return 0\n  fi\n\n  APPS_OUT_OF_DATE=\"true\"\n  log \"INFO\" \"New version available for ${APP_NAME}: ${LATEST_VERSION}\"\n\n  export DESCRIPTION=$(curl -s \"https://gitea.com/api/v1/repos/${GITHUB_REPO}\" | jq -r '.description' | sed -e 's/:\\w\\+://g' -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')\n\n  local linux_binaries\n  linux_binaries=$(echo \"${json_response}\" | jq -r '.assets[] | select(.name | contains(\"-linux-\") and (endswith(\".asc\") | not) and (endswith(\".sha256\") | not) and (endswith(\".tar.gz\") | not) and (endswith(\".zip\") | not)) | .name')\n\n  local app_update_failed=\"false\"\n  for binary in ${linux_binaries}; do\n    local gitea_arch\n    gitea_arch=$(echo \"${binary}\" | sed -n \"s/${binary_name}-${LATEST_VERSION}-linux-//p\")\n\n    local debian_arch=\"\"\n    case \"${gitea_arch}\" in\n      \"amd64\") debian_arch=\"amd64\";;\n      \"arm64\") debian_arch=\"arm64\";;\n      \"arm-7\") debian_arch=\"armhf\";;\n      \"386\") debian_arch=\"i386\";;\n      *)\n        log \"WARN\" \"Unsupported architecture for ${APP_NAME}: ${gitea_arch}. Skipping.\"\n        continue;;\n    esac\n\n    local download_url\n    download_url=$(echo \"${json_response}\" | jq -r --arg pkg_name \"$binary\" '.assets[] | select(.name==$pkg_name) | .browser_download_url')\n    if [ -z \"${download_url}\" ]; then\n      log \"ERRO\" \"Failed to get download url for ${binary}\"\n      app_update_failed=\"true\"\n      continue\n    fi\n\n    local binary_path=\"${TEMP_PATH}/${binary}\"\n\n    log \"INFO\" \"Downloading ${binary}...\"\n    wget -q \"${download_url}\" -O \"${binary_path}\" 2&gt;&amp;1 | log \"DEBU\" || { log \"ERRO\" \"Failed to download ${binary}\"; app_update_failed=\"true\"; continue; }\n\n    local package_dir=\"${TEMP_PATH}/${APP_NAME}_${LATEST_VERSION}_${debian_arch}\"\n    mkdir -p \"${package_dir}/usr/local/bin\"\n    mkdir -p \"${package_dir}/DEBIAN\"\n\n    mv \"${binary_path}\" \"${package_dir}/usr/local/bin/${binary_name}\"\n    chmod +x \"${package_dir}/usr/local/bin/${binary_name}\"\n\n    log \"INFO\" \"Creating control file for ${debian_arch}...\"\n    cat &lt;&lt; EOF &gt; \"${package_dir}/DEBIAN/control\"\nPackage: ${APP_NAME}\nVersion: ${LATEST_VERSION}\nSection: utils\nPriority: optional\nArchitecture: ${debian_arch}\nMaintainer: Nicholas Wilde &lt;noreply@email.com&gt;\nDescription: ${DESCRIPTION}\nEOF\n\n    log \"INFO\" \"Building .deb package for ${debian_arch}...\"\n    local deb_file=\"${APP_NAME}_${LATEST_VERSION}_${debian_arch}.deb\"\n    local build_output=$(dpkg-deb --build \"${package_dir}\" \"${TEMP_PATH}/${deb_file}\" 2&gt;&amp;1)\n    local exit_status=$?\n    echo \"${build_output}\" | log \"DEBU\"\n    if [[ ${exit_status} -ne 0 ]]; then\n      log \"ERRO\" \"Failed to build .deb package for ${APP_NAME} ${LATEST_VERSION} ${debian_arch}\"\n      app_update_failed=\"true\"\n      continue\n    fi\n\n    log \"INFO\" \"Adding ${deb_file} to reprepro...\"\n    for codename in \"${UBUNTU_CODENAMES[@]}\"; do\n      sudo reprepro -b \"${BASE_DIR}/ubuntu\" -C main includedeb \"${codename}\" \"${TEMP_PATH}/${deb_file}\" 2&gt;&amp;1 | log \"DEBU\" || true\n    done\n    for codename in \"${DEBIAN_CODENAMES[@]}\"; do\n      sudo reprepro -b \"${BASE_DIR}/debian\" -C main includedeb \"${codename}\" \"${TEMP_PATH}/${deb_file}\"  2&gt;&amp;1 | log \"DEBU\" || true\n    done\n  done\n\n  get_current_version\n  if [[ \"${LATEST_VERSION}\" != \"${CURRENT_VERSION}\" || \"${app_update_failed}\" == \"true\" ]]; then\n    log \"ERRO\" \"Failed to update ${APP_NAME} to ${LATEST_VERSION}.\"\n    FAILED_APPS+=(\"${APP_NAME}: ${LATEST_VERSION}\")\n    return 1\n  else\n    log \"INFO\" \"Successfully updated ${APP_NAME} to ${LATEST_VERSION}.\"\n    SUCCESSFUL_APPS+=(\"${APP_NAME}: ${LATEST_VERSION}\")\n    return 0\n  fi\n}\n\nfunction send_notification(){\n  if [[ \"${ENABLE_NOTIFICATIONS}\" == \"false\" ]]; then\n    log \"WARN\" \"Notifications are disabled. Skipping.\"\n    return 0\n  fi\n  if [[ -z \"${MAILRISE_URL}\" || -z \"${MAILRISE_FROM}\" || -z \"${MAILRISE_RCPT}\" ]]; then\n    log \"WARN\" \"Notification variables not set. Skipping notification.\"\n    return 1\n  fi\n  if [[ \"${APPS_OUT_OF_DATE}\" == \"false\" ]]; then\n    log \"INFO\" \"No applications were out of date. No email notification sent.\"\n    return 0\n  fi\n\n  local EMAIL_SUBJECT=\"Homelab - Update Reprepro Summary\"\n  local EMAIL_BODY=\"\"\n  if [[ \"${UPDATE_SUCCESS}\" == \"true\" ]]; then\n    EMAIL_BODY=\"All out-of-date applications were successfully updated.\"\n  else\n    EMAIL_BODY=\"Some out-of-date applications failed to update\"\n  fi\n\n  if [ ${#SUCCESSFUL_APPS[@]} -gt 0 ]; then\n    EMAIL_BODY+=$'\\n\\nSuccessfully updated:\\n'\n    for app in \"${SUCCESSFUL_APPS[@]}\"; do\n      EMAIL_BODY+=\"- ${app}\"$'\\n'\n    done\n  fi\n\n  if [ ${#FAILED_APPS[@]} -gt 0 ]; then\n    EMAIL_BODY+=$'\\n\\nFailed to update:\\n'\n    for app in \"${FAILED_APPS[@]}\"; do\n      EMAIL_BODY+=\"- ${app}\"$'\\n'\n    done\n  fi\n\n  log \"INFO\" \"Sending email notification...\"\n  curl -s \\\n    --url \"${MAILRISE_URL}\" \\\n    --mail-from \"${MAILRISE_FROM}\" \\\n    --mail-rcpt \"${MAILRISE_RCPT}\" \\\n    --upload-file - &lt;&lt;EOF\nFrom: Reprepro &lt;${MAILRISE_FROM}&gt;\nTo: Nicholas Wilde &lt;${MAILRISE_RCPT}&gt;\nSubject: ${EMAIL_SUBJECT}\n\n${EMAIL_BODY}\nEOF\n  log \"INFO\" \"Email notification sent.\"\n}\n\n# Main function to orchestrate the script execution\nfunction main() {\n  trap cleanup EXIT\n  local package_to_remove=\"\"\n\n  while [[ \"$#\" -gt 0 ]]; do\n    case $1 in\n      -d|--debug) DEBUG=\"true\"; shift;;\n      -r|--remove)\n        if [ -n \"$2\" ] &amp;&amp; [ \"${2:0:1}\" != \"-\" ]; then\n          package_to_remove=\"$2\"; shift 2;\n        else\n          log \"ERRO\" \"Error: Argument for $1 is missing\"; usage; exit 1;\n        fi;;\n      -h|--help) usage; exit 0;;\n      *) log \"ERRO\" \"Unknown parameter passed: $1\"; usage; exit 1;;\n    esac\n  done\n\n  log \"INFO\" \"Starting reprepro update script...\"\n  check_root\n\n  if [ -n \"${package_to_remove}\" ]; then\n    remove_package \"${package_to_remove}\"\n    log \"INFO\" \"Script finished.\"\n    exit 0\n  fi\n\n  check_dependencies\n  make_temp_dir\n\n  # Process apps to be packaged from source\n  if [ -z \"${PACKAGE_APPS-}\" ]; then\n    log \"WARN\" \"PACKAGE_APPS is not defined in .env. Skipping source packaging.\"\n  else\n    for app_config in \"${PACKAGE_APPS[@]}\"; do\n      IFS=':' read -r github_repo extract_type bin_name arch_regexp &lt;&lt;&lt; \"${app_config}\"\n      local app_name\n      app_name=$(basename \"${github_repo}\")\n\n      if [ -z \"${extract_type}\" ]; then extract_type=\"file\"; fi\n      if [ -z \"${bin_name}\" ]; then bin_name=\"${app_name}\"; fi\n      if [ -z \"${arch_regexp}\" ]; then arch_regexp='(?&lt;=_)[^_]+(?=\\.tar\\.gz)'; fi\n\n      update_app_from_source \"${app_name}\" \"${github_repo}\" \"${extract_type}\" \"${bin_name}\" \"${arch_regexp}\" || UPDATE_SUCCESS=\"false\"\n    done\n  fi\n\n  # Process pre-compiled deb apps\n  if [ -z \"${SYNC_APPS_GITHUB_REPOS-}\" ]; then\n    log \"WARN\" \"SYNC_APPS_GITHUB_REPOS is not defined in .env. Skipping deb sync.\"\n  else\n    for app_config in \"${SYNC_APPS_GITHUB_REPOS[@]}\"; do\n      update_app_from_deb \"${app_config}\" || UPDATE_SUCCESS=\"false\"\n    done\n  fi\n\n  update_tea || UPDATE_SUCCESS=\"false\"\n\n  send_notification\n  log \"INFO\" \"Script finished.\"\n}\n\n# Call main to start the script\nmain \"$@\"\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#package-neovim","title":"Package Neovim","text":"<p>The script <code>package-neovim.sh</code> is used to compare the latest released version of Neovim to the local version in reprepro.</p> <p>If out of date, the compressed archive is downloaded, built, packaged into a deb file.</p> <p>The reason this is separate from <code>update-reprepro.sh</code> is because dependencies need to get packaged along with the binary and an <code>armhf</code> version is not part of the release package.</p> <p>There are three ways to build the Neovim package for different architectures:</p> <ol> <li>Docker: Use <code>@pve/reprepro/docker/**</code> on the localhost to build for multiple platforms.</li> <li>Ansible: Use <code>@pve/reprepro/ansible/**</code> if you have physical machines with different architectures.</li> <li>Manual Script: Log into each machine with a different architecture and run the <code>@pve/reprepro/package-neovim.sh</code> script.</li> </ol> <p>Tip</p> <p>To get multiple architectures of the deb file, the script may be run on different architecture platforms. For instance, I use my RPi2 to build the <code>armv7l</code>, RPi5 to build the <code>arm64</code>, and HP to build the <code>amd64</code> version.</p> <p><code>homelab/pve/reprepro</code></p> TaskManual <pre><code>task package-neovim\n</code></pre> <pre><code>sudo ./package-neovim.sh\n</code></pre> package-neovim.sh <pre><code>#!/usr/bin/env bash\n################################################################################\n#\n# Script Name: package-neovim.sh\n# ----------------\n# Clones, builds, and packages the latest release of Neovim as a .deb file.\n#\n# @author Nicholas Wilde, 0xb299a622\n# @date 16 Oct 2025\n# @version 0.2.0\n#\n################################################################################\n\n# Options\n# set -e\n# set -o pipefail\n\n# These are constants\nreadonly BLUE=$(tput setaf 4)\nreadonly RED=$(tput setaf 1)\nreadonly YELLOW=$(tput setaf 3)\nreadonly PURPLE=$(tput setaf 5)\nreadonly RESET=$(tput sgr0)\nreadonly SCRIPT_DIR=$( cd -- \"$( dirname -- \"${BASH_SOURCE[0]}\" )\" &amp;&gt; /dev/null &amp;&amp; pwd )\n\n# Default variables\nDEBUG=\"false\"\n\nif [ ! -f \"${SCRIPT_DIR}/.env\" ]; then\n  echo \"ERRO[$(date +'%Y-%m-%d %H:%M:%S')] The .env file is missing. Please create it.\" &gt;&amp;2\n  exit 1\nfi\nsource \"${SCRIPT_DIR}/.env\"\n\n# Logging function\nfunction log() {\n  local type=\"$1\"\n  local color=\"$RESET\"\n\n  if [ \"${type}\" = \"DEBU\" ] &amp;&amp; [ \"${DEBUG}\" != \"true\" ]; then\n    return 0\n  fi\n\n  case \"$type\" in\n    INFO)\n      color=\"$BLUE\";;\n    WARN)\n      color=\"$YELLOW\";;\n    ERRO)\n      color=\"$RED\";;\n    DEBU)\n      color=\"$PURPLE\";;\n    *)\n      type=\"LOGS\";;\n  esac\n  if [[ -t 0 ]]; then\n    local message=\"$2\"\n    echo -e \"${color}${type}${RESET}[$(date +'%Y-%m-%d %H:%M:%S')] ${message}\"\n  else\n    while IFS= read -r line; do\n      echo -e \"${color}${type}${RESET}[$(date +'%Y-%m-%d %H:%M:%S')] ${line}\"\n    done\n  fi\n}\n\nfunction usage() {\n  cat &lt;&lt;EOF\nUsage: $0 [options]\n\nClones, builds, and packages the latest release of Neovim as a .deb file.\n\nOptions:\n  -d, --debug         Enable debug mode, which prints more info.\n  -h, --help          Display this help message.\nEOF\n}\n\n# Cleanup function to remove temporary directory\nfunction cleanup() {\n  if [ -d \"${TEMP_PATH}\" ]; then\n    log \"INFO\" \"Cleaning up temporary directory: ${TEMP_PATH}\"\n    rm -rf \"${TEMP_PATH}\"\n  fi\n}\n\n# Checks if a command exists.\nfunction command_exists() {\n  command -v \"$1\" &gt;/dev/null 2&gt;&amp;1\n}\n\nfunction check_dependencies() {\n  if ! command_exists curl || ! command_exists jq || ! command_exists git || ! command_exists make || ! command_exists cpack; then\n    log \"ERRO\" \"Required dependencies (curl, jq, git, make, cpack) are not installed.\"\n    exit 1\n  fi\n}\n\nfunction make_temp_dir(){\n  export TEMP_PATH=$(mktemp -d)\n  if [ ! -d \"${TEMP_PATH}\" ]; then\n    log \"ERRO\" \"Could not create temp dir\"\n    exit 1\n  fi\n  log \"INFO\" \"Temp path: ${TEMP_PATH}\"\n}\n\nfunction get_latest_version() {\n  local api_url=\"https://api.github.com/repos/neovim/neovim/releases/latest\"\n  local curl_args=('-s')\n  if [ -n \"${GITHUB_TOKEN}\" ]; then\n    curl_args+=('-H' \"Authorization: Bearer ${GITHUB_TOKEN}\")\n  fi\n\n  export json_response=$(curl \"${curl_args[@]}\" \"${api_url}\")\n\n  if ! echo \"${json_response}\" | jq -e '.tag_name' &gt;/dev/null 2&gt;&amp;1; then\n    log \"ERRO\" \"Failed to get latest version for neovim from GitHub API.\"\n    echo \"${json_response}\"\n    exit 1\n  fi\n\n  export TAG_NAME=$(echo \"${json_response}\" | jq -r '.tag_name')\n  log \"INFO\" \"Latest neovim version: ${TAG_NAME}\"\n}\n\nfunction main() {\n  trap cleanup EXIT\n\n  while [[ \"$#\" -gt 0 ]]; do\n    case $1 in\n      -d|--debug) DEBUG=\"true\"; shift;;\n      -h|--help) usage; exit 0;;\n      *) log \"ERRO\" \"Unknown parameter passed: $1\"; usage; exit 1;;\n    esac\n  done\n\n  log \"INFO\" \"Starting package neovim script...\"\n  check_dependencies\n  make_temp_dir\n  log \"INFO\" \"Architecture: $(dpkg --print-architecture)\"\n\n  get_latest_version\n\n  local tarball_url\n  tarball_url=$(echo \"${json_response}\" | jq -r '.tarball_url')\n  if [ -z \"${tarball_url}\" ] || [ \"${tarball_url}\" == \"null\" ]; then\n    log \"ERRO\" \"Could not find tarball URL in GitHub API response.\"\n    echo \"${json_response}\"\n    exit 1\n  fi\n\n  log \"INFO\" \"Downloading and extracting neovim version ${TAG_NAME} from ${tarball_url}\"\n  mkdir -p \"${TEMP_PATH}/neovim\"\n  curl -sL \"${tarball_url}\" | tar -xz --strip-components=1 -C \"${TEMP_PATH}/neovim\" 2&gt;&amp;1 | log \"INFO\"\n\n  cd \"${TEMP_PATH}/neovim\"\n\n  log \"INFO\" \"Building neovim...\"\n  make CMAKE_BUILD_TYPE=RelWithDebInfo 2&gt;&amp;1 | log \"INFO\"\n\n  log \"INFO\" \"Packaging neovim...\"\n  cd build\n  cpack -G DEB 2&gt;&amp;1 | log \"INFO\"\n\n  local deb_file\n  deb_file=$(find . -maxdepth 1 -name \"*.deb\")\n\n  log \"INFO\" \"Copying ${deb_file} to ${SCRIPT_DIR}\"\n  cp \"${deb_file}\" \"${SCRIPT_DIR}/\"\n\n  log \"INFO\" \"Neovim package created.\"\n  log \"INFO\" \"Debian package: ${TEMP_PATH}/neovim/build/${deb_file}\"\n  log \"INFO\" \"Script finished.\"\n}\n\nmain \"$@\"\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#package-sops","title":"Package SOPS","text":"<p>The script <code>package-sops.sh</code> is used to compare the latest released version of SOPS to the local version in reprepro.</p> <p>If out of date, the compressed archive is downloaded, built, packaged into a deb file.</p> <p>The reason this is separate from <code>update-reprepro.sh</code> is because the sops repo doesn't offer an <code>armhf</code> version and so I manually build and package the <code>armhf</code> version and add it to reprepro.</p> <p>Tip</p> <p>To get multiple architectures of the deb file, the script may be run on different architecture platforms. For instance, I use my RPi2 to build the <code>armhf</code> version.</p> <p><code>homelab/pve/reprepro</code></p> TaskManual <pre><code>task package-sops\n</code></pre> <pre><code>sudo ./package-sops.sh\n</code></pre> package-sops.sh <pre><code>#!/usr/bin/env bash\n################################################################################\n#\n# Script Name: package-sops.sh\n# ----------------\n# Clones, builds, and packages the latest release of sops as a .deb file.\n#\n# @author Nicholas Wilde, 0xb299a622\n# @date 17 Oct 2025\n# @version 0.2.0\n#\n################################################################################\n\n# set -e\n# set -o pipefail\n\n# Constants\nreadonly BLUE=$(tput setaf 4)\nreadonly RED=$(tput setaf 1)\nreadonly YELLOW=$(tput setaf 3)\nreadonly RESET=$(tput sgr0)\nreadonly SCRIPT_DIR=$( cd -- \"$( dirname -- \"${BASH_SOURCE[0]}\" )\" &amp;&gt; /dev/null &amp;&amp; pwd )\n\n# Logging function\nfunction log() {\n  local type=\"$1\"\n  # local message=\"$2\"\n  local color=\"$RESET\"\n\n  case \"$type\" in\n    INFO)\n      color=\"$BLUE\";;\n    WARN)\n      color=\"$YELLOW\";;\n    ERRO)\n      color=\"$RED\";;\n    # Add a default case for other types\n    *)\n      type=\"LOGS\";;\n  esac\n  if [[ -t 0 ]]; then\n    local message=\"$2\"\n    echo -e \"${color}${type}${RESET}[$(date +'%Y-%m-%d %H:%M:%S')] ${message}\"\n  else\n    while IFS= read -r line; do\n      echo -e \"${color}${type}${RESET}[$(date +'%Y-%m-%d %H:%M:%S')] ${line}\"\n    done\n  fi\n}\n\n# Cleanup function to remove temporary directory\nfunction cleanup() {\n  if [ -d \"${TEMP_PATH}\" ]; then\n    log \"INFO\" \"Cleaning up temporary directory: ${TEMP_PATH}\"\n    rm -rf \"${TEMP_PATH}\"\n  fi\n}\n\nfunction make_temp_dir(){\n  export TEMP_PATH=$(mktemp -d)\n  if [ ! -d \"${TEMP_PATH}\" ]; then\n    log \"ERRO\" \"Could not create temp dir\"\n    exit 1\n  fi\n  log \"INFO\" \"Temp path: ${TEMP_PATH}\"\n}\n\nfunction get_latest_version() {\n  local api_url=\"https://api.github.com/repos/getsops/sops/releases/latest\"\n  local curl_args=('-s')\n  if [ -n \"${GITHUB_TOKEN}\" ]; then\n    curl_args+=('-H' \"Authorization: Bearer ${GITHUB_TOKEN}\")\n  fi\n\n  export json_response=$(curl \"${curl_args[@]}\" \"${api_url}\")\n\n  if ! echo \"${json_response}\" | jq -e '.tag_name' &gt;/dev/null 2&gt;&amp;1; then\n    log \"ERRO\" \"Failed to get latest version for sops from GitHub API.\"\n    echo \"${json_response}\"\n    exit 1\n  fi\n\n  export TAG_NAME=$(echo \"${json_response}\" | jq -r '.tag_name')\n  export LATEST_VERSION=${TAG_NAME#v}\n  log \"INFO\" \"Latest sops version: ${LATEST_VERSION} (tag: ${TAG_NAME})\"\n}\n\nfunction get_description() {\n  export DESCRIPTION\n  DESCRIPTION=$(curl -s \"https://api.github.com/repos/getsops/sops\" | jq -r '.description' | sed -e 's/:\\w\\+://g' -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')\n}\n\nfunction check_dependencies() {\n  log \"INFO\" \"Checking for dependencies...\"\n  if command -v go &amp;&gt; /dev/null; then\n    export GO_CMD=$(command -v go)\n  else\n    log \"WARN\" \"Go not found in PATH. Searching common locations...\"\n    local go_executable=\"\"\n    if [ -x \"/usr/local/go/bin/go\" ]; then\n      go_executable=\"/usr/local/go/bin/go\"\n    elif [ -n \"$SUDO_USER\" ]; then\n      local user_home\n      user_home=$(getent passwd \"$SUDO_USER\" | cut -d: -f6)\n      if [ -x \"${user_home}/go/bin/go\" ]; then\n        go_executable=\"${user_home}/go/bin/go\"\n      fi\n    fi\n\n    if [ -n \"${go_executable}\" ]; then\n      log \"INFO\" \"Found go at ${go_executable}.\"\n      export GO_CMD=\"${go_executable}\"\n      export PATH=\"$(dirname \"${go_executable}\"):${PATH}\"\n    else\n      log \"ERRO\" \"Go is not installed or couldn't be found. Please install Go.\"\n      exit 1\n    fi\n  fi\n  if ! command -v dpkg-deb &amp;&gt; /dev/null; then\n    log \"ERRO\" \"dpkg-deb is not installed. Please install it.\"\n    exit 1\n  fi\n  if ! command -v jq &amp;&gt; /dev/null; then\n    log \"ERRO\" \"jq is not installed. Please install jq.\"\n    exit 1\n  fi\n  log \"INFO\" \"All dependencies are installed.\"\n}\n\nfunction check_root(){\n  if [ \"$UID\" -ne 0 ]; then\n    log \"ERRO\" \"Please run as root or with sudo.\"\n    exit 1\n  fi\n}\n\nfunction main() {\n    trap cleanup EXIT\n    check_root\n    check_dependencies\n    make_temp_dir\n    log \"INFO\" \"Starting package sops script...\"\n    log \"INFO\" \"Building for architecture: armhf\"\n\n    get_latest_version\n    get_description\n\n    local tarball_url\n    tarball_url=$(echo \"${json_response}\" | jq -r '.tarball_url')\n    if [ -z \"${tarball_url}\" ] || [ \"${tarball_url}\" == \"null\" ]; then\n      log \"ERRO\" \"Could not find tarball URL in GitHub API response.\"\n      echo \"${json_response}\"\n      exit 1\n    fi\n\n    log \"INFO\" \"Downloading and extracting sops version ${TAG_NAME} from ${tarball_url}\"\n    mkdir -p \"${TEMP_PATH}/sops\"\n    curl -sL \"${tarball_url}\" | tar -xz --strip-components=1 -C \"${TEMP_PATH}/sops\" 2&gt;&amp;1 | log \"INFO\"\n\n    cd \"${TEMP_PATH}/sops\"\n\n    log \"INFO\" \"Building sops for armhf...\"\n    GOOS=linux GOARCH=arm ${GO_CMD} build ./cmd/sops 2&gt;&amp;1 | log \"INFO\"\n\n    local arch_debian=\"armhf\"\n    local package_dir=\"${TEMP_PATH}/sops_${LATEST_VERSION}_${arch_debian}\"\n    mkdir -p \"${package_dir}/usr/local/bin\"\n    mkdir -p \"${package_dir}/DEBIAN\"\n\n    mv sops \"${package_dir}/usr/local/bin/\"\n\n    log \"INFO\" \"Creating control file...\"\n    cat &lt;&lt; EOF &gt; \"${package_dir}/DEBIAN/control\"\nPackage: sops\nVersion: ${LATEST_VERSION}\nSection: utils\nPriority: optional\nArchitecture: ${arch_debian}\nMaintainer: Nicholas Wilde &lt;noreply@email.com&gt;\nDescription: ${DESCRIPTION}\nEOF\n\n    log \"INFO\" \"Building .deb package...\"\n    local deb_file=\"sops_${LATEST_VERSION}_${arch_debian}.deb\"\n    if ! dpkg-deb --build \"${package_dir}\" \"${TEMP_PATH}/${deb_file}\"; then\n        log \"ERRO\" \"Failed to build .deb package for sops ${LATEST_VERSION} ${arch_debian}\"\n        exit 1\n    fi\n\n    log \"INFO\" \"Copying ${deb_file} to ${SCRIPT_DIR}\"\n    cp \"${TEMP_PATH}/${deb_file}\" \"${SCRIPT_DIR}/\"\n\n    log \"INFO\" \"Sops package created: ${SCRIPT_DIR}/${deb_file##*/}\"\n}\n\nmain \"$@\"\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#upload-deb-files","title":"Upload Deb Files","text":"<p>Once the neovim or sops deb files are built, they are copied to the current <code>pve/reprepro</code> folder. The <code>upload-debs</code> task can then be used to push the deb files to the reprepro LXC using <code>scp</code>.</p> <p>The <code>REMOTE_IP</code>, <code>REMOTE_USER</code>, and <code>REMOTE_PATH</code> variables in the <code>.env</code> file are used to specify the reprepro LXC.</p> <pre><code>task upload-debs\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#script-notifications","title":"Script Notifications","text":"<p>Some scripts can send notifications via Mailrise.</p> <p>Set the <code>MAILRISE_*</code> variables and the <code>ENABLE_NOTIFICATIONS</code> variable in the <code>.env</code> file.</p>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#cronjob","title":"Cronjob","text":"<p>A cronjob can be setup to run every night to check the released versions.</p> <p>2 A.M. nightly</p> AutomaticManual <pre><code>(crontab -l 2&gt;/dev/null; echo \"0 2 * * * /root/git/nicholaswilde/homelab/pve/reprepro/update-reprepro.sh\") | crontab -\n</code></pre> <pre><code>crontab -e\n</code></pre> <pre><code>0 2 * * * /root/git/nicholaswilde/homelab/pve/reprepro/update-reprepro.sh\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/reprepro.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    reprepro:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`deb.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: reprepro\n#endregion\n#region services\n  services:\n    reprepro:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.32\"\n        passHostHeader: true\n# #endregion\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* bootstrap:                  Bootstrap the reprepro environment\n* build-lnav:                 Build lnav\n* clear:                      Remove all packages from all distributions\n* decrypt:                    Decrypt sensitive configuration files using SOPS.\n* deps:                       Install dependencies\n* deps-lnav:                  Install lnav dependencies\n* dirs:                       Create reprepro directories\n* download:                   Download SOPS and Task .deb files\n* encrypt:                    Encrypt sensitive configuration files using SOPS.\n* export:                     Export the task list\n* init:                       Initialize the application's environment and configuration files.\n* list:                       List all packages in all distributions\n* nuke:                       Nuke the packages\n* package-lastpass-cli:       Package the latest lastpass-cli release\n* package-neovim:             Package the latest neovim release\n* package-sops:               Package the latest sops release\n* symlinks:                   Create reprepro symlinks\n* update-reprepro:            Downloads application tar.gz and .deb files, packages them as needed, and adds them to a reprepro repository.\n* upload-debs:                Upload the deb packages to a remote server\n</code></pre>","tags":["lxc","proxmox","debian"]},{"location":"apps/reprepro/#references","title":"References","text":"<ul> <li>https://santi-bassett.blogspot.com/2014/07/setting-up-apt-repository-with-reprepro.html?m=1</li> <li>https://wiki.debian.org/DebianRepository/SetupWithReprepro</li> <li>https://wikitech.wikimedia.org/wiki/Reprepro</li> </ul>","tags":["lxc","proxmox","debian"]},{"location":"apps/stirling-pdf/","title":"Stirling PDF","text":"<p>Stirling PDF is a locally hosted web application that allows you to perform various operations on PDF files.</p>","tags":["lxc","proxmox"]},{"location":"apps/stirling-pdf/#installation","title":"Installation","text":"<p> Default Port: <code>8080</code></p> <p> Configuration path: <code>/opt/Stirling-PDF/.env</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/stirling-pdf.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/stirling-pdf.sh)\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/stirling-pdf/#config","title":"Config","text":"<p>Make symlinks to repo.</p>","tags":["lxc","proxmox"]},{"location":"apps/stirling-pdf/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* enable:        Enable service\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Resart service\n* start:         Start service\n* status:        Service status\n* stop:          Stop service\n* upgrade:       upgrade\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/stirling-pdf/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=stirling-pdf</li> <li>https://pimox-scripts.com/scripts?id=stirling-pdf</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/traefik/","title":"Traefik","text":"<p>Traefik is used as my reverse proxy.</p>","tags":["proxmox","lxc"]},{"location":"apps/traefik/#installation","title":"Installation","text":"<p> Default Port: <code>80</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/traefik.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/{{ app_name | lower }}.sh)\"\nbash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/traefik.sh)\"\n</code></pre>","tags":["proxmox","lxc"]},{"location":"apps/traefik/#config","title":"Config","text":"<p>All internal URLs use an <code>l</code> sub domain so that only one certificate is needed from letsencrypt. E.g. <code>https://app.l.nicholaswilde.io/</code></p> <p>Note</p> <p>Paths in config file should be absolute.</p>","tags":["proxmox","lxc"]},{"location":"apps/traefik/#service","title":"Service","text":"<p><code>/etc/systemd/system/traefik.service</code></p> AutomaticDownloadManual <pre><code>cat &gt; /etc/systemd/system/traefik.service &lt;&lt;EOF\n[Unit]\nDescription=Traefik is an open-source Edge Router that makes publishing your services a fun and easy experience\n\n[Service]\nType=notify\nEnvironmentFile=/root/git/nicholaswilde/homelab/pve/traefik/.env\nExecStart=/usr/bin/traefik --configFile=/root/git/nicholaswilde/homelab/pve/traefik/traefik.yaml\nRestart=on-failure\nExecReload=/bin/kill -USR1 $MAINPID\n\n[Install]\nWantedBy=multi-user.target\n\nEOF\n</code></pre> <pre><code>wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/traefik/traefik.service -O /etc/systemd/system/traefik.service\n</code></pre> <pre><code>[Unit]\nDescription=Traefik is an open-source Edge Router that makes publishing your services a fun and easy experience\n\n[Service]\nType=notify\nEnvironmentFile=/root/git/nicholaswilde/homelab/pve/traefik/.env\nExecStart=/usr/bin/traefik --configFile=/root/git/nicholaswilde/homelab/pve/traefik/traefik.yaml\nRestart=on-failure\nExecReload=/bin/kill -USR1 $MAINPID\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Enable service</p> Manual <pre><code>(\n systemctl enable traefik.service &amp;&amp; \\\n systemctl start traefik.service &amp;&amp; \\\n systemctl status traefik.service\n) \n</code></pre> <code>homelab/pve/traefik/traefik.yaml</code> <pre><code>---\nproviders:\n  file:\n    filename: /root/git/nicholaswilde/homelab/pve/traefik/middlewares.yaml\n    directory: /root/git/nicholaswilde/homelab/pve/traefik/conf.d/\n    watch: true\n\nentryPoints:\n  web:\n    address: ':80'\n    http:\n      redirections:\n        entryPoint:\n          to: websecure\n          scheme: https\n  websecure:\n    address: ':443'\n    http:\n      tls:\n        certResolver: cloudflare\n  traefik:\n    address: ':8080'\n  # mailsecure:\n    # address: ':465'\n\ncertificatesResolvers:\n  cloudflare:\n    acme:\n      email: ncwilde43@gmail.com\n      storage: /root/git/nicholaswilde/homelab/pve/traefik/ssl/acme.json\n      caServer: https://acme-v02.api.letsencrypt.org/directory # prod (default)\n      # caServer: https://acme-staging-v02.api.letsencrypt.org/directory # staging\n      dnsChallenge:\n        provider: cloudflare\n        #disablePropagationCheck: true # uncomment this if you have issues pulling certificates through cloudflare, By setting this flag to true disables the need to wait for the propagation of the TXT record to all authoritative name servers.\n        delayBeforeCheck: 60s # uncomment along with disablePropagationCheck if needed to ensure the TXT record is ready before verification is attempted \n        resolvers:\n          - \"1.1.1.1:53\"\n          - \"1.0.0.1:53\"\n  # letsencrypt:\n    # acme:\n      # email: \"ncwilde43@gmail.com\"\n      # storage: /etc/traefik/ssl/acme.json\n      # tlsChallenge: {}\n\nserversTransport:\n  insecureSkipVerify: true\n\napi:\n  dashboard: true\n  insecure: true\n  debug: true\n\nlog:\n  filePath: /var/log/traefik/traefik.log\n  format: common\n  level: INFO\n\naccessLog:\n  filePath: /var/log/traefik/traefik-access.log\n  format: json\n  filters:\n    statusCodes:\n      - \"200\"\n      - \"400-599\"\n    retryAttempts: true\n    minDuration: \"10ms\"\n  bufferingSize: 0\n  fields:\n    headers:\n      defaultMode: drop\n      names:\n        User-Agent: keep\n</code></pre> <code>homelab/pve/traefik/conf.d/config.yaml</code> <pre><code>---\nhttp:\n  routers:\n    traefik:\n      entrypoints:\n        - web\n      rule: Host(`traefik.l.nicholaswilde.io`)\n      middlewares: traefik-https-redirect\n      service: api@internal\n    traefik-secure:\n      entrypoints:\n        - websecure\n      rule: Host(`traefik.l.nicholaswilde.io`)\n      # middlewares: traefik-auth\n      tls:\n        certresolver: cloudflare\n        domains:\n          - main: l.nicholaswilde.io\n            sans: \n              - '*.l.nicholaswilde.io'\n      service: api@internal\n\n  middlewares:\n    # traefik-auth:\n      # basicAuth:\n        # users: ${TRAEFIK_DASHBOARD_CREDENTIALS}\n    traefik-https-redirect:\n      redirectScheme:\n        scheme: https\n    sslheader:\n      headers:\n        customRequestHeaders:\n          X-Forwarded-Proto: https\n</code></pre>","tags":["proxmox","lxc"]},{"location":"apps/traefik/#usage","title":"Usage","text":"<p>Create new config for app</p> <p><code>homelab/pve/traefik/conf.d/</code></p> TaskManual <pre><code>APP_NAME=AppName task new &gt; appname.yaml\n</code></pre> <pre><code>jinja2 -D APP_NAME=AppName .template.yaml.j2 &gt; appname.yaml\n</code></pre> <p>Edit config file</p> <p>Restart traefik</p> <p><code>homelab/pve/traefik/conf.d/</code></p> TaskManual <pre><code>task restart\n</code></pre> <pre><code>systemctl restart traefik.service\n</code></pre> <p>Test URL</p> <p>Comment out middleware in config file</p> <p>Restart traefik</p> <p>Test URL</p> <p>Remove middleware or uncomment middleware</p> <p>Restart traefik</p>","tags":["proxmox","lxc"]},{"location":"apps/traefik/#logs","title":"Logs","text":"<p><code>/var/log/traefik/traefik.log</code></p> TaskManual <pre><code>task logs\n</code></pre> <pre><code>tail -n10 /var/log/traefik/traefik.log\n</code></pre>","tags":["proxmox","lxc"]},{"location":"apps/traefik/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* export:        Export the task list\n* new:           Create a new config file\n* restart:       Restart Traefik\n* status:        View the Traefik service status\n* update:        Update running containers\n* watch:         Watch the log file\n</code></pre>","tags":["proxmox","lxc"]},{"location":"apps/traefik/#references","title":"References","text":"","tags":["proxmox","lxc"]},{"location":"apps/unbound/","title":"Unbound","text":"<p>Unbound is used as a recursive DNS resolver and cacher.</p>","tags":["lxc","proxmox"]},{"location":"apps/unbound/#installation","title":"Installation","text":"<p> Default Port: <code>5335</code></p> <p> Configuration path: <code>/etc/unbound/unbound.conf.d/unbound.conf</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/unbound.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/unbound.sh)\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/unbound/#config","title":"Config","text":"<p><code>/etc/unbound/unbound.conf.d/unbound.conf</code></p> Manual <pre><code>server:\n  interface: 0.0.0.0\n  port: 5335\n  do-ip6: no\n  hide-identity: yes\n  hide-version: yes\n  harden-referral-path: yes\n  cache-min-ttl: 300\n  cache-max-ttl: 14400\n  serve-expired: yes\n  serve-expired-ttl: 3600\n  prefetch: yes\n  prefetch-key: yes\n  target-fetch-policy: \"3 2 1 1 1\"\n  unwanted-reply-threshold: 10000000\n  rrset-cache-size: 256m\n  msg-cache-size: 128m\n  so-rcvbuf: 1m\n  private-address: 192.168.0.0/16\n  private-address: 169.254.0.0/16\n  private-address: 172.16.0.0/12\n  private-address: 10.0.0.0/8\n  private-address: fd00::/8\n  private-address: fe80::/10\n  access-control: 192.168.0.0/16 allow\n  access-control: 172.16.0.0/12 allow\n  access-control: 10.0.0.0/8 allow\n  access-control: 127.0.0.1/32 allow\n  chroot: \"\"\n  logfile: /var/log/unbound.log\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/unbound/#adguard-home","title":"AdGuard Home","text":"<p>Upstream DNS Servers: <code>192.168.2.23:5335</code></p> <p>Disable Cache Size</p> <p>Disable DNSSEC</p>","tags":["lxc","proxmox"]},{"location":"apps/unbound/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make symlinks\n* restart:       Restart service\n* status:        Check service status\n* stop:          Stop service\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/unbound/#references","title":"References","text":"<ul> <li>https://medium.com/@life-is-short-so-enjoy-it/homelab-adguard-setup-unbound-as-iterative-dns-6048d5072276</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden-backup/","title":"vaultwarden-backup","text":"<p>vaultwarden-backup is an automated setup for SQLite-based Vaultwarden backups. It's designed solely to meet my own backup requirements (i.e., not to be general purpose).</p>","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden-backup/#installation","title":"Installation","text":"<p> Configuration path: <code>/opt/vaultwarden/backup</code></p> <pre><code>(\n  cd /opt/vaultwarden\n  git clone https://github.com/jjlin/vaultwarden-backup.git backup\n)\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden-backup/#config","title":"Config","text":"<ol> <li> <p>Generate a single archive with a complete backup of all Vaultwarden data    and config on a configurable schedule.</p> </li> <li> <p>Retain backup archives on the local Vaultwarden host for a configurable    number of days.</p> </li> <li> <p>Upload encrypted copies of the backup archives to one or more cloud    storage services using rclone. The retention policy    is configured/managed at the storage service level.</p> </li> <li> <p>Return success when all backup archives are successfully uploaded,    or failure if any uploads fail. This allows cron monitoring services like    Healthchecks.io, Cronitor,    or Dead Man\u2019s Snitch to provide notification    of backup failures.</p> </li> </ol> <p>Note</p> <p>This single-archive backup scheme isn't space-efficient if your vault includes large file attachments, as they will be re-uploaded with each backup. If this is an issue, you might consider modifying the script to use restic instead.</p>","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden-backup/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>A standard Unix-like (preferably Linux) host running Vaultwarden. I don't    know much about Synology or other such environments.</p> </li> <li> <p>A cron daemon. This is used to run    backup actions on a scheduled basis.</p> </li> <li> <p>An <code>sqlite3</code> binary (https://sqlite.org/cli.html). This is used to back up    the SQLite database. This can be installed via the <code>sqlite3</code> package on    Debian/Ubuntu or the <code>sqlite</code> package on RHEL/CentOS/Fedora.</p> </li> <li> <p>An <code>rclone</code> binary (https://rclone.org/). This is used to copy the backup    archives to cloud storage. This can be installed via the <code>rclone</code> package    on Debian/Ubuntu and RHEL/CentOS/Fedora (EPEL    required for RHEL/CentOS), but as rclone changes more rapidly, it's probably    best to just use the latest binary from https://rclone.org/downloads/.</p> </li> <li> <p>An account at one or more cloud storage services    supported by rclone. If you don't have one    yet, here are a few cloud storage services that offer a free tier:</p> </li> <li> <p>Backblaze B2 (10 GB)</p> </li> <li>Box (10 GB)</li> <li>Cloudflare R2 (10 GB)</li> <li>Dropbox (2 GB)</li> <li>Google Drive (15 GB)</li> <li>Microsoft OneDrive (5 GB)</li> <li> <p>Oracle Cloud (10 GB)</p> </li> <li> <p>Optionally, a <code>gpg</code> (GnuPG 2.x) binary (https://gnupg.org/). This can be    installed via the <code>gnupg</code> package on Debian/Ubuntu or the <code>gnupg2</code> package    on RHEL/CentOS/Fedora.</p> </li> <li> <p>Optionally, an <code>age</code> binary (https://github.com/FiloSottile/age). This option    requires a custom version    of the tool that supports reading the passphrase from an environment variable.</p> </li> </ol>","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden-backup/#usage","title":"Usage","text":"<ol> <li> <p>Start by cloning this repo to the directory containing your Vaultwarden    data directory, under the name <code>backup</code>. In my setup, it looks like this:</p> <pre><code> /opt/vaultwarden  # Top-level Vaultwarden directory\n \u251c\u2500\u2500 backup         # This backup repo\n \u2514\u2500\u2500 data           # Vaultwarden data directory\n</code></pre> </li> <li> <p>Copy the <code>backup.conf.template</code> file to <code>backup.conf</code>.</p> </li> <li> <p>If you want encrypted backup archives using <code>gpg</code>, set the       <code>GPG_PASSPHRASE</code> variable accordingly. If you want to encrypt using       <code>age</code> instead, set the <code>AGE_PASSPHRASE</code> variable. If both variables are       set, only <code>gpg</code> encryption will be performed. If you don't want       encryption at all, comment out both variables or set them to be blank.</p> <p>This passphrase is used to encrypt the backup archives, which may   contain somewhat sensitive data in plaintext in <code>config.json</code> (the   password entries themselves are already encrypted by Bitwarden). It   should be something easy enough for you to remember, but complex enough   to deter, for example, any unscrupulous cloud storage personnel who   might be snooping around. As this passphrase is stored on disk in   plaintext, it definitely should not be your Bitwarden master passphrase   or anything similar.</p> <p>rclone crypt is another option for encrypted   archives. If you prefer to use this method, just set <code>GPG_PASSPHRASE</code> to   be blank, configure rclone crypt appropriately, and use the crypt remote   in <code>RCLONE_DESTS</code>.</p> </li> <li> <p>Change <code>RCLONE_DESTS</code> to your list of rclone destinations. You'll have       to configure rclone appropriately first.</p> </li> <li> <p>Note that <code>backup.conf</code> is simply sourced into the <code>backup.sh</code> script, so       you can add arbitrary environment variables into <code>backup.conf</code> as needed.       This can be useful for configuring any tools called from <code>backup.sh</code>,       such as <code>rclone</code>.</p> </li> <li> <p>Modify the <code>backup/crontab.template</code> file as needed. This crontab actually    calls <code>cron.sh</code> to run the backup, rather than calling <code>backup.sh</code> directly.    Currently, <code>cron.sh</code> captures the output of the current run of <code>backup.sh</code>    to a <code>backup.log</code> file. It also saves a copy of this log file, named    according to whether the backup run was a success or failure. You can add    other custom logic to <code>cron.sh</code> if needed, such as signaling failure to a    cron monitoring service.</p> </li> <li> <p>If <code>$HOME/vaultwarden</code> isn't your top-level Vaultwarden directory, adjust       the paths in this file accordingly.</p> </li> <li> <p>Review the backup schedule. I generate backup archives hourly, but you       might prefer to do this less frequently to save space.</p> </li> <li> <p>Review the local backup archive retention policy. I delete archives       older than 14 days (<code>-mtime +14</code>). Adjust this if needed.</p> </li> <li> <p>Review the log file retention policy. I delete log files older than       14 days (<code>-mtime +14</code>). Adjust this if needed.</p> </li> <li> <p>Review the SQLite VACUUM schedule,       or remove the job if you don't want vacuuming. Vacuuming compacts the       database file so that operations are faster and backups are smaller.</p> </li> <li> <p>Install the crontab under a user (typically your normal login) that can    read your Vaultwarden data. In many cases, running <code>crontab -e</code> and pasting    the contents of the filled-in crontab template file should work. Note that    if your cron user doesn't have write permissions to the database, then you    must ensure it has write permissions to the Vaultwarden data directory,    as SQLite may need to create a <code>-wal</code> file for the database if it doesn't    already exist. If it's unable to do this, the backup will fail with an    <code>attempt to write a readonly database</code> error. (For more details, see    https://sqlite.org/wal.html#read_only_databases.)</p> </li> <li> <p>If you use GnuPG 2.1 or later, see the note about <code>--pinentry-mode loopback</code>    in <code>backup.sh</code>.</p> </li> </ol> <p>If everything is working properly, you should see the following:</p> <ol> <li>Backup archives generated under <code>backup/archives</code>.</li> <li>Encrypted backup archives uploaded to your configured rclone destination(s).</li> <li>A log of the last backup at <code>backup/backup.log</code>.</li> <li>Copies of the backup logs saved to <code>backup/logs</code>.</li> </ol> <p>For example</p> <pre><code>/opt/vaultwarden/backup\n\u251c\u2500\u2500 archives\n\u2502   \u251c\u2500\u2500 vaultwarden-20210101-0000.tar.xz\n\u2502   \u251c\u2500\u2500 vaultwarden-20210101-0000.tar.xz.gpg\n\u2502   \u251c\u2500\u2500 vaultwarden-20210101-0100.tar.xz\n\u2502   \u251c\u2500\u2500 vaultwarden-20210101-0100.tar.xz.gpg\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 backup.conf\n\u251c\u2500\u2500 backup.conf.template\n\u251c\u2500\u2500 backup.log\n\u251c\u2500\u2500 backup.sh\n\u251c\u2500\u2500 cron.sh\n\u251c\u2500\u2500 crontab.template\n\u251c\u2500\u2500 logs\n\u2502   \u251c\u2500\u2500 backup-success-20210101-0000.log\n\u2502   \u251c\u2500\u2500 backup-success-20210101-0100.log\n\u2502   \u251c\u2500\u2500 backup-failure-20210101-0200.log\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 LICENSE\n\u2514\u2500\u2500 README.md\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden-backup/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt backup.conf using SOPS\n* enable:        Enable service\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make symlinks to backup.conf\n* restart:       Resart service\n* start:         Start service\n* status:        Service status\n* stop:          Stop service\n* update:        Update running containers\n* upgrade:       upgrade\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden-backup/#references","title":"References","text":"<ul> <li>https://github.com/jjlin/vaultwarden-backup</li> <li>https://rclone.org/remote_setup/</li> <li>https://rclone.org/drive/</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden/","title":"Vaultwarden","text":"","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden/#installation","title":"Installation","text":"<p> Default Port: <code>8000</code></p> <p>Vaultwarden</p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/vaultwarden.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/vaultwarden.sh)\"\n</code></pre> <p>bw cli</p> Installer <pre><code>(\n  curl -s https://installer.l.nicholaswilde.io/bitwarden/clients! | bash\n  mv /usr/local/bin/clients /usr/local/bin/bw\n)\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden/#config","title":"Config","text":"<p>Connect to self-hosted server</p> <pre><code>bw config server https://vault.l.nicholaswilde.io\n</code></pre> <p>Authorize via API</p> <pre><code>bw login --apikey\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt .env using SOPS\n* enable:        Enable service\n* encrypt:       Encrypt .env using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make client symlinks\n* restart:       Resart service\n* start:         Start service\n* status:        Service status\n* stop:          Stop service\n* upgrade:       upgrade\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden/#usage","title":"Usage","text":"<p>Create Attachment</p> <pre><code>bw create attachment --file ./path/to/file --itemid 16b15b89-65b3-4639-ad2a-95052a6d8f66\n</code></pre> <p>Tip</p> <p>If you don\u2019t know the exact <code>itemid</code> you want to use, use <code>bw get item &lt;search-term&gt;</code> to return the item, including its <code>id</code>.</p> <p>Get Attachment</p> <pre><code>bw get attachment photo.png --itemid 99ee88d2-6046-4ea7-92c2-acac464b1412 --output /Users/myaccount/Pictures/\n</code></pre> <p>Note</p> <p>When using <code>--output</code>, the path must end a forward slash (/) to specify a directory or a filename (<code>/Users/myaccount/Pictures/photo.png</code>).</p>","tags":["lxc","proxmox"]},{"location":"apps/vaultwarden/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=vaultwarden</li> <li>https://pimox-scripts.com/scripts?id=Vaultwarden</li> <li>https://bitwarden.com/help/cli/</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/ventoy/","title":"Ventoy","text":"<p>Ventoy is used as an app to serve multipe ISOs on a bootable USB drive. The drive is consistently plugged into the node and updated automatically using <code>cp -u</code>. It is meant to be synchronized with ISOs saved in Proxmox or downloaded via qTorrent.</p> <p>The way that it works is that an NFS share and USB drive are mounted using autofs. A cronjob is run nightly to sync the ISO files on the NFS with the thumb drive.</p> <p>Warning</p> <p>Continuous writes to USB drives will degrade the life of the drive.</p>","tags":["lxc","proxmox"]},{"location":"apps/ventoy/#installation","title":"Installation","text":"<p> Default Port: <code>24680</code></p> <p> Configuration path: <code>/opt/ventoy</code> </p> <p> .env: <code>true</code></p> <p><code>homelab/pve/ventoy/install.sh</code></p> Taskrootsudo <pre><code>task install\n</code></pre> <pre><code>./install.sh\n</code></pre> <pre><code>sudo ./install.sh\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/ventoy/#config","title":"Config","text":"<p>.env</p> TemplateManual <pre><code>cp .env.tmpl .env\nnano .env\n</code></pre> <pre><code>VENTOY_HOST=0.0.0.0\nVENTOY_MNT=/mnt/usb\nVENTOY_USB=/dev/disk/by-id/usb-USB_SanDisk_3.2Gen1_04019ebb9045b2187b4c68fdf6daa1ba6507f9ffa0329ae0dc9c496da45564b4c2550000000000000000000066a6801d000fb41883558107952c0477-0:0-part1\nVENTOY_DEST=/mnt/usb\nVENTOY_SOURCE=/mnt/storage/downloads\nVENTOY_INSTALL_DIR=/opt/ventoy\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/ventoy/#service","title":"Service","text":"<p>/etc/systemd/system/ventoy.service</p> AutomaticDownloadManual <pre><code>cat &gt; /etc/systemd/system/ventoy.service &lt;&lt;EOF\n[Unit]\nDescription=Ventoy Web Service\nAfter=network-online.target\n\n[Service]\nType=simple\nUser=root\nWorkingDirectory=/opt/ventoy\nEnvironmentFile=/root/git/nicholaswilde/homelab/pve/ventoy/.env\nExecStart=/opt/ventoy/VentoyWeb.sh -H ${VENTOY_HOST}\nRestart=always\nExecReload=/bin/kill -USR1 $MAINPID\n\n[Install]\nWantedBy=multi-user.target\n\nEOF\n</code></pre> <pre><code>wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/ventoy/ventoy.service -O /etc/systemd/system/ventoy.service\n</code></pre> <pre><code>[Unit]\nDescription=Ventoy Web Service\nAfter=network-online.target\n\n[Service]\nType=simple\nUser=root\nWorkingDirectory=/opt/ventoy\nEnvironmentFile=/root/git/nicholaswilde/homelab/pve/ventoy/.env\nExecStart=/opt/ventoy/VentoyWeb.sh -H ${VENTOY_HOST}\nRestart=always\nExecReload=/bin/kill -USR1 $MAINPID\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Enable service</p> Manual <pre><code>(\n systemctl enable ventoy.service &amp;&amp; \\\n systemctl start ventoy.service &amp;&amp; \\\n systemctl status ventoy.service\n) \n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/ventoy/#cronjob","title":"Cronjob","text":"<p>2 A.M. nightly</p> AutomaticManual <pre><code>(crontab -l 2&gt;/dev/null; echo \"0 2 * * * find /mnt/storage/downloads -type f -name \\\"*.iso\\\" -exec cp -u {} /mnt/usb \\;  &gt;/dev/null 2&gt;&amp;1\") | crontab -\n</code></pre> <pre><code>  crontab -e\n</code></pre> <pre><code>0 2 * * * find /mnt/storage/downloads -type f -name \\\"*.iso\\\" -exec cp -u {} /mnt/usb \\;  &gt;/dev/null 2&gt;&amp;1\"\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/ventoy/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/ventoy.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    ventoy:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`ventoy.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: ventoy\n#endregion\n#region services\n  services:\n    ventoy:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.70:24680\"\n        passHostHeader: true\n#endregion\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/ventoy/#usage","title":"Usage","text":"<p>The app may be installed and updated on the USB drive via the web app.</p> <p>Start web server</p> TaskManual <pre><code>task serve\n</code></pre> <pre><code>(\n  cd /opt/ventoy &amp;&amp; \\\n  sudo bash -c bash VentoyWeb.sh -H \"0.0.0.0\"\n)\n</code></pre> <p>Sync ISOs</p> TaskManual <pre><code>task sync\n</code></pre> <pre><code>find /mnt/storage/downloads -type f -name \\\"*.iso\\\" -exec cp -u {} /mnt/usb \\;\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/ventoy/#upgrade","title":"Upgrade","text":"Task <pre><code>task update\n</code></pre> <p>Then update the USB drive from the Web GUI.</p>","tags":["lxc","proxmox"]},{"location":"apps/ventoy/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* cron:          Setup cron job\n* deps:          Install dependencies\n* export:        Export the task list\n* install:       Install Ventoy\n* mount:         Mount USB\n* remove:        Remove Ventoy\n* restart:       Restart Ventoy\n* serve:         Start web server\n* start:         Restart Ventoy\n* stop:          Stop Ventoy\n* sync:          Sync ISO images with USB drive\n* umount:        Unmount USB\n* up:            Start web server\n* update:        Update Ventoy\n</code></pre>","tags":["lxc","proxmox"]},{"location":"apps/ventoy/#references","title":"References","text":"<ul> <li>https://www.ventoy.net/en/index.html</li> </ul>","tags":["lxc","proxmox"]},{"location":"apps/w11/","title":"Windows 11","text":"<p>Windows 11 is installed as a Proxmox VM on my NUC. I remote into it using Apache Guacamole.</p>","tags":["vm","proxmox"]},{"location":"apps/w11/#installation","title":"Installation","text":"<p>Warning</p> <p>In order for RDP to work, Windows Pro needs to be installed!</p> <ul> <li>Download Windows 11 ISO using <code>Download Windows 11 Disk Image (ISO) for x64 devices</code> section.</li> </ul> <pre><code>Windows 11 (multi-edition ISO for x64 evices)\n</code></pre> <ul> <li> <p>Download Windows VirtIO ISO</p> </li> <li> <p>Upload ISOs to Proxmox</p> </li> </ul>","tags":["vm","proxmox"]},{"location":"apps/w11/#create-vm","title":"Create VM","text":"OSSystemDiskCPUMemoryNetwork <p> <code>Use CD/DVD disc image file (iso)</code></p> <p>Storage: <code>local</code></p> <p>ISO image: <code>Win11_24H2_English_x64.iso</code></p> <p>Guest OS:</p> <p>Type: <code>Microsoft Windows</code></p> <p>Version: <code>11/2022/2025</code></p> <p> <code>Add additional drive for VirtIO drivers</code></p> <p>Storage: <code>local</code></p> <p>ISO image: <code>virtio-win.iso</code></p> <p>Graphics card: <code>Default</code></p> <p>Machine: <code>q35</code></p> <p>BIOS: <code>OVMF (UEFI)</code></p> <p>Add EFI Disk: </p> <p>EFI Storage: <code>local-lvm</code></p> <p>Pre-Enroll keys: </p> <p>SCSI Controller: <code>VirtIO SCSI single</code></p> <p>Qemu Agent </p> <p>Add TPM </p> <p>TPM Storage: <code>local-lvm</code></p> <p>Version: <code>v2.0</code></p> <p>Bus/Device: <code>SCSI 0</code></p> <p>Storage: <code>local-lvm</code></p> <p>Recommended minimum (GiB): <code>64</code></p> <p>Disk size (GiB): <code>128</code></p> <p>Cache: <code>Default (No cache)</code></p> <p>Discard: </p> <p>IO thread: </p> <p>Leave all others as default.</p> <p>Sockets: <code>1</code></p> <p>Cores: <code>16</code></p> <p>Type: <code>host</code></p> <p>Total cores: <code>16</code></p> <p>Memory (MiB): <code>16384</code></p> <p> No network device</p> <p>Bridge: <code>vmbr0</code></p> <p>VLAN Tag: <code>no VLAN</code></p> <p>Firewall:  </p>","tags":["vm","proxmox"]},{"location":"apps/w11/#install-windows","title":"Install Windows","text":"<p>In the <code>Server View</code>, find the new VM and right click, then select <code>Start</code>. Then right click again and select <code>Console</code>. This should bring up a window where you can view the <code>Monitor</code> of the VM. You may need to press a key on your keyboard to boot from the CD/DVD to get started.</p>","tags":["vm","proxmox"]},{"location":"apps/w11/#windows-setup","title":"Windows Setup","text":"<p>Follow the first few steps of the Windows 11 Setup workflow. I recommend choosing Windows 11 Pro if you want to use Remote Desktop in the future. Once you reach the <code>Install Location</code> page proceed to the next step to install the drivers.</p>","tags":["vm","proxmox"]},{"location":"apps/w11/#driver-installation","title":"Driver Installation","text":"<p>You likely will be unable to see any disks until the correct drivers are installed. Click the <code>Load Driver</code> option to load the <code>virtio-win</code> SCSI driver. Click <code>Browse</code> and then navigate to the path \\amd64\\w11 and then click <code>OK</code>.</p> <p>Select the <code>Red Hat VirtIO SCSI pass-through controller</code>, then click <code>Install</code>. After the driver is installed the driver should be visible.</p> <p>Click <code>Next</code> to proceed. Then <code>Install</code>. Wait for the installation to finish. It may reboot a few times. Once the configuration workflow loads up, proceed to the <code>Let's connect you to a network step</code> then proceed to the next step.</p>","tags":["vm","proxmox"]},{"location":"apps/w11/#install-virtio-drivers","title":"Install VirtIO Drivers","text":"<p>Previously, only the driver to view the disks during installation was installed. Now all the drivers need to be installed in order to have full functionality of the VM. Press <code>Shift + F10</code> to bring up the Terminal. You will need to click the <code>Terminal</code> to bring it into focus. Then start the driver installation</p> <p>Code</p> <pre><code>D:\\virtio-win-guest-tools.exe\n</code></pre> <p>Once executed, the VirtIO setup will start. Follow the installation instructions. I typically use the defaults. Once the install has finished click \"Finish\" and close out of the Terminal. The \"Network\" should now be connected. Click \"Next\" to proceed and complete the Windows installation as normal.</p>","tags":["vm","proxmox"]},{"location":"apps/w11/#rdp","title":"RDP","text":"<p>Remote control of the W11 installation is done through Apache Guacamole.</p>","tags":["vm","proxmox"]},{"location":"apps/w11/#proxmox-gui","title":"Proxmox GUI","text":"<p>Ensure that the firewall is turned off.</p> <p>Firewall</p> Options <p>Firewall: <code>No</code></p> <p>Hardware</p> Network Device (net0) <p>Firewall: </p>","tags":["vm","proxmox"]},{"location":"apps/w11/#windows","title":"Windows","text":"<p>Windows Defender Firewall</p> Domain ProfilePrivate ProfilePublic Profile <p>Firewall state: <code>Off</code></p> <p>Firewall state: <code>Off</code></p> <p>Firewall state: <code>Off</code></p>","tags":["vm","proxmox"]},{"location":"apps/w11/#references","title":"References","text":"<ul> <li>https://guides.hakedev.com/wiki/proxmox/windows-11-vm</li> </ul>","tags":["vm","proxmox"]},{"location":"apps/watchyourlan/","title":"WatchYourLAN","text":"<p>WatchYourLAN is used to monitor IP addresses on my network rather than logging into Unifi.</p>","tags":["lxc","vm","proxmox"]},{"location":"apps/watchyourlan/#installation","title":"Installation","text":"<p> Default Port: <code>8840</code></p> <p> Configuration path: <code>/etc/watchyourlan</code></p> AMD64ARM64 <pre><code>bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/ct/watchyourlan.sh)\"\n</code></pre> <pre><code>bash -c \"$(wget -qLO - https://github.com/asylumexp/Proxmox/raw/main/ct/watchyourlan.sh)\"\n</code></pre>","tags":["lxc","vm","proxmox"]},{"location":"apps/watchyourlan/#config","title":"Config","text":"<p>/etc/watchyourlan/config_v2.yaml</p> Symbolic LinkAutomaticDownloadManual <pre><code>ln -s /root/git/nicholaswilde/homelab/pve/watchyourlan/config_v2.yaml /etc/watchyourlan/config_v2.yaml\n</code></pre> <pre><code>cat &gt; /etc/watchyourlan/config_v2.yaml &lt;&lt;EOF\n\narp_args: \"\"\narp_strs:\n    - -gNx 192.168.1.0/24 -Q 1 -I eth0\n    - -gNx 192.168.2.0/24 -Q 2 -I eth0\n    - -gNx 192.168.3.0/24 -Q 3 -I eth0\narp_strs_joined: \"\"\ncolor: dark\nhist_in_db: false\nhost: 0.0.0.0\nifaces: eth0\ninflux_addr: \"\"\ninflux_bucket: \"\"\ninflux_enable: false\ninflux_org: \"\"\ninflux_skip_tls: false\ninflux_token: \"\"\nlog_level: info\nnodepath: \"\"\npg_connect: \"\"\nport: \"8840\"\nshoutrrr_url: \"\"\ntheme: sand\ntimeout: 120\ntrim_hist: 48\nuse_db: sqlite\n\nEOF\n</code></pre> <pre><code>wget https://github.com/nicholaswilde/homelab/raw/refs/heads/main/pve/watchyourlan/config_v2.yaml -O /etc/watchyourlan/config_v2.yaml\n</code></pre> <pre><code>arp_args: \"\"\narp_strs:\n    - -gNx 192.168.1.0/24 -Q 1 -I eth0\n    - -gNx 192.168.2.0/24 -Q 2 -I eth0\n    - -gNx 192.168.3.0/24 -Q 3 -I eth0\narp_strs_joined: \"\"\ncolor: dark\nhist_in_db: false\nhost: 0.0.0.0\nifaces: eth0\ninflux_addr: \"\"\ninflux_bucket: \"\"\ninflux_enable: false\ninflux_org: \"\"\ninflux_skip_tls: false\ninflux_token: \"\"\nlog_level: info\nnodepath: \"\"\npg_connect: \"\"\nport: \"8840\"\nshoutrrr_url: \"\"\ntheme: sand\ntimeout: 120\ntrim_hist: 48\nuse_db: sqlite\n</code></pre> <p>/etc/watchyourlan/scan.db</p> <p>Decrypt</p> TaskSOPS <pre><code>task decrypt\n</code></pre> <pre><code>sops -d scan.db.enc &gt; scan.db\n</code></pre> <p>Encrypt</p> TaskSOPS <pre><code>task encrypt\n</code></pre> <pre><code>sops -e scan.db &gt; scan.db.enc\n</code></pre> <p>Symbolic Link</p> <pre><code>ln -s /root/git/nicholaswilde/homelab/pve/watchyourlan/scan.db /etc/watchyourlan/scan.db\n</code></pre>","tags":["lxc","vm","proxmox"]},{"location":"apps/watchyourlan/#traefik","title":"Traefik","text":"<code>homelab/pve/traefik/conf.d/watchyourlan.yaml</code> <pre><code>---\nhttp:\n #region routers \n  routers:\n    watchyourlan:\n      entryPoints:\n        - \"websecure\"\n      rule: \"Host(`watch.l.nicholaswilde.io`)\"\n      middlewares:\n        - default-headers@file\n        - https-redirectscheme@file\n      tls: {}\n      service: watchyourlan\n#endregion\n#region services\n  services:\n    watchyourlan:\n      loadBalancer:\n        servers:\n          - url: \"http://192.168.2.53:8840\"\n        passHostHeader: true\n</code></pre>","tags":["lxc","vm","proxmox"]},{"location":"apps/watchyourlan/#task-list","title":"Task List","text":"<pre><code>task: Available tasks for this project:\n* decrypt:       Decrypt scan.db using SOPS\n* encrypt:       Encrypt scan.db using SOPS\n* export:        Export the task list\n* init:          Init\n* mklinks:       Make soft links\n* restart:       Restart the service\n* stop:          Stop the service\n* update:        Update WakeYourLAN\n</code></pre>","tags":["lxc","vm","proxmox"]},{"location":"apps/watchyourlan/#references","title":"References","text":"<ul> <li>https://community-scripts.github.io/ProxmoxVE/scripts?id=watchyourlan</li> <li>https://pimox-scripts.com/scripts?id=watchyourlan</li> </ul>","tags":["lxc","vm","proxmox"]},{"location":"hardware/asus-chromebook-plus-cx34/","title":"ASUS Chromebook Plus CX34","text":"<p>This Chromebook is my daily driver that I use to do most of my homelabbing. It's portable and fairly powerful. Mostly, it's used to remote into my other machines or browse the web or compose documents or email.</p> <p>OS: <code>Chrome OS</code></p> <p>Manufacturer: <code>ASUS</code></p> <p>Model: <code>CX3402CBA-DH386-WH</code></p> <p>CPU: <code>Intel i3</code></p> <p>RAM: <code>32GB</code></p> <p>Drive: <code>256GB</code></p>","tags":["hardware","chromeos"]},{"location":"hardware/asus-chromebook-plus-cx34/#background","title":"Background","text":"<p>I was interested in the Chromebook when the <code>Cr-48</code> was first released by Google and I was chosen to be part of their pilot progarm. Since then, I've used Chromebooks as my main laptop and used other OS' and systems for support.</p> <p>The reason for going with a Chromebook is to use a simple OS that does the basics of browsing the web and enabling me to SSH into other systems.</p>","tags":["hardware","chromeos"]},{"location":"hardware/asus-chromebook-plus-cx34/#penguin-terminal","title":"Penguin Terminal","text":"<p>I only use the built in Penguin Terminal when I'm away from my home network.</p>","tags":["hardware","chromeos"]},{"location":"hardware/asus-chromebook-plus-cx34/#ssh-client","title":"SSH Client","text":"<p>I use the Secure Shell extension by Google as my main SSH client to connect to all of my other machines. This client is lightweight and syncs with my other Chrome browser sessions, which is handy.</p>","tags":["hardware","chromeos"]},{"location":"hardware/asus-chromebook-plus-cx34/#references","title":"References","text":"<ul> <li>https://www.asus.com/us/laptops/for-home/chromebook/asus-chromebook-plus-cx34-cx3402/</li> </ul>","tags":["hardware","chromeos"]},{"location":"hardware/digital-picture-frame/","title":"Digital Picture Frame","text":"<p>I have a NIX Advance 8 Inch USB Digital Photo Frame that does not have wireless communication.</p>","tags":["hardware"]},{"location":"hardware/digital-picture-frame/#background","title":"Background","text":"<p>The issue is workflow for updating the memory card or USB thumb drive with pictures is a bit manual and clunky. I want to automate the process a little bit more.</p>","tags":["hardware"]},{"location":"hardware/digital-picture-frame/#current-process","title":"Current Process","text":"<ol> <li>Create a <code>Digital Picture Frame</code> album in Google Photos (manual).</li> <li>Add desired photos to album (manual).</li> <li>Download album as zip file via web interface on Chromebook (manual).</li> <li>Transfer zip file to LXC (manual).</li> <li>Use the <code>heic-extract.sh</code> script to extract zip file, convert <code>HEIC</code> files to <code>jpg</code>, and delete <code>MP4</code> files (auto).</li> <li>Format SD card as <code>FAT32</code> (optional) (manual).</li> <li>Transfer <code>png</code> and <code>jpg</code> files to SD card (manual).</li> <li>Plug in SD card to digital picture frame (manual).</li> </ol>","tags":["hardware"]},{"location":"hardware/digital-picture-frame/#future-process","title":"Future Process","text":"<p>I'd like to be able to make a custom programmed LILYGO T-Dongle S3 that allows the frame to read from a micro SD card and also allow to write to the SD card wirelessly.</p> <ol> <li>Create a <code>Digital Picture Frame</code> album in Google Photos (manual).</li> <li>Add desired photos to album (manual).</li> <li>Download files from album (auto).</li> <li>Convert <code>HEIC</code> files to <code>jpg</code> (auto).</li> <li>Wirelessly upload files to frame USB drive via LILYGO T-Dongle S3 (auto).</li> </ol>","tags":["hardware"]},{"location":"hardware/digital-picture-frame/#config","title":"Config","text":"","tags":["hardware"]},{"location":"hardware/digital-picture-frame/#sd-card-preparation","title":"SD Card Preparation","text":"<p>Determine USB device</p> <pre><code>sudo lsusb\n</code></pre> Output<pre><code>Bus 003 Device 003: ID 0bda:0306 Realtek Semiconductor Corp. USB3.0 Card Reader\n</code></pre> <p>Look at messages after plugging in USB adapter</p> <pre><code>sudo dmesg\n</code></pre> Output<pre><code>[ 1409.448074] usb 3-1: new SuperSpeed USB device number 3 using xhci_hcd\n[ 1409.468208] usb 3-1: New USB device found, idVendor=0bda, idProduct=0306, bcdDevice= 1.17\n[ 1409.468215] usb 3-1: New USB device strings: Mfr=1, Product=2, SerialNumber=3\n[ 1409.468216] usb 3-1: Product: USB3.0 Card Reader\n[ 1409.468218] usb 3-1: Manufacturer: Realtek\n[ 1409.468219] usb 3-1: SerialNumber: 201506301013\n[ 1409.470012] usb-storage 3-1:1.0: USB Mass Storage device detected\n[ 1411.925210] sd 3:0:0:1: [sdc] 31116288 512-byte logical blocks: (15.9 GB/14.8 GiB)\n[ 1411.926227] sd 3:0:0:1: [sdc] Write Protect is off\n[ 1411.926231] sd 3:0:0:1: [sdc] Mode Sense: 2f 00 00 00\n[ 1411.927024] sd 3:0:0:1: [sdc] Write cache: disabled, read cache: enabled, doesn't support DPO or FUA\n[ 1411.946558]  sdc: sdc1\n[ 1411.946720] sd 3:0:0:1: [sdc] Attached SCSI removable disk\n</code></pre> <p>Format the SD card as FAT32</p> <pre><code>sudo mkfs.vfat -F 32 /dev/sdc \n</code></pre>","tags":["hardware"]},{"location":"hardware/digital-picture-frame/#usage","title":"Usage","text":"","tags":["hardware"]},{"location":"hardware/digital-picture-frame/#heic-converter-script","title":"HEIC Converter Script","text":"<p>This script converts <code>HEIC</code> images to <code>JPG</code> or <code>PNG</code> format. It can also delete original <code>HEIC</code> files upon successful conversion, delete <code>MP4</code> files, and extract zip/tar archives.</p> <p>It requires ImageMagick (<code>magick</code> or <code>convert</code> command) for <code>HEIC</code> conversion, <code>unzip</code> for <code>.zip</code> files, and <code>tar</code> for <code>.tar</code> and compressed tarballs.</p> <p>Prerequisites</p> apt <pre><code>sudo apt install imagemagick\n</code></pre> <p>Note</p> <p>Certain ImageMagick packages uses the <code>convert</code> command and others use the <code>magick</code> command.</p> <p>Convert individual HEIC files</p> <pre><code>./heic-converter.sh image.heic photo.heic\n</code></pre> <p>Convert individual HEIC file to png and extract zip file</p> <pre><code>./heic-converter.sh -f png photo.heic --extract-archives archive.zip\n</code></pre> <p>Process all files in directory and delete all HEIC files</p> <pre><code>./heic-converter.sh -d ~/Pictures/MyHEICImages -f jpg --delete-heic-on-success --extract-archives\n</code></pre> <p>Process all files in directory and deleta all mp4 files</p> <pre><code>./heic-converter.sh -d ./my_media --delete-mp4 --extract-archives\n</code></pre> <p>Extract archive files, such as zip or tar</p> <pre><code>./heic-converter.sh --extract-archives my_photos.zip video_archive.tar.gz\n</code></pre> heic-converter.sh <pre><code>#!/usr/bin/env bash\n\n################################################################################\n#\n# HEIC Converter\n# ----------------\n# This script converts HEIC images to JPG or PNG format.\n# It can also delete original HEIC files upon successful conversion,\n# delete MP4 files, and extract zip/tar archives.\n#\n# It requires ImageMagick ('magick' or 'convert' command) for HEIC conversion,\n# 'unzip' for .zip files, and 'tar' for .tar and compressed tarballs.\n##\n# @author Nicholas Wilde, 0xb299a622 \n# @date 05 Jul 2025\n# @version 0.1.0\n#\n################################################################################\n\n# Options\nset -e\nset -o pipefail\n\n# Constants\nbold=$(tput bold)\nnormal=$(tput sgr0)\nred=$(tput setaf 1)\ngreen=$(tput setaf 2)\nyellow=$(tput setaf 3)\nblue=$(tput setaf 4)\npurple=$(tput setaf 5)\ncyan=$(tput setaf 6)\nwhite=$(tput setaf 7)\ndefault=$(tput setaf 9)\n\nreadonly bold\nreadonly normal\nreadonly red\nreadonly green\nreadonly yellow\nreadonly blue\nreadonly purple\nreadonly cyan\nreadonly white\nreadonly default\n\n# Global variables\nOUTPUT_FORMAT=\"jpg\"\nPROCESS_DIRECTORY=\"\"\ndeclare -a RAW_INPUT_ARGS # Holds all non-option arguments from the command line\ndeclare -a HEIC_FILES_TO_PROCESS # Files identified for HEIC conversion\ndeclare -a ARCHIVE_FILES_TO_EXTRACT # Files identified for archive extraction\nIMAGEMAGICK_CMD=\"\"\nDELETE_HEIC_ON_SUCCESS=false\nDELETE_MP4_FILES=false\nEXTRACT_ARCHIVES=false # This flag now enables/disables the extraction *feature*\n\n# Functions\nfunction print_text(){\n  echo \"${blue}==&gt; ${white}${bold}${1}${normal}\"\n}\n\nfunction print_error(){\n  echo \"${red}${1}${normal}\"\n}\n\n# Function to get the current timestamp\nfunction get_timestamp() {\n  date +\"%Y-%m-%d %H:%M:%S\"\n}\n\n# INFO level logging (often default color or green/blue)\nfunction log_info() {\n  printf \"${blue}INFO${normal}[%s] %s\\n\" \"$(get_timestamp)\" \"$*\"\n}\n\n# INFO level logging (often default color or green/blue)\nfunction log_debu() {\n  printf \"${purple}DEBU${normal}[%s] %s\\n\" \"$(get_timestamp)\" \"$*\"\n}\n\n# WARN level logging (yellow)\nfunction log_warn() {\n  printf \"${yellow}WARN${normal}[%s] %s\\n\" \"$(get_timestamp)\" \"$*\" &gt;&amp;2\n}\n\n# ERRO level logging (red)\nfunction log_erro() {\n  printf \"${red}ERRO${normal}[%s] %s\\n\" \"$(get_timestamp)\" \"$*\" &gt;&amp;2\n}\n\nfunction raise_error(){\n  print_error \"${1}\"\n  exit 1\n}\n\n# Check if variable is set\n# Returns false if empty\nfunction is_set(){\n  [ -n \"${1}\" ]\n}\n\nfunction command_exists() {\n  command -v \"$1\" &gt;/dev/null 2&gt;&amp;1\n}\n\n# Function to display usage instructions\nfunction show_usage() {\n  echo \"Usage: $0 [-f &lt;jpg|png&gt;] [file1.heic ...] [-d &lt;dir&gt;] [--delete-heic-on-success] [--delete-mp4] [--extract-archives] [archive1.zip ...]\"\n  echo \"\"\n  echo \"Options:\"\n  echo \"  -f &lt;jpg|png&gt;             : Specify the output format (default: jpg).\"\n  echo \"  -d &lt;directory&gt;           : Process files in the specified directory.\"\n  echo \"                             Required for --delete-mp4 and automatic archive detection in directory.\"\n  echo \"  --delete-heic-on-success : DELETE original HEIC files after successful conversion.\"\n  echo \"                             USE WITH CAUTION: This action is irreversible!\"\n  echo \"  --delete-mp4             : DELETE all MP4 files found in the processed directory (-d option).\"\n  echo \"                             USE WITH CAUTION: This action is irreversible!\"\n  echo \"  --extract-archives       : Enable extraction for provided archive files or archives found via -d.\"\n  echo \"  -h                       : Display this help message.\"\n  echo \"\"\n  echo \"Examples:\"\n  echo \"  $0 image.heic photo.heic\"\n  echo \"  $0 -f png photo.heic --extract-archives archive.zip\"\n  echo \"  $0 -d ~/Pictures/MyHEICImages -f jpg --delete-heic-on-success --extract-archives\"\n  echo \"  $0 -d ./my_media --delete-mp4 --extract-archives\"\n  echo \"  $0 --extract-archives my_photos.zip video_archive.tar.gz\"\n  exit 1\n}\n\n# Function to parse command-line arguments\nfunction parse_arguments() {\n  local ARGS=$(getopt -o f:d:h -l delete-heic-on-success,delete-mp4,extract-archives -- \"$@\")\n  if [[ $? -ne 0 ]]; then\n    show_usage\n  fi\n\n  eval set -- \"$ARGS\"\n\n  while true; do\n    case \"$1\" in\n      -f )\n        if [[ \"$2\" == \"jpg\" || \"$2\" == \"png\" ]]; then\n          OUTPUT_FORMAT=\"$2\"\n        else\n          log_erro \"Invalid format '$2'. Only 'jpg' or 'png' are supported.\"\n          show_usage\n        fi\n        shift 2;;\n      -d )\n        PROCESS_DIRECTORY=\"$2\"\n        shift 2;;\n      --delete-heic-on-success )\n        DELETE_HEIC_ON_SUCCESS=true\n        shift;;\n      --delete-mp4 )\n        DELETE_MP4_FILES=true\n        shift;;\n      --extract-archives )\n        EXTRACT_ARCHIVES=true\n        shift;;\n      -h )\n        show_usage;;\n      -- )\n        shift\n        break;;\n      * )\n        break;;\n    esac\n  done\n\n  # All remaining arguments are file paths (HEIC, archives, or others)\n  RAW_INPUT_ARGS=(\"$@\")\n\n  if [[ -z \"$PROCESS_DIRECTORY\" ]] &amp;&amp; [[ ${#RAW_INPUT_ARGS[@]} -eq 0 ]]; then\n    log_erro \"No input files or directory specified.\"\n    show_usage\n  fi\n}\n\n# Function to resolve and categorize input file paths\nfunction resolve_input_files() {\n  local files_to_categorize=()\n\n  if [[ -n \"$PROCESS_DIRECTORY\" ]]; then\n    # Resolve the directory path to its absolute form for robustness\n    local ABS_PROCESS_DIRECTORY\n    if [[ \"$PROCESS_DIRECTORY\" == /* ]]; then # Already an absolute path\n      ABS_PROCESS_DIRECTORY=\"$PROCESS_DIRECTORY\"\n    else # Relative path, resolve it\n      ABS_PROCESS_DIRECTORY=\"$(pwd)/$PROCESS_DIRECTORY\"\n    fi\n\n    if [[ ! -d \"$ABS_PROCESS_DIRECTORY\" ]]; then\n      log_erro \"Directory '$PROCESS_DIRECTORY' (resolved to '$ABS_PROCESS_DIRECTORY') not found.\"\n      exit 1\n    fi\n    log_info \"Scanning directory: $PROCESS_DIRECTORY (resolved to '$ABS_PROCESS_DIRECTORY') for HEIC and archive files...\"\n    # Find all relevant files in the directory\n    mapfile -t files_to_categorize &lt; &lt;(find \"$ABS_PROCESS_DIRECTORY\" -maxdepth 1 -type f \\\n      \\( -iname \"*.heic\" -o -iname \"*.heif\" -o \\\n         -iname \"*.zip\" -o \\\n         -iname \"*.tar\" -o -iname \"*.tar.gz\" -o -iname \"*.tgz\" -o -iname \"*.tar.bz2\" -o -iname \"*.tbz2\" \\))\n\n    if [[ ${#files_to_categorize[@]} -eq 0 ]] &amp;&amp; ! $DELETE_MP4_FILES; then\n      log_info \"No HEIC, archive files, or MP4 files found in '$ABS_PROCESS_DIRECTORY' for processing.\"\n      exit 0 # Exit if directory specified but nothing to do\n    fi\n  else\n    # Direct file arguments were passed\n    files_to_categorize=(\"${RAW_INPUT_ARGS[@]}\")\n    # For directly passed files, resolve them to absolute paths for consistency\n    local resolved_files=()\n    for file_arg in \"${files_to_categorize[@]}\"; do\n      if [[ \"$file_arg\" == /* ]]; then # Already an absolute path\n        resolved_files+=(\"$file_arg\")\n      else # Relative path, resolve it\n        resolved_files+=(\"$(pwd)/$file_arg\")\n      fi\n    done\n    files_to_categorize=(\"${resolved_files[@]}\")\n\n    # If MP4 deletion or archive extraction flags are set without -d,\n    # these ops only apply to explicitly provided files of that type.\n    # Warn if --delete-mp4 is used without -d as its primary function is directory-wide.\n    if $DELETE_MP4_FILES; then\n      log_warn \"--delete-mp4 primarily cleans MP4s in a directory (via -d). For specific MP4 files, pass them directly.\"\n    fi\n  fi\n\n  # Now, categorize the identified files into HEIC_FILES_TO_PROCESS and ARCHIVE_FILES_TO_EXTRACT\n  for file_path in \"${files_to_categorize[@]}\"; do\n    local basename_lc=$(basename -- \"$file_path\" | tr '[:upper:]' '[:lower:]') # Lowercase for case-insensitive check\n    if [[ \"$basename_lc\" =~ \\.(heic|heif)$ ]]; then\n      HEIC_FILES_TO_PROCESS+=(\"$file_path\")\n    elif [[ \"$basename_lc\" =~ \\.(zip|tar|tar\\.gz|tgz|tar\\.bz2|tbz2)$ ]]; then\n      ARCHIVE_FILES_TO_EXTRACT+=(\"$file_path\")\n    else\n      log_info \"Ignoring unrecognized file type: '$file_path'\"\n    fi\n  done\n\n  # Final check if any operations are actually going to run\n  if [[ ${#HEIC_FILES_TO_PROCESS[@]} -eq 0 ]] &amp;&amp; \\\n    [[ ! \"$EXTRACT_ARCHIVES\" || ${#ARCHIVE_FILES_TO_EXTRACT[@]} -eq 0 ]] &amp;&amp; \\\n    [[ ! \"$DELETE_MP4_FILES\" || -z \"$PROCESS_DIRECTORY\" ]]; then\n    log_info \"No relevant files (HEIC, Archives, or directory for MP4 cleanup) found or specified for requested operations.\"\n    exit 0\n  fi\n}\n\n# Function to check for ImageMagick commands\nfunction check_imagemagick_command() {\n  if command -v magick &amp;&gt; /dev/null; then\n    IMAGEMAGICK_CMD=\"magick\"\n  elif command -v convert &amp;&gt; /dev/null; then\n    IMAGEMAGICK_CMD=\"convert\"\n  else\n    log_erro \"Neither 'magick' nor 'convert' commands (from ImageMagick) found in your PATH.\"\n    log_erro \"Please install ImageMagick. For example:\"\n    log_erro \"  macOS: brew install imagemagick\"\n    log_erro \"  Debian/Ubuntu: sudo apt install imagemagick\"\n    log_erro \"  Fedora/RHEL: sudo yum install ImageMagick\"\n    exit 1\n  fi\n}\n\n# Function to check for archive extraction commands\nfunction check_archive_commands() {\n  if $EXTRACT_ARCHIVES; then\n    if ! command -v unzip &amp;&gt; /dev/null; then\n      log_erro \"'unzip' command not found. Cannot extract .zip files. Please install it.\"\n      log_erro \"  Debian/Ubuntu: sudo apt install unzip\"\n      log_erro \"  Fedora/RHEL: sudo yum install unzip\"\n      log_erro \"  macOS: brew install unzip\"\n      # Don't exit, allow tar extraction if available\n    fi\n    if ! command -v tar &amp;&gt; /dev/null; then\n      log_erro \"'tar' command not found. Cannot extract .tar/.tar.gz/.tar.bz2 files. Please install it.\"\n      log_erro \"  Tar is usually pre-installed on Linux/macOS. If not, install via your package manager.\"\n      exit 1 # Tar is crucial for these types, so exit if not found\n    fi\n  fi\n}\n\n# Function to clean up MP4 files in the processed directory\nfunction cleanup_mp4_files() {\n  # This function only acts if -d is used to define a directory scope\n  if $DELETE_MP4_FILES &amp;&amp; [[ -n \"$PROCESS_DIRECTORY\" ]]; then\n    log_info \"Initiating MP4 File Deletion\"\n    local ABS_PROCESS_DIRECTORY # Ensure it's available from resolve_input_files scope\n    if [[ \"$PROCESS_DIRECTORY\" == /* ]]; then\n      ABS_PROCESS_DIRECTORY=\"$PROCESS_DIRECTORY\"\n    else\n      ABS_PROCESS_DIRECTORY=\"$(pwd)/$PROCESS_DIRECTORY\"\n    fi\n\n    log_info \"Searching for and deleting MP4 files in '$ABS_PROCESS_DIRECTORY'...\"\n    local mp4_files=()\n    mapfile -t mp4_files &lt; &lt;(find \"$ABS_PROCESS_DIRECTORY\" -maxdepth 1 -type f -iname \"*.mp4\")\n\n    if [[ ${#mp4_files[@]} -eq 0 ]]; then\n      log_info \"No MP4 files found in '$ABS_PROCESS_DIRECTORY'.\"\n    else\n      for mp4_file in \"${mp4_files[@]}\"; do\n        log_info \"Deleting MP4: '$mp4_file'\"\n        rm -f \"$mp4_file\"\n        if [[ $? -ne 0 ]]; then\n          log_warn \"Failed to delete '$mp4_file'.\"\n        fi\n      done\n      log_info \"MP4 file deletion complete.\"\n    fi\n  elif $DELETE_MP4_FILES &amp;&amp; [[ -z \"$PROCESS_DIRECTORY\" ]]; then\n    log_info \"--delete-mp4 flag was used, but no directory (-d) was specified. Skipping directory-wide MP4 cleanup.\"\n  fi\n}\n\n# Function to extract archives\nfunction extract_archives() {\n  if $EXTRACT_ARCHIVES &amp;&amp; [[ ${#ARCHIVE_FILES_TO_EXTRACT[@]} -gt 0 ]]; then\n    log_info \"Initiating Archive Extraction\"\n    for archive_file in \"${ARCHIVE_FILES_TO_EXTRACT[@]}\"; do\n      if [[ ! -f \"$archive_file\" ]]; then\n        log_warn \"Archive file '$archive_file' not found. Skipping extraction.\"\n        continue\n      fi\n\n      local archive_basename=$(basename -- \"$archive_file\")\n      local archive_dir=$(dirname \"$archive_file\")\n      local extract_dir=\"${archive_dir}/${archive_basename%.*}_extracted\" # Extract into a new dir next to the archive\n      mkdir -p \"$extract_dir\" # Create the extraction directory\n\n      log_info \"Extracting '$archive_basename' to '$extract_dir'...\"\n\n      case \"$archive_file\" in\n        *.zip)\n          if command -v unzip &amp;&gt; /dev/null; then\n            unzip -q \"$archive_file\" -d \"$extract_dir\"\n            if [[ $? -eq 0 ]]; then\n              log_info \"Successfully extracted '$archive_basename'.\"\n            else\n              log_erro \"Failed to extract '$archive_basename' with unzip.\"\n            fi\n          else\n            log_warn \"'unzip' command not found. Cannot extract '$archive_basename'.\"\n          fi;;\n        *.tar|*.tar.gz|*.tgz|*.tar.bz2|*.tbz2)\n          if command -v tar &amp;&gt; /dev/null; then\n            local tar_flags=\"-xf\"\n            case \"$archive_file\" in\n              *.tar.gz|*.tgz) tar_flags=\"-xzf\";;\n              *.tar.bz2|*.tbz2) tar_flags=\"-xjf\";;\n            esac\n            tar \"$tar_flags\" \"$archive_file\" -C \"$extract_dir\"\n            if [[ $? -eq 0 ]]; then\n              log_info \"Successfully extracted '$archive_basename'.\"\n            else\n              log_erro \"Failed to extract '$archive_basename' with tar.\"\n            fi\n          else\n            log_warn \"'tar' command not found. Cannot extract '$archive_basename'.\"\n          fi;;\n        *)\n          log_warn \"Unrecognized archive type for '$archive_basename'. Skipping.\";;\n      esac\n    done\n    log_info \"Archive extraction complete.\"\n  elif $EXTRACT_ARCHIVES &amp;&amp; [[ ${#ARCHIVE_FILES_TO_EXTRACT[@]} -eq 0 ]]; then\n    log_info \"--extract-archives flag was used, but no archive files were specified or found in the directory for extraction.\"\n  fi\n}\n\n# Function to process (convert) the HEIC files\nfunction process_files() {\n  if [[ ${#HEIC_FILES_TO_PROCESS[@]} -eq 0 ]]; then\n    log_info \"No HEIC files to convert.\"\n    return 0\n  fi\n\n  log_info \"HEIC to ${OUTPUT_FORMAT^^} Converter (using '$IMAGEMAGICK_CMD')\"\n\n  for heic_file in \"${HEIC_FILES_TO_PROCESS[@]}\"; do\n    if [[ ! -f \"$heic_file\" ]]; then\n      log_warn \"File '$heic_file' not found. Skipping.\"\n      continue\n    fi\n\n    local heic_dir=$(dirname \"$heic_file\")\n    local filename_no_ext=$(basename -- \"$heic_file\" | sed 's/\\.[Hh][Ee][Ii][Cc]$//' | sed 's/\\.[Hh][Ee][Ii][Ff]$//')\n    local output_file=\"${heic_dir}/${filename_no_ext}.${OUTPUT_FORMAT}\"\n\n    log_info \"Converting \"$(basename \"$heic_file\")\" to \"$(basename \"$output_file\")\"...\"\n\n    if \"$IMAGEMAGICK_CMD\" \"$heic_file\" \"$output_file\"; then\n      log_info \"Successfully converted\" $(basename \"$heic_file\")\" to \"$(basename \"$output_file\")\".\"\n      if $DELETE_HEIC_ON_SUCCESS; then\n        log_info \"Deleting original HEIC file: \" $(basename \"$heic_file\")\n        rm -f \"$heic_file\"\n        if [[ $? -ne 0 ]]; then\n          log_warn \"Failed to delete original HEIC file \"$(basename \"$heic_file\")\".\"\n        fi\n      fi\n    else\n      log_erro \"Failed to convert \"$(basename \"$heic_file\")\".\"\n    fi\n  done\n\n  log_info \"HEIC Conversion complete\"\n}\n\n# Main Script Execution\n\n# Main function to orchestrate the script execution\nfunction main() {\n  parse_arguments \"$@\"\n  resolve_input_files # This categorizes files and sets ABS_PROCESS_DIRECTORY if -d is used\n\n  # Only check commands if the relevant operations are requested\n  if [[ ${#HEIC_FILES_TO_PROCESS[@]} -gt 0 ]]; then\n    check_imagemagick_command\n  fi\n  if $EXTRACT_ARCHIVES &amp;&amp; [[ ${#ARCHIVE_FILES_TO_EXTRACT[@]} -gt 0 ]]; then\n    check_archive_commands\n  fi\n\n  cleanup_mp4_files # Run MP4 cleanup if enabled and in directory mode (still only applies to -d)\n  extract_archives  # Run archive extraction if enabled and archives are found/passed\n  process_files     # Run HEIC conversion if HEIC files are found/passed\n}\n\n# Call the main function with all command-line arguments\nmain \"$@\"\n</code></pre>","tags":["hardware"]},{"location":"hardware/digital-picture-frame/#references","title":"References","text":"<ul> <li>https://www.amazon.com/dp/B015XVAKG4</li> </ul>","tags":["hardware"]},{"location":"hardware/hp-prodesk-600-g3/","title":"HP ProDesk 600 G3","text":"<p>This computer was inherited and so I converted it to a Proxmox node.</p>","tags":["proxmox","hardware","amd64"]},{"location":"hardware/hp-prodesk-600-g3/#config","title":"Config","text":"<p>OS: <code>Proxmox 8.4.1</code></p> <p>RAM: <code>24GB</code></p> <p>DRIVE: <code>SATA SSD</code></p>","tags":["proxmox","hardware","amd64"]},{"location":"hardware/hp-prodesk-600-g3/#references","title":"References","text":"","tags":["proxmox","hardware","amd64"]},{"location":"hardware/lenovo-chromebook-flex-5/","title":"Lenovo ChromeBook Flex 5","text":"<p>This chromebook was inherited and is used when I'm away from my homelab network. I use it the same way as my ASUS Chromebook.</p> <p>OS: <code>ChromeOS</code></p> <p>Manufacturer: <code>Lenovo</code></p> <p>Model: <code>ChromeBook Flex 5</code></p> <p>CPU: <code>Core i3</code></p> <p>RAM: <code>4GB</code></p> <p>Drive: <code>64GB</code></p>","tags":["chromeos","hardware"]},{"location":"hardware/lenovo-chromebook-flex-5/#background","title":"Background","text":"<p>Unfortunately, one of the hinges was very difficult to open and so the stress from opening the screen on the hinge caused the monitor to crack. Therefore, I'm using this chromebook in conjunction with two external monitors and an external mouse and keyboard.</p>","tags":["chromeos","hardware"]},{"location":"hardware/lenovo-chromebook-flex-5/#displays","title":"Displays","text":"<p>I'm using two external monitors that are connected via a USC C to Dual DisplayPort splitter adapter.</p>","tags":["chromeos","hardware"]},{"location":"hardware/lenovo-chromebook-flex-5/#references","title":"References","text":"<ul> <li>https://www.lenovo.com/us/en/p/laptops/lenovo/lenovo-edu-chromebooks/ideapad-f5-cb-13cml-05/88ipfc51448</li> </ul>","tags":["chromeos","hardware"]},{"location":"hardware/lilygo-t-dongle-s3/","title":"LilyGo T-Dongle S3","text":"<p>The LilyGo T-Dongle S3 is a compact and versatile development board based on the Espressif ESP32-S3. It is designed for a wide range of IoT applications and projects that require wireless connectivity and low power consumption.</p>","tags":["hardware","lilygo","t-dongle-s3"]},{"location":"hardware/lilygo-t-dongle-s3/#installation","title":"Installation","text":"<p>To use the T-Dongle S3, you will need to set up your development environment with support for the ESP32-S3. The most common ways to do this are with the Arduino IDE or PlatformIO.</p>","tags":["hardware","lilygo","t-dongle-s3"]},{"location":"hardware/lilygo-t-dongle-s3/#arduino-ide","title":"Arduino IDE","text":"<ol> <li>Install the Arduino IDE: If you don't have it already, download and install the Arduino IDE.</li> <li>Add ESP32 Board Support:<ul> <li>Open the Arduino IDE and go to <code>File &gt; Preferences</code>.</li> <li>In the \"Additional Board Manager URLs\" field, add the following URL:   <pre><code>https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json\n</code></pre></li> <li>Go to <code>Tools &gt; Board &gt; Boards Manager...</code>, search for \"esp32\", and install the \"esp32\" by Espressif Systems.</li> </ul> </li> <li>Select the Board:<ul> <li>Go to <code>Tools &gt; Board</code> and under the \"ESP32 Arduino\" section, select \"ESP32S3 Dev Module\".</li> </ul> </li> </ol>","tags":["hardware","lilygo","t-dongle-s3"]},{"location":"hardware/lilygo-t-dongle-s3/#platformio","title":"PlatformIO","text":"<ol> <li>Install Visual Studio Code and PlatformIO: If you don't have it, install Visual Studio Code and the PlatformIO IDE extension.</li> <li>Create a new project:<ul> <li>Open PlatformIO and create a new project.</li> <li>For the board, search for \"ESP32-S3-DevKitC-1\" or a similar generic ESP32-S3 board.</li> </ul> </li> <li> <p>Configure <code>platformio.ini</code>:</p> <ul> <li>Your <code>platformio.ini</code> file should look something like this:</li> </ul> <pre><code>[env:esp32s3_dongle]\nplatform = espressif32\nboard = esp32-s3-devkitc-1\nframework = arduino\n</code></pre> </li> </ol>","tags":["hardware","lilygo","t-dongle-s3"]},{"location":"hardware/lilygo-t-dongle-s3/#config","title":"Config","text":"<p>The T-Dongle S3 does not require much specific configuration. The main thing is to select the correct board and settings in your development environment.</p> <p>Here are some common settings for the ESP32-S3 in the Arduino IDE under <code>Tools</code>:</p> <ul> <li>Board: \"ESP32S3 Dev Module\"</li> <li>USB CDC On Boot: \"Enabled\" (for serial communication over USB)</li> <li>Flash Mode: \"QIO\"</li> <li>Flash Size: \"4MB\"</li> <li>Partition Scheme: \"Default\"</li> </ul>","tags":["hardware","lilygo","t-dongle-s3"]},{"location":"hardware/lilygo-t-dongle-s3/#usage","title":"Usage","text":"<p>You can use the T-Dongle S3 like any other ESP32 development board. You can write code in C++ (Arduino) or MicroPython to control the GPIO pins, use the Wi-Fi and Bluetooth capabilities, and interact with sensors and other peripherals.</p> <p>Here is a simple \"Blink\" example for the Arduino IDE to get you started. The T-Dongle S3 has a built-in RGB LED that you can control.</p> <p>examples/Blink/Blink.ino</p> <pre><code>#define LED_PIN 38 // The built-in RGB LED is on GPIO 38\n\nvoid setup() {\n  pinMode(LED_PIN, OUTPUT);\n}\n\nvoid loop() {\n  digitalWrite(LED_PIN, HIGH);\n  delay(1000);\n  digitalWrite(LED_PIN, LOW);\n  delay(1000);\n}\n</code></pre>","tags":["hardware","lilygo","t-dongle-s3"]},{"location":"hardware/lilygo-t-dongle-s3/#upgrade","title":"Upgrade","text":"<p>To upgrade the firmware on your T-Dongle S3, you simply need to upload a new sketch from the Arduino IDE or PlatformIO. The board will automatically go into bootloader mode when you try to upload new code.</p> <p>If you need to manually put the board into bootloader mode:</p> <ol> <li>Hold down the \"BOOT\" button (the one on the side of the USB connector).</li> <li>Press and release the \"RESET\" button (the one next to the BOOT button).</li> <li>Release the \"BOOT\" button.</li> </ol>","tags":["hardware","lilygo","t-dongle-s3"]},{"location":"hardware/lilygo-t-dongle-s3/#references","title":"References","text":"<ul> <li>https://github.com/Xinyuan-LilyGO/T-Dongle-S3</li> <li>https://www.arduino.cc/en/software</li> <li>https://code.visualstudio.com/</li> <li>https://platformio.org/platformio-ide</li> </ul>","tags":["hardware","lilygo","t-dongle-s3"]},{"location":"hardware/nuc/","title":"Intel NUC","text":"<p>I'm in the process of converting my Intel NUC to be used as another <code>amd64</code> Proxmox node.</p>","tags":["hardware","proxmox","amd64"]},{"location":"hardware/nuc/#config","title":"Config","text":"<p>OS: Proxmox 8</p> <p>Manufacturer: <code>Intel</code></p> <p>Model: <code>NUC10i3FNK</code></p> <p>Generation: <code>10</code></p> <p>CPU: <code>Intel i3</code></p> <p>RAM: <code>32GB</code></p> <p>Drive: <code>WIP</code></p>","tags":["hardware","proxmox","amd64"]},{"location":"hardware/nuc/#references","title":"References","text":"","tags":["hardware","proxmox","amd64"]},{"location":"hardware/rpi0/","title":"Raspberry Pi Zero W","text":"","tags":["rpi","bare-metal"]},{"location":"hardware/rpi0/#config","title":"Config","text":"<p>OS: Rasbperry Pi OS (Legacy) Lite</p>","tags":["rpi","bare-metal"]},{"location":"hardware/rpi0/#references","title":"References","text":"","tags":["rpi","bare-metal"]},{"location":"hardware/rpi1/","title":"Raspberry Pi 1 Model B+","text":"<p>I am still running the Raspberry Pi 1 Model B+, my first RPi board.</p>","tags":["rpi","bare-metal"]},{"location":"hardware/rpi1/#config","title":"Config","text":"<p>OS: Rasbperry Pi OS (Legacy) Lite</p>","tags":["rpi","bare-metal"]},{"location":"hardware/rpi1/#references","title":"References","text":"","tags":["rpi","bare-metal"]},{"location":"hardware/rpi2/","title":"Raspberry Pi 2","text":"<p>My old Raspberry Pi 2 is used as a backup AdGuard Home instance so that I still have DNS when my main Proxmox server goes down.</p>","tags":["rpi","bare-metal"]},{"location":"hardware/rpi2/#config","title":"Config","text":"<p>OS: Rasbperry Pi OS (Legacy) Lite</p>","tags":["rpi","bare-metal"]},{"location":"hardware/rpi2/#references","title":"References","text":"","tags":["rpi","bare-metal"]},{"location":"hardware/rpi4/","title":"Raspberry Pi 4 8GB","text":"<p>I recently converted my Raspberry Pi 4 8GB to run Home Assistant so that I can use my NUC as another Proxmox node.</p>","tags":["home-assistant","rpi","arm64"]},{"location":"hardware/rpi4/#config","title":"Config","text":"<p>OS: <code>Raspberry Pi OS Lite (64-bit)</code></p> <p>RAM: <code>8GB</code></p> <p>HAT1: <code>Argon Fan HAT for Raspberry Pi 4</code></p> <p>HAT2: <code>GeeekPi M.2 NVME SSD Storage Expansion Board for Raspberry Pi 4 (52Pi EP-0171)</code></p> <p>DRIVE: <code>500GB NVMe</code></p>","tags":["home-assistant","rpi","arm64"]},{"location":"hardware/rpi4/#raspberry-pi-4-boot-from-usb","title":"Raspberry Pi 4 boot from usb","text":"<pre><code>sudo raspi-config\n</code></pre> GUI<pre><code>Advanced Options -&gt; Boot Order -&gt; B2 NVMe/USB\n</code></pre> <pre><code>sudo reboot\n</code></pre> <p>Sometimes, the USB adapter is slow and disconnections. The device quirks may need to be set.</p> <p>Get <code>vendorId</code> and <code>deviceId</code></p> <pre><code>sudo dmesg | grep usb\n</code></pre> Output<pre><code>[1.301989] usb 2-1: new SuperSpeed Gen 1 USB device number 2 using xhci_hcd\n[1.332965] usb 2-1: New USB device found, idVendor=152d, idProduct=1561, bcdDevice= 1.00\n[1.332999] usb 2-1: New USB device strings: Mfr=2, Product=3, SerialNumber=1\n[1.333026] usb 2-1: Product: ASM105x\n[1.333048] usb 2-1: Manufacturer: ASMT\n[1.333071] usb 2-1: SerialNumber: 123456789B79F\n</code></pre> <p>Verify the <code>vendorId</code> and <code>deviceId</code></p> <pre><code>sudo lsusb\n</code></pre> Output<pre><code>Bus 002 Device 002: ID 152d:1561 ASMedia Technology Inc. Name: ASM1051E SATA 6Gb/s bridge\n</code></pre> <p>Combine the <code>vendorId</code> and <code>deviceId</code> to get make up the <code>quirks</code>.</p> <p>Example</p> <pre><code>usb-storage.quirks=152d:1561:u\n</code></pre> <p>Add the quirks to <code>/boot/firmware/cmdline.txt</code></p> AutomaticManual <pre><code>sed -i '1s/$/ usb-storage.quirks=152d:1561:u console=serial0,115200 console=tty1 root=PARTUUID=fcf4cb94-02 rootfstype=ext4 elevator=deadline fsck.repair=yes rootwait/' cmdline.txt\n</code></pre> <pre><code>usb-storage.quirks=152d:1561:u console=serial0,115200 console=tty1 root=PARTUUID=fcf4cb94-02 rootfstype=ext4 elevator=deadline fsck.repair=yes rootwait\n</code></pre> <p><code>/boot/firmware/config.txt</code></p> AutomaticManual <pre><code>echo program_usb_boot_mode=1 | sudo tee -a config.txt\n</code></pre> <pre><code>program_usb_boot_mode=1\n</code></pre> <p>Check</p> <pre><code>mount | egrep \"/([[:space:]]|boot)\"\n</code></pre> <pre><code>vcgencmd otp_dump | grep 17\n</code></pre> <pre><code>17:1020000a=USB boot disabled\n17:3020000a=USB boot enabled\n</code></pre> sudoroot <pre><code>sudo raspi-config\nsudo rpi-update\nsudo raspi-config --expand-rootfs\n</code></pre> <pre><code>raspi-config\nrpi-update\nraspi-config --expand-rootfs\n</code></pre>","tags":["home-assistant","rpi","arm64"]},{"location":"hardware/rpi4/#swap","title":"Swap","text":"<p>See Raspberry Pi 5 16GB.</p>","tags":["home-assistant","rpi","arm64"]},{"location":"hardware/rpi4/#argon-fan-hat","title":"Argon Fan Hat","text":"<p>Install</p> <pre><code>curl https://download.argon40.com/argonfanhat.sh | bash\n</code></pre> <p>Uninstall</p> <pre><code>argonone-uninstall\n</code></pre> <p>Config</p> <pre><code>argonone-config\n</code></pre>","tags":["home-assistant","rpi","arm64"]},{"location":"hardware/rpi4/#config_1","title":"Config","text":"<ol> <li>Without the <code>ARGON FAN HAT</code> script the FAN will run constantly at 50% <code>FAN SPEED</code></li> <li>Upon installation of the script, <code>DEFAULT SETTINGS</code> of the <code>ARGON FAN HAT</code> are as follows:</li> </ol> CPU TEMP FAN SPEED / POWER 55\u00b0C 10 % 60\u00b0C 55 % 65\u00b0C 100 %","tags":["home-assistant","rpi","arm64"]},{"location":"hardware/rpi4/#power-buttons","title":"Power Buttons","text":"ARGON FAN HAT ACTION FUNCTION OFF (FROM SOFT SHUTDOWN) Short Press Turn ON ON Short Press Nothing ON Long Press (&gt; 3 Secs) Initiate Soft Shutdown (NO POWER CUT) ON Double Tap Reboot","tags":["home-assistant","rpi","arm64"]},{"location":"hardware/rpi4/#references","title":"References","text":"<ul> <li>https://github.com/jiangcuo/Proxmox-Port/wiki/Install-Proxmox-VE-on-Debian-bookworm</li> <li>https://mirrors.apqa.cn/proxmox/isos/</li> </ul>","tags":["home-assistant","rpi","arm64"]},{"location":"hardware/rpi5/","title":"Raspberry Pi 5 16GB","text":"<p>My Raspberry Pi 5 16GB is being used as another <code>arm64</code> Proxmox server.</p>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#config","title":"Config","text":"<p>OS: <code>Rasbperry Pi OS Lite (64-bit)</code></p> <p>RAM: <code>16GB</code></p> <p>HAT1: <code>Raspberry Pi Active Cooler</code></p> <p>HAT2: <code>GeeekPi N04 M.2 NVMe to PCIe Adapter</code></p> <p>DRIVE: <code>Crucial P3 500GB PCIe Gen3 3D NAND NVMe M.2 SSD</code></p>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#enable-pcie","title":"Enable PCIe","text":"<p>Tip</p> <p>When connecting the PCIe adapter to the pi, ensure that the correct end of the ribbon cable is being plugged into the correct connector. Typically, the ribbon cable ends are labeled.</p> <p>/boot/firmware/config.txt</p> Automatic Gen 3.0Automatic Gen 2.0Manual Gen 3.0Manual Gen 2.0 <pre><code>echo \"dtparam=pciex1_gen=3\" | sudo tee -a config.txt\n</code></pre> <pre><code>echo \"dtparam=pciex1\" | sudo tee -a config.txt\n</code></pre> <pre><code>dtparam=pciex1_gen=3\n</code></pre> <pre><code>dtparam=pciex1\n</code></pre>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#enable-auto-detection-pcie-and-booting-from-nvme","title":"Enable auto detection PCIe and booting from NVMe","text":"rootsudo <pre><code>rpi-eeprom-config --edit\n</code></pre> <pre><code>sudo rpi-eeprom-config --edit\n</code></pre> <pre><code>PCIE_PROBE=1\n\nBOOT_ORDER=0xf416\n</code></pre> <p>The 6 means to enable booting from nvme. Reboot Raspberry Pi 5 and try to use <code>lsblk</code> or <code>lspci -vvv</code> to get more details of the PCIe device.</p>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#enable-5a-psu","title":"Enable 5A PSU","text":"<p>If <code>apt</code> is slow, it might be due to the pi reducing the power input.</p> rootsudo <pre><code>rpi-eeprom-config --edit\n</code></pre> <pre><code>sudo rpi-eeprom-config --edit\n</code></pre> <pre><code>PSU_MAX_CURRENT=5000\n</code></pre>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#set-resolution","title":"Set Resolution","text":"<p>When using a TV as a temporary monitor, usually when troubleshooting the booting from a USB or NVMe drive, the text size can be way too small. This is how to change the resolution on boot of the command line so that it can be read more easily on the TV.</p> <p>Warning</p> <p>This does not seem to work for the Raspberry Pi 4 for some reason. Perhaps it's the display port mapping?</p> <p><code>/boot/firmware/cmdline.txt</code></p> AutomaticManual <pre><code>sed -i `1s/$/ video=HDMI-A-1:1920x1080M@60D/' /boot/firmware/cmdline.txt\n</code></pre> <pre><code>video=HDMI-A-1:1920x1080M@60D\n</code></pre>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#pxvirt","title":"PXVIRT","text":"<p>Setup LVM first</p>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#setup-raspberry-pi-os","title":"Setup Raspberry Pi OS.","text":"<p>Create a tmp dir</p> <pre><code>cd \"$(mktemp -d)\"\n</code></pre> <p>Download image</p> <pre><code>wget https://downloads.raspberrypi.com/raspios_lite_arm64/images/raspios_lite_arm64-2024-11-19/2024-11-19-raspios-bookworm-arm64-lite.img.xz -O 2024-11-19-raspios-bookworm-arm64-lite.img.xz\n</code></pre> <p>Extract image</p> <pre><code>xz -d 2024-11-19-raspios-bookworm-arm64-lite.img.xz\n</code></pre> <p>Write image to SD card</p> <pre><code>dd if=2024-11-19-raspios-bookworm-arm64-lite.img /dev/mmcblk0 status=progress\n</code></pre> <p>Mount boot partition</p> <pre><code>(\n  [ -d /media/sd ] || mkdir /media/sd\n  sudo mount -a /dev/mmcblk0p1 /media/sd\n)\n</code></pre> <p>Change to boot partition</p> <pre><code>cd /media/sd\n</code></pre>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#create-username-password","title":"Create Username &amp; Password","text":"<p>/boot/firmware/userconf.txt</p> AutomaticManual <pre><code>echo 'nicholas:' \"$(openssl passwd -6)\" | sed 's/ //g' | sudo tee -a userconf.txt\n</code></pre> <pre><code>nicholas:&lt;hash&gt;\n</code></pre>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#enable-ssh","title":"Enable SSH","text":"<p>/boot/ssh</p> <pre><code>touch ssh\n</code></pre>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#kernel-page-size","title":"Kernel Page Size","text":"<p>You should use the Kernel with 4K pagesize</p> <p>/boot/firmware/config.txt</p> Manual <pre><code>kernel=kernel8.img # to end of line\n</code></pre>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#ct-notes","title":"CT Notes","text":"<p>Is the container summary memory usage and swap usage always shows <code>0</code>?</p> <p>/boot/firmware/cmdline.txt</p> AutomaticManual <pre><code>sed -i '1s/$/ cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1/' cmdline.txt\n</code></pre> <pre><code>cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1\n</code></pre> <p>Unmount SD card, plug into the Raspberry Pi and boot</p>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#pxvirt-installation","title":"PXVIRT Installation","text":"<p>Tip</p> <p>Alternatively, the ISO may be downloaded and installed as a removable media.</p> <p>Log into the Raspberry Pi using SSH.</p> <p>Switch to <code>root</code> user. Default password is blank for Raspberry Pi OS.\"</p> <pre><code>sudo su root\n</code></pre> <p>Set root password so that you can log into Proxmox web GUI</p> <pre><code>passwd\n</code></pre> <p>Add an <code>/etc/hosts</code> entry for your IP address.</p> <p>Please make sure that your machine's hostname is resolvable via <code>/etc/hosts</code>, i.e. you need an entry in <code>/etc/hosts</code> which assigns an address to its hostname.</p> <p>Make sure that you have configured one of the following addresses in <code>/etc/hosts</code> for your hostname:</p> <p>1 <code>IPv4</code> or 1 <code>IPv6</code> or 1 <code>IPv4</code> and 1 <code>IPv6</code></p> <p>Note</p> <p>This also means removing the address <code>127.0.1.1</code> that might be present as default.</p> <p>Get IP address</p> <pre><code>hostname -I | awk '{print $1}'\n</code></pre> <p>For instance, if your IP address is <code>192.168.15.77</code>, and your hostname <code>prox4m1</code>, then your <code>/etc/hosts</code> file could look like:</p> <p>/etc/hosts</p> <pre><code>127.0.0.1       localhost.localdomain localhost\n\n::1             localhost ip6-localhost ip6-loopback\nff02::1         ip6-allnodes\nff02::2         ip6-allrouters\n\n192.168.1.192   pve02.nicholaswilde.io pve02\n</code></pre> <p>Test if your setup is ok using the hostname command</p> <pre><code>hostname --ip-address\n</code></pre> <p>should return your IP address here</p> <pre><code>192.168.1.192\n</code></pre>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#install-pxvirt","title":"Install PXVIRT","text":"<p>Warning</p> <p>Proxmox-Port has now been replaced by PXVIRT! The information below may be out of date!</p>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#add-the-pxvirt-repository","title":"Add the PXVIRT repository","text":"<p>/etc/apt/sources.list.d/pxvirt.list</p> AutomaticManual <pre><code>echo 'deb https://download.lierfang.com/pxcloud/pxvirt bookworm main'&gt;/etc/apt/sources.list.d/pxvirt.list\n</code></pre> <pre><code>deb https://download.lierfang.com/pxcloud/pxvirt bookworm main\n</code></pre> <p>Add the PXVIRT repository key</p> <pre><code>curl -L https://mirrors.lierfang.com/proxmox/debian/pveport.gpg -o /etc/apt/trusted.gpg.d/pveport.gpg \n</code></pre> <p>Update repository and system</p> <pre><code>apt update &amp;&amp; apt full-upgrade\n</code></pre> <p>Install <code>ifupdown2</code> and PXVIRT packages</p> <pre><code>apt install --allow-downgrades -y ifupdown2 pxvirt pve-manager=8.3.5-1+port2 qemu-server=8.3.8+port5 postfix open-iscsi\n</code></pre> <p>Configure packages which require user input on installation according to your needs (e.g. Samba asking about WINS/DHCP support). If you have a mail server in your network, you should configure postfix as a satellite system, your existing mail server will then be the relay host which will route the emails sent by the Proxmox server to their final recipient.</p> <p>If you don't know what to enter here, choose local only and leave the system name as is.</p>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#reenable-ssh","title":"Reenable SSH","text":"<p>/etc/ssh/sshd_config</p> AutomaticManual  <pre><code>sudo sed -i 's/^#?\\s*PermitRootLogin\\s+.*/PermitRootLogin yes/' /etc/ssh/sshd_config\n</code></pre> <pre><code>PermitRootLogin yes\n</code></pre> <p>Finally, you can connect to the admin web interface (<code>https://youripaddress:8006</code>).</p>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#network","title":"Network","text":"","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#missing-vmbr0","title":"Missing <code>vmbr0</code>","text":"<p>Warning</p> <p>This should be done before reboot, else you won't be able to connect to the network!</p> <p>Create <code>vmbr0</code> network interface in GUI</p> <pre><code>&lt;node&gt; -&gt; Network -&gt; Create\nName: vmbr0\nIPv4: 192.168.1.192/24\nGateweay: 192.168.1.1 \nBridge Ports: eth0\n</code></pre> <p><code>/etc/network/interfaces</code></p> <pre><code>auto lo\niface lo inet loopback\n\niface eth0 inet manual\n\nauto vmbr0\niface vmbr0 inet static\n        address 192.168.2.192/24\n        gateway 192.168.2.1\n        bridge-ports eth0\n        bridge-stp off\n        bridge-fd 0\n</code></pre> <p>Where <code>eth0</code> is the current existing network interface</p>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#repository-httpdebdebianorgdebian-buster-inrelease-changed-its-version-value-from-to-100-error","title":"Repository 'http://deb.debian.org/debian buster InRelease' changed its 'Version' value from '' to '10.0' Error","text":"<pre><code>apt --allow-releaseinfo-change update\n</code></pre>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#proxmox-ve-helper-scripts","title":"Proxmox VE Helper-Scripts","text":"<pre><code>(\n  bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/misc/update-repo.sh)\" &amp;&amp;\n  bash -c \"$(wget -qLO - https://github.com/community-scripts/ProxmoxVE/raw/main/misc/post-pve-install.sh)\"\n)\n</code></pre>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#swap","title":"Swap","text":"<p>The Raspberry Pi uses <code>dphys-swapfile</code> to manage it's swap.</p> <p>For Proxmox, I'm using a logical volume instead of a swap file.</p>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#change-swap-size","title":"Change Swap Size","text":"<p>Check the free space</p> <pre><code>free -h\n</code></pre> <p>Turn of swap</p> <pre><code>dphys-swapfile swapoff\n</code></pre> <p>Update size in <code>/etc/dphys-swapfile</code></p> <pre><code>CONF_SWAPSIZE=2048\n</code></pre> <p>Resetup swap and turn it back on</p> <pre><code>(\n  dphys-swapfile setup\n  dphys-swapfile swapon\n)\n</code></pre> <p>Check for the new size</p> <pre><code>free -h\n</code></pre>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#disable-permanently","title":"Disable Permanently","text":"<p>Disable dphys-swapfile temporarily</p> <pre><code>dphys-swapfile swapoff\n</code></pre> <p>Stop the service</p> <pre><code>systemctl stop dphys-swapfile\n</code></pre> <p>Disable the service</p> <pre><code>systemctl disable dphys-swapfile\n</code></pre> <p>Remove the swap file to save disk space</p> <pre><code>rm /var/swap\n</code></pre>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#lvm","title":"LVM","text":"<p>See LVM.</p>","tags":["rpi","proxmox","arm64"]},{"location":"hardware/rpi5/#references","title":"References","text":"<ul> <li>https://a.co/d/etvDazc</li> </ul>","tags":["rpi","proxmox","arm64"]},{"location":"reference/emoji/","title":"Emoji","text":"<p>Emoji that are used on this site.</p> Short code Heading <code>## :hammer_and_wrench: Installation</code>  Installation <code>## :pushpin: TL;DR</code>  TL;DR <code>## :gear: Config</code>  Config <code>## :pencil: Usage</code>  Usage <code>## :simple-task: Task</code>  Task List <code>## :simple-traefikproxy: Traefik</code>  Traefik <code>## :rocket: Upgrade</code>  Upgrade <code>## :stethoscope: Troubleshooting</code>  Troubleshooting <code>## :link: Reference</code>  Reference","tags":["reference"]},{"location":"reference/emoji/#reference","title":"Reference","text":"<ul> <li>https://emojipedia.org/</li> <li>https://emojidb.org/</li> </ul>","tags":["reference"]},{"location":"reference/tags/","title":"Tags","text":"<p>Following is a list of relevant tags:</p> <p>[TAGS]</p>","tags":["reference"]},{"location":"tools/apprise/","title":"Apprise","text":"<p>Apprise is used as a notification app that supports multiple protocols and integrations.</p>","tags":["tool","notifications"]},{"location":"tools/apprise/#installation","title":"Installation","text":"apt <pre><code>apt install apprise\n</code></pre>","tags":["tool","notifications"]},{"location":"tools/apprise/#config","title":"Config","text":"","tags":["tool","notifications"]},{"location":"tools/apprise/#email","title":"Email","text":"<p>Note</p> <p>Google Users using the 2 Step Verification Process will be required to generate an app-password from here that you can use in the <code>passkey</code> field.</p> <p>Notification URL List</p> <pre><code>mailto://user:passkey@gmail.com\n</code></pre>","tags":["tool","notifications"]},{"location":"tools/apprise/#usage","title":"Usage","text":"<p>Example</p> <pre><code>apprise -vv -t 'my title' -b 'my notification body' 'mailto://user:passkey@gmail.com'\n</code></pre>","tags":["tool","notifications"]},{"location":"tools/apprise/#references","title":"References","text":"<ul> <li>https://github.com/caronc/apprise</li> </ul>","tags":["tool","notifications"]},{"location":"tools/autofs/","title":"Autofs","text":"<p>Autofs is used to automatically connect to my NFS storage on my containers/VMs so that they can share storage.</p>","tags":["tool"]},{"location":"tools/autofs/#installation","title":"Installation","text":"<pre><code>apt install autofs\n</code></pre>","tags":["tool"]},{"location":"tools/autofs/#client","title":"Client","text":"<pre><code>(\n  apt install -y autofs &amp;&amp; \\\n  echo '/mnt /etc/auto.nfs --ghost --timeout=60' | tee -a /etc/auto.master &amp;&amp; \\\n  echo 'storage -fstype=nfs4,rw,insecure 192.168.2.19:/storage' | tee -a /etc/auto.nfs &amp;&amp; \\\n  service autofs restart &amp;&amp; \\\n  service autofs status\n)\n</code></pre>","tags":["tool"]},{"location":"tools/autofs/#references","title":"References","text":"","tags":["tool"]},{"location":"tools/bat/","title":"bat","text":"<p>bat is a <code>cat</code> clone with syntax highlighting and Git integration.</p>","tags":["tool"]},{"location":"tools/bat/#installation","title":"Installation","text":"<p><code>bat</code> is available in the <code>reprepro</code> repository.</p> amd64arm64 <pre><code>sudo apt update\nsudo apt install bat\n</code></pre> <pre><code>sudo apt update\nsudo apt install bat\n</code></pre> <p>On Debian and Ubuntu, the executable might be installed as <code>batcat</code> instead of <code>bat</code> due to a name conflict with another package. To use <code>bat</code> directly, you can create a symbolic link or an alias:</p> <p>Symbolic Link</p> <pre><code>mkdir -p ~/.local/bin\nln -s /usr/bin/batcat ~/.local/bin/bat\n</code></pre> <p>Alias</p> <pre><code>echo \"alias bat='batcat'\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>","tags":["tool"]},{"location":"tools/bat/#config","title":"Config","text":"<p><code>bat</code> can be configured using a configuration file. You can find the default configuration directory by running <code>bat --config-dir</code>.</p> <p>To set a theme permanently, you can export the <code>BAT_THEME</code> environment variable in your shell's configuration file (e.g., <code>.bashrc</code> or <code>.zshrc</code>).</p> <p>Set Theme</p> <pre><code>export BAT_THEME=\"TwoDark\"\n</code></pre> <p>You can also add new themes by creating a <code>themes</code> folder within <code>bat</code>'s configuration directory and rebuilding the cache.</p> <p>Add Themes</p> <pre><code>mkdir -p \"$(bat --config-dir)/themes\"\n# Add theme files to the directory\nbat cache --build\n</code></pre>","tags":["tool"]},{"location":"tools/bat/#catppuccin-theme","title":"Catppuccin Theme","text":"<p>To install the Catppuccin theme for <code>bat</code>, follow these steps:</p> <p>Install Catppuccin Theme</p> <pre><code>mkdir -p \"$(bat --config-dir)/themes\"\nwget -P \"$(bat --config-dir)/themes\" https://github.com/catppuccin/bat/raw/main/themes/Catppuccin-mocha.tmTheme\nbat cache --build\n</code></pre> <p>To use the Catppuccin theme, set <code>BAT_THEME</code> to <code>Catppuccin-mocha</code>:</p> <p>Set Catppuccin Theme</p> <pre><code>export BAT_THEME=\"Catppuccin-mocha\"\n</code></pre>","tags":["tool"]},{"location":"tools/bat/#usage","title":"Usage","text":"<p>To view a file:</p> <pre><code>bat filename.txt\n</code></pre> <p>To not show line numbers:</p> <pre><code>bat -p config.yaml\n</code></pre> <p>To show line numbers:</p> <pre><code>bat -n config.yaml\n</code></pre> <p>To concatenate multiple files:</p> <pre><code>bat file1.txt file2.txt\n</code></pre>","tags":["tool"]},{"location":"tools/bat/#references","title":"References","text":"<ul> <li>https://github.com/sharkdp/bat</li> <li>https://github.com/catppuccin/bat</li> </ul>","tags":["tool"]},{"location":"tools/cheat/","title":"cheat","text":"<p><code>cheat</code> allows you to create and view interactive cheatsheets on the command-line. It was designed to help remind *nix system administrators of options for commands that they use frequently, but not frequently enough to remember.</p> <p>I use this rather than cheat.sh because I can more easily add and edit my own cheatsheets.</p>","tags":["lxc","proxmox","tool"]},{"location":"tools/cheat/#installation","title":"Installation","text":"<pre><code>curl https://installer.l.nicholaswilde.io/cheat/cheat?type=script | bash\n</code></pre>","tags":["lxc","proxmox","tool"]},{"location":"tools/cheat/#config","title":"Config","text":"<p>Make the config dir</p> <pre><code>mkdir -p ~/.config/cheat\n</code></pre> <p>~/.config/cheat/conf.yml</p> AutomatedManual <pre><code>cat &gt; ~/.config/cheat/conf.yml &lt;&lt;EOF\n---\ncheatpaths:\n  - name: community                \n    path: /mnt/storage/cheat/cheatsheets/community\n    tags: [ community ]            \n    readonly: true\n\n  - name: personal\n    path: /mnt/storage/cheat/cheatsheets/personal  # this is a separate directory and repository than above\n    tags: [ personal ]\n    readonly: false\nEOF\n</code></pre> <pre><code>---\ncheatpaths:\n  - name: community                \n    path: /mnt/storage/cheat/cheatsheets/community\n    tags: [ community ]            \n    readonly: true\n\n  - name: personal\n    path: /mnt/storage/cheat/cheatsheets/personal\n    tags: [ personal ]\n    readonly: false \n</code></pre> <p>Download cheatsheets locally</p> <pre><code>(\n  mkdir -p /mnt/storage/cheat/cheatsheets\n  git clone git@github.com:nicholaswilde/cheatsheets.git /mnt/storage/cheat/cheatsheets/personal\n)\n</code></pre>","tags":["lxc","proxmox","tool"]},{"location":"tools/cheat/#usage","title":"Usage","text":"<p>Show gpg cheatsheet</p> <pre><code>cheat gpg\n</code></pre> <p>Edit gpg cheatsheet</p> <pre><code>cheat -e gpg\n</code></pre>","tags":["lxc","proxmox","tool"]},{"location":"tools/cheat/#references","title":"References","text":"","tags":["lxc","proxmox","tool"]},{"location":"tools/docker-volume-backup/","title":"docker-volume-backup","text":"<p>docker-volume-backup (<code>dvb</code>) is used to backup Docker volumes locally or to any S3, WebDAV, Azure Blob Storage, Dropbox or SSH compatible storage.</p>","tags":["lxc","proxmox","docker"]},{"location":"tools/docker-volume-backup/#installation","title":"Installation","text":"<p><code>dvb</code> is used as a docker container inside of an already existing Docker compose file.</p>","tags":["lxc","proxmox","docker"]},{"location":"tools/docker-volume-backup/#config","title":"Config","text":"<p>This example backs up two volumes in the same compose volume, <code>postgres_data</code> and <code>minio_data</code>.</p> <p>compose.yaml</p> <pre><code>---\nservices:\n  # https://offen.github.io/docker-volume-backup/\n  backup_postgres: &amp;backup_service\n    image: offen/docker-volume-backup:v2.44.0\n    environment: &amp;backup_environment\n      BACKUP_FILENAME: backup-%Y-%m-%dT%H-%M-%S.tar.gz\n      BACKUP_LATEST_SYMLINK: backup-postgres-latest.tar.gz\n      BACKUP_PRUNING_PREFIX: backup-postgres-\n      BACKUP_RETENTION_DAYS: '14'\n      AGE_PUBLIC_KEYS: \"${AGE_PUBLIC_KEYS}\"\n      BACKUP_STOP_DURING_BACKUP_LABEL: service-postgres\n    volumes:\n      - postgres_data:/backup/my-app-backup:ro\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      # - ${HOME}/backups:/archive\n      - /mnt/storage/backup/reactive-resume:/archive\n      - /etc/timezone:/etc/timezone:ro\n      - /etc/localtime:/etc/localtime:ro\n\n  backup_minio:\n    &lt;&lt;: *backup_service\n    environment:\n      &lt;&lt;: *backup_environment\n      BACKUP_FILENAME: backup2-%Y-%m-%dT%H-%M-%S.tar.gz\n      BACKUP_LATEST_SYMLINK: backup-minio-latest.tar.gz\n      BACKUP_PRUNING_PREFIX: backup-minio-\n      BACKUP_STOP_DURING_BACKUP_LABEL: service-minio\n    volumes:\n      - minio_data:/backup/my-app-backup:ro\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      # - ${HOME}/backups:/archive\n      - /mnt/storage/backup/reactive-resume:/archive\n      - /etc/timezone:/etc/timezone:ro\n      - /etc/localtime:/etc/localtime:ro\n      # OPENID_USER_INFO_URL:\n\nvolumes:\n  minio_data:\n  postgres_data:\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"tools/docker-volume-backup/#usage","title":"Usage","text":"<p>Backup Manually</p> <pre><code>docker exec &lt;container_ref&gt; backup\n</code></pre>","tags":["lxc","proxmox","docker"]},{"location":"tools/docker-volume-backup/#references","title":"References","text":"<ul> <li>https://offen.github.io/docker-volume-backup/</li> </ul>","tags":["lxc","proxmox","docker"]},{"location":"tools/duf/","title":"duf","text":"<p>duf is a Disk Usage Free Utility.</p>","tags":["tool"]},{"location":"tools/duf/#installation","title":"Installation","text":"repreproaptbrew <pre><code>sudo apt install duf\n</code></pre> <pre><code>sudo apt install duf\n</code></pre> <pre><code>brew install duf\n</code></pre>","tags":["tool"]},{"location":"tools/duf/#usage","title":"Usage","text":"<p>1. Show disk usage</p> <pre><code>duf\n</code></pre> <p>2. Show all file systems, including pseudo, duplicate, and inaccessible file systems</p> <pre><code>duf --all\n</code></pre> <p>3. List only local file systems</p> <pre><code>duf --local\n</code></pre> <p>4. Sort the output by a specific column</p> <pre><code>duf --sort size\n</code></pre>","tags":["tool"]},{"location":"tools/duf/#references","title":"References","text":"<ul> <li>https://github.com/muesli/duf</li> </ul>","tags":["tool"]},{"location":"tools/env-files/","title":".env Files","text":"<p><code>.env</code> files are used to store variables and secrets. There are used whenver possible.</p> <p>Note</p> <p>Because they can hold secrets, they are ignored by git.</p>","tags":["tool"]},{"location":"tools/env-files/#template","title":"Template","text":"<p>Since the file is ignored by git, the template file may be copied, if it exists.</p> <p>.env.tmpl</p> <pre><code>cp .env.tmpl .env\n</code></pre>","tags":["tool"]},{"location":"tools/env-files/#secrets","title":"Secrets","text":"<p>If secrets are kept in the <code>.env</code> file, the file is encrypted using SOPS and stored as <code>.env.enc</code>.</p> <p>Warning</p> <p>Storing encrypted secrets in a public repo is risky and is not recommended!</p>","tags":["tool"]},{"location":"tools/env-files/#service","title":"Service","text":"<p>appname.service</p> <pre><code>[Service]\nEnvironmentFile=/root/git/nicholaswilde/homelab/pve/appname/.env\n</code></pre>","tags":["tool"]},{"location":"tools/env-files/#task","title":"Task","text":"<p>Taskfile.yml</p> <pre><code>dotenv:\n  - .env\n</code></pre>","tags":["tool"]},{"location":"tools/env-files/#docker-compose","title":"Docker Compose","text":"<p>compose.yaml</p> <pre><code>services:\n  appname:\n    env_file:\n      - .env\n</code></pre>","tags":["tool"]},{"location":"tools/env-files/#shell-script","title":"Shell Script","text":"<p>script.sh</p> <pre><code>DEFAULT_VALUE=foo\nsource .env\n</code></pre>","tags":["tool"]},{"location":"tools/env-files/#references","title":"References","text":"<ul> <li>https://www.dotenv.org/docs/security/env</li> </ul>","tags":["tool"]},{"location":"tools/eza/","title":"eza","text":"<p>eza is a modern alternative to <code>ls</code>.</p>","tags":["tool"]},{"location":"tools/eza/#installation","title":"Installation","text":"repreproaptbrew <pre><code>sudo apt install eza\n</code></pre> <pre><code>sudo mkdir -p /etc/apt/keyrings\nwget -qO- https://raw.githubusercontent.com/eza-community/eza/main/deb.asc | sudo gpg --dearmor -o /etc/apt/keyrings/gierens.gpg\necho \"deb [signed-by=/etc/apt/keyrings/gierens.gpg] http://deb.gierens.de stable main\" | sudo tee /etc/apt/sources.list.d/gierens.list\nsudo chmod 644 /etc/apt/keyrings/gierens.gpg /etc/apt/sources.list.d/gierens.list\nsudo apt update\nsudo apt install -y eza\n</code></pre> <pre><code>brew install eza\n</code></pre>","tags":["tool"]},{"location":"tools/eza/#config","title":"Config","text":"<p>eza is backeard compatible with <code>ls</code> so you can add to your bash aliases and map it to <code>ls</code>.</p> <p>~/.bashrc</p> <pre><code># Check if command exists\nfunction command_exists(){\n  command -v \"${1}\" &amp;&gt; /dev/null\n}\n\nif command_exists eza; then\n  alias ls='eza'\nfi\n</code></pre> <pre><code>source ~/.bashrc\n</code></pre>","tags":["tool"]},{"location":"tools/eza/#usage","title":"Usage","text":"<p>Here are some common ways to use <code>eza</code>, demonstrating its features beyond the standard <code>ls</code>.</p> <p>Show detailed long view, all files (including hidden), with a header</p> <pre><code>eza -la --header\n</code></pre> <p>Display files as a tree (limited to 2 levels deep)</p> <pre><code>eza --tree --level=2\n</code></pre> <p>Tip</p> <p>Requires a Nerd Font to render icons</p> <p>A common alias: long format, all files, icons, and Git status</p> <pre><code>eza -la --icons --git\n</code></pre> <p>Sort by file size, largest first</p> <pre><code>eza -l --sort=size --reverse\n</code></pre>","tags":["tool"]},{"location":"tools/eza/#references","title":"References","text":"","tags":["tool"]},{"location":"tools/fd/","title":"fd","text":"<p>fd is a simple, fast, and user-friendly alternative to <code>find</code>.</p>","tags":["tool"]},{"location":"tools/fd/#installation","title":"Installation","text":"repreproaptbrew <pre><code>sudo apt install fd-find\n</code></pre> <pre><code>sudo apt install fd-find\n</code></pre> <pre><code>brew install fd\n</code></pre>","tags":["tool"]},{"location":"tools/fd/#config","title":"Config","text":"<p><code>fd</code> can be configured with a configuration file. By default, <code>fd</code> will look for a configuration file in <code>$XDG_CONFIG_HOME/fd/config</code> or <code>$HOME/.fdrc</code>.</p> <p>$HOME/.fdrc</p> <pre><code>--hidden\n--exclude .git\n</code></pre>","tags":["tool"]},{"location":"tools/fd/#usage","title":"Usage","text":"<p>1. Find files by name</p> <pre><code>fd \"pattern\"\n</code></pre> <p>2. Find files by extension</p> <pre><code>fd -e js\n</code></pre> <p>3. Execute a command on found files</p> <pre><code>fd \".md\" -exec wc -l\n</code></pre> <p>4. Search hidden files and directories</p> <pre><code>fd -H \"pattern\"\n</code></pre>","tags":["tool"]},{"location":"tools/fd/#references","title":"References","text":"<ul> <li>https://github.com/sharkdp/fd</li> </ul>","tags":["tool"]},{"location":"tools/google-gemini-cli/","title":"Google Gemini CLI","text":"<p>Google Gemini CLI is used as an AI agent that can be used directly in a terminal.</p> <p>I use the Gemini CLI to help generate bash script files and markdown documents for mkdocs-material. It is my preferred coding agent at the moment since I already pay for Google One.</p>","tags":["tools"]},{"location":"tools/google-gemini-cli/#installation","title":"Installation","text":"<p> Config path: <code>~/.gemini/</code></p> npxnpm <pre><code>npx https://github.com/google-gemini/gemini-cli\n</code></pre> <pre><code>sudo npm install -g @google/gemini-cli\n</code></pre> <pre><code>gemini\n</code></pre>","tags":["tools"]},{"location":"tools/google-gemini-cli/#config","title":"Config","text":"<ol> <li>Generate a key from Google AI Studio.</li> <li>Set it as an environment variable in your terminal. Replace <code>YOUR_API_KEY</code> with your generated key.</li> </ol> .envManual <pre><code>export GEMINI_API_KEY=\"YOUR_API_KEY\"\n</code></pre> <pre><code>export GEMINI_API_KEY=\"YOUR_API_KEY\"\n</code></pre>","tags":["tools"]},{"location":"tools/google-gemini-cli/#syntax-files","title":"Syntax Files","text":"<p>Syntax files are used to customize the iutput from Gemini.</p> docs/GEMINI.md <pre><code># New PVE Application Guidelines for Gemini\n\n**Context:** This directory contains all Proxmox LXC applications.\n- The `.template` folder is to be used as a template folder for new applications.\n\n## Creating a New PVE Application\n\nTo create a new Proxmox LXC application, follow these steps:\n\n1. **Copy the template:** Copy the `.template` directory to a new directory named after your application (e.g., `my-app/`).\n\n2. **Update the files:** The following files need to be updated with the new application's information:\n\n    - The app is a typical Debian based application.\n    - `README.md`: This is the documentation for the application.\n      - Update the `APP_NAME` to the new application's name.\n    - `Taskfile.yml`: This file contains tasks for managing the application.\n      - Update the service name from `{{ APP_NAME | lower }}` to your application's name.\n      - Read environmental variables from the application and add them to the `Taskfile.yml` if needed.\n      - Get the following values from the application properties:\n        - `CONFIG_DIR` is the location of the app config dir, usually in the `/etc` folder.\n        - `INSTALL_DIR` is the location of the app folder, usually in the `/opt/` folder.\n        - `SERVICE_NAME` is the name of the `systemctl` service of the app.\n    - `task-list.txt`: This file contains a list of tasks for the application.\n    - `update.sh`: This script updates the application. Use standard Debian application practices to update the app.\n      - Can model the update script from https://community-scripts.github.io/ProxmoxVE/scripts for `amd64` apps or https://pimox-scripts.com/scripts for `arm64` apps.\n\n3.  **Finalize:** Once you have updated these files, you can remove any placeholder values.\n</code></pre> <p>AGENTS.md files can also be used to enable the use of other AI agents.</p> <p>Enable <code>gemini-cli</code> to use <code>AGENTS.md</code> files.</p> <p>~/.gemini/settings.json</p> <pre><code>{ \"contextFileName\": \"AGENTS.md\" }\n</code></pre>","tags":["tools"]},{"location":"tools/google-gemini-cli/#usage","title":"Usage","text":"<p>Once installed and authenticated, start interacting with Gemini from the shell.</p> <p>Example</p> <pre><code>git clone https://github.com/google-gemini/gemini-cli\ncd gemini-cli\ngemini\n&gt; Give me a summary of all of the changes that went in yesterday\n</code></pre> <p>Start a chat</p> <pre><code>gemini\n</code></pre> <p>Pipe content to the CLI from <code>stdin</code></p> <pre><code>echo \"Explain the content of this file docs/README.md\" | gemini -p\n</code></pre>","tags":["tools"]},{"location":"tools/google-gemini-cli/#references","title":"References","text":"<ul> <li>https://github.com/google-gemini/gemini-cli</li> </ul>","tags":["tools"]},{"location":"tools/jinja2-cli/","title":"jinja2-cli","text":"<p>jinja2-cli is used as a template engine to help generate documents, such as mkdocs markdown pages or traefik config files.</p>","tags":["tool"]},{"location":"tools/jinja2-cli/#installation","title":"Installation","text":"pipx <pre><code>pipx install jinja2-cli\n</code></pre>","tags":["tool"]},{"location":"tools/jinja2-cli/#usage","title":"Usage","text":"<p>Example</p> <pre><code>jinja2 .template.md.j2 -D APP_NAME=\"New App\" -D APP_PORT=8080 -D CONFIG_PATH=/opt/new-app &gt; new-app.md\n</code></pre>","tags":["tool"]},{"location":"tools/jinja2-cli/#references","title":"References","text":"","tags":["tool"]},{"location":"tools/localsend/","title":"LocalSend","text":"<p>LocalSend is a free and open-source cross-platform app that allows you to securely share files and messages with nearby devices over your local network without the need for an internet connection.</p>","tags":["tool"]},{"location":"tools/localsend/#installation","title":"Installation","text":"aptbrew <pre><code>sudo apt install localsend\n</code></pre> <pre><code>brew install localsend\n</code></pre>","tags":["tool"]},{"location":"tools/localsend/#usage","title":"Usage","text":"<p>1. Send a file</p> <pre><code>localsend send &lt;file_path&gt;\n</code></pre> <p>2. Receive files</p> <pre><code>localsend receive\n</code></pre> <p>3. List nearby devices</p> <pre><code>localsend discover\n</code></pre>","tags":["tool"]},{"location":"tools/localsend/#references","title":"References","text":"<ul> <li>https://github.com/localsend/localsend</li> </ul>","tags":["tool"]},{"location":"tools/lvm/","title":"LVM","text":"<p>By default, Raspberry Pi OS does not come with LVM. However, LVM is useful for taking snapshots in Proxmox.</p>","tags":["proxmox","rpi","rpi4","rpi5"]},{"location":"tools/lvm/#setup","title":"Setup","text":"<p>The main setup concept is as follows:</p> <ol> <li>Create an SD card with a stock Raspberry Pi OS on a host system.</li> <li>Install necessary packages on SD card.</li> <li>Generate new <code>initramfs</code> on the Pi.</li> <li>Backup the OS to a <code>tar</code> file from the host system.</li> <li>Create file system on new NVMe drive.</li> <li>Mount new file system drive.</li> <li>Extract <code>tar</code> to new drive.</li> <li>Modify boot on new drive.</li> <li>Boot new drive.</li> </ol>","tags":["proxmox","rpi","rpi4","rpi5"]},{"location":"tools/lvm/#equipment","title":"Equipment","text":"<p>The following equipment was used:</p> <ol> <li>Raspberry Pi 5 with SD card and an NVMe hat.</li> <li>Host computer with Ubuntu server installed that can read an SD card.</li> <li>SD card.</li> <li>500GB NVMe.</li> </ol> <p>Note</p> <p>My setup can only read NVMe drives from my Pi and so all of my interfacing with the NVMe is done while booted into the SD card on the Pi.</p> <p>Note</p> <p>I have an NVMe drive on my Pi, therefore my commnds below are with respect to <code>/dev/nvme0n1</code> when working with it.</p> <p>Note</p> <p>When working with my SD card mounted on my host system, the drive location is <code>/dev/mmcblk0</code></p> <p>Note</p> <p>Most of the mounting of file systems is being done in the <code>/mnt</code> directory of both the Pi and host system.</p>","tags":["proxmox","rpi","rpi4","rpi5"]},{"location":"tools/lvm/#host-system","title":"Host System","text":"<p>Install Raspberry Pi OS on an SD card.</p>","tags":["proxmox","rpi","rpi4","rpi5"]},{"location":"tools/lvm/#sd-card","title":"SD Card","text":"<p>Insert SD card into Pi and boot from SD card.</p> <p>Switch to <code>root</code></p> <pre><code>sudo su\n</code></pre> <p>Update the Pi</p> <pre><code>(\n  apt update\n  apt full-upgrade\n)\n</code></pre> <p>Install <code>lvm2</code> and <code>initramfs-tools</code></p> <pre><code>(\n  apt install initramfs-tools\n  apt install lvm2 -y\n)\n</code></pre> <p>Update <code>initramfs</code></p> <pre><code>update-initramfs -u -k all\n</code></pre> <p>Note</p> <p>Updating initramfs may not be needed because it may update itself during the <code>lvm2</code> installation.</p> <p>Shutown the Pi</p> <pre><code>poweroff\n</code></pre>","tags":["proxmox","rpi","rpi4","rpi5"]},{"location":"tools/lvm/#host-system_1","title":"Host System","text":"<p>Remove the SD card from the Pi and insert it back into the host system.</p> <p>Switch to <code>root</code></p> <pre><code>sudo su\n</code></pre> <p>Get the <code>/dev</code> drive location</p> <pre><code>lsblk\n</code></pre> Output<pre><code>NAME         MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\nmmcblk0      179:0    0 119.1G  0 disk \n\u251c\u2500mmcblk0p1  179:1    0   512M  0 part /boot/firmware\n\u2514\u2500mmcblk0p2  179:2    0 118.6G  0 part /\nnvme0n1      259:0    0 465.8G  0 disk\n</code></pre> <p>Set the drive location</p> <pre><code>DRIVE=mmcblk0p\n</code></pre> <p>Note</p> <p>The <code>p</code> needs to be added to the end of the drive if using an SD card or NVMe drive.</p> <p>Mount the SD card partitions and archive the contents to a <code>tar</code> file</p> <pre><code>(\n  cd /mnt\n  mount /dev/${DRIVE}2 ./rpi\n  mkdir -p rpi/boot/firmware\n  mount /dev/${DRIVE}1 ./rpi/boot/firmware\n  tar -cvzf rpi.tar.gz -C rpi ./\n  umount ./rpi/boot/firmware\n  umount ./rpi\n)\n</code></pre> <p>The SD card is not archived into the <code>/mnt/rpi.tar.gz</code> file on the host system.</p> <p>Check the <code>tar</code> file before using it</p> <pre><code>tar -tvf /mnt/rpi.tar.gz\n</code></pre>","tags":["proxmox","rpi","rpi4","rpi5"]},{"location":"tools/lvm/#sd-card_1","title":"SD Card","text":"<p>Insert SD card into Pi and boot from SD card.</p> <p>Using <code>parted</code>, remove all partitions from the NVMe.  </p> <p>Warning</p> <p>THIS DESTROYS ALL EXISTING DATA ON THE NVMe</p> <p>Switch to <code>root</code></p> <pre><code>sudo su\n</code></pre> <p>Set the drive location</p> <pre><code>DRIVE=nvme0n1p\n</code></pre> <p>Note</p> <p>The <code>p</code> needs to be added to the end of the drive if using an SD card or NVMe drive.</p> <p>Code</p> <pre><code>parted /dev/${DRIVE%p}\n</code></pre> <p>Identify the partition number: Once inside the parted interactive shell (you'll see a (parted) prompt), use the print command to list the partitions on the selected disk and find the number of the one you want to delete.</p> <p>Code</p> <pre><code>(parted) print\n</code></pre> <p>Look at the output to identify the correct partition number (the first column).</p> <pre><code>(parted) rm 2\n</code></pre> <pre><code>(parted) rm 1\n</code></pre> <pre><code>(parted) quit\n</code></pre> <p>Check that the partitions were deleted</p> <pre><code>lsblk\n</code></pre> Output<pre><code>NAME         MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\nmmcblk0      179:0    0 119.1G  0 disk \n\u251c\u2500mmcblk0p1  179:1    0   512M  0 part /boot/firmware\n\u2514\u2500mmcblk0p2  179:2    0 118.6G  0 part /\nnvme0n1      259:0    0 465.8G  0 disk \n</code></pre> <p>Create a 500MB FAT32 partition and the remainder of the disk as an LVM partition</p> <pre><code>(\n  parted /dev/${DRIVE%p} mkpart primary fat32 2048s 512MiB &amp;&amp; \\\n  parted /dev/${DRIVE%p} mkpart primary ext4 512MiB 100% &amp;&amp; \\\n  parted /dev/${DRIVE%p} set 2 lvm on\n)\n</code></pre> <p>Check that the partitions were created successfully</p> <pre><code>lsblk\n</code></pre> Output<pre><code>NAME         MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\nmmcblk0      179:0    0 119.1G  0 disk \n\u251c\u2500mmcblk0p1  179:1    0   512M  0 part /boot/firmware\n\u2514\u2500mmcblk0p2  179:2    0 118.6G  0 part /\nnvme0n1      259:0    0 465.8G  0 disk \n\u251c\u2500nvme0n1p1  259:1    0   511M  0 part \n\u2514\u2500nvme0n1p2  259:2    0 465.3G  0 part\n</code></pre> <p>Format and label the FAT partition</p> <pre><code>mkfs.fat -F 32 -n bootfs-rpi /dev/${DRIVE}1\n</code></pre> <p>Setup LVM on the NVMe drive, create and format the root volume</p> <pre><code>(\n  pvcreate /dev/${DRIVE}2 &amp;&amp; \\\n  vgcreate pve /dev/${DRIVE}2 &amp;&amp; \\\n  lvcreate -L 70G -n root pve &amp;&amp; \\\n  mke2fs -t ext4 -L pve /dev/pve/root\n)\n</code></pre> <p>Check that the volumes were created successfully</p> <pre><code>lsblk\n</code></pre> Output<pre><code>NAME         MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\nmmcblk0      179:0    0 119.1G  0 disk \n\u251c\u2500mmcblk0p1  179:1    0   512M  0 part /boot/firmware\n\u2514\u2500mmcblk0p2  179:2    0 118.6G  0 part /\nnvme0n1      259:0    0 465.8G  0 disk \n\u251c\u2500nvme0n1p1  259:1    0   511M  0 part \n\u2514\u2500nvme0n1p2  259:2    0 465.3G  0 part \n  \u2514\u2500pve-root 254:0    0    30G  0 lvm\n</code></pre> <p>Transfer the archived tar file from the host system using SCP</p> <pre><code>scp user@hostip:/mnt/rpi.tar.gz /mnt\n</code></pre> <p>Mount the USB partitions and restore the contents</p> <pre><code>(\n  cd /mnt &amp;&amp; \\\n  mkdir -p ./rpi/boot/firmware &amp;&amp; \\\n  mount /dev/pve/root rpi &amp;&amp; \\\n  mount /dev/${DRIVE}1 ./rpi/boot/firmware &amp;&amp; \\\n  tar -xvzf rpi.tar.gz -C ./rpi\n)\n</code></pre> <p>Check that the contents transferred successfully</p> <pre><code>ls rpi\n</code></pre> Output<pre><code>bin  boot  dev  etc  home  lib  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\n</code></pre> <p>Note</p> <p>Don't seem to need to change <code>config.txt</code> with <code>initramfs</code>.</p> <p><code>./rpi/etc/fstab</code></p> AutomaticManual <pre><code>(\n  sed -i 's/^PARTUUID=[a-z0-9]*-01/\\/dev\\/'\"${DRIVE}\"'1/' /mnt/rpi/etc/fstab &amp;&amp; \\\n  sed -i 's/^PARTUUID=[a-z0-9]*-02/\\/dev\\/pve\\/root/' /mnt/rpi/etc/fstab &amp;&amp; \\\n  cat /mnt/rpi/etc/fstab\n)\n</code></pre> <pre><code>proc            /proc           proc    defaults          0       0\n/dev/nvme0n1p1  /boot/firmware  vfat    defaults          0       2\n/dev/pve/root  /               ext4    defaults,noatime  0       1\n</code></pre> <p><code>./rpi/boot/firmware/cmdline.txt</code></p> AutomaticManual <pre><code>(\n  sed -i 's/root=PARTUUID=[a-z0-9]*-02/root=\\/dev\\/pve\\/root/' /mnt/rpi/boot/firmware/cmdline.txt &amp;&amp; \\\n  cat /mnt/rpi/boot/firmware/cmdline.txt\n)\n</code></pre> <pre><code>console=serial0,115200 console=tty1 root=/dev/pve/root rootfstype=ext4 fsck.repair=yes rootwait cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1\n</code></pre> <p>Unmount the partitions</p> <pre><code>(\n  cd /mnt &amp;&amp; \\\n  umount ./rpi/boot/firmware/ &amp;&amp; \\\n  umount ./rpi/ &amp;&amp; \\\n  rm -r rpi/\n)\n</code></pre> <p>Reboot and hold the <code>spacebar</code> to get to the boot menu. Choose <code>6</code> for NVMe.</p> <p>Verify that it's booting from the NVMe</p> <pre><code>lsblk\n</code></pre> Output<pre><code>NAME         MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\nmmcblk0      179:0    0 119.1G  0 disk \n\u251c\u2500mmcblk0p1  179:1    0   512M  0 part \n\u2514\u2500mmcblk0p2  179:2    0 118.6G  0 part \nnvme0n1      259:0    0 465.8G  0 disk \n\u251c\u2500nvme0n1p1  259:1    0   511M  0 part /boot/firmware\n\u2514\u2500nvme0n1p2  259:2    0 465.3G  0 part \n  \u251c\u2500pve-swap 254:0    0     8G  0 lvm  \n  \u2514\u2500pve-root 254:1    0    70G  0 lvm  /\n</code></pre> <p>If successful, use <code>raspi-config</code> to set the boot order to be NVMe drive first.</p>","tags":["proxmox","rpi","rpi4","rpi5"]},{"location":"tools/lvm/#swap","title":"Swap","text":"<p>This sets up a logical volume for swap instead of using the default Raspberry Pi OS file swap.</p> <p>Disable <code>dphys-swapfile</code> file swap.</p> <p>Create the LVM2 logical volume of 8GB</p> <pre><code>lvm lvcreate pve -n swap -L 8G\n</code></pre> <p>Format the new swap space</p> <pre><code>mkswap /dev/pve/swap\n</code></pre> <p>Check that the volume was created</p> <pre><code>lvdisplay\n</code></pre> Output<pre><code>  --- Logical volume ---\n  LV Path                /dev/pve/swap\n  LV Name                swap\n  VG Name                pve\n  LV UUID                Gb7n93-OBv9-YtPu-vz7K-GeXK-G5fY-W2QQ3T\n  LV Write Access        read/write\n  LV Creation host, time raspberrypi, 2025-03-30 05:11:22 +0100\n  LV Status              available\n  # open                 0\n  LV Size                8.00 GiB\n  Current LE             2048\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           254:0    \n</code></pre> <p><code>/etc/fstab</code></p> Manual <pre><code> /dev/pve/swap swap swap defaults 0 0 \n</code></pre> <p>Enable the extended logical volume</p> <pre><code>swapon -va\n</code></pre> <p>Test that the swap has been extended properly</p> <pre><code>cat /proc/swaps # free\n</code></pre> Output<pre><code>Filename                                Type            Size            Used            Priority\n/dev/dm-0                               partition       8388592         0               -2\n</code></pre>","tags":["proxmox","rpi","rpi4","rpi5"]},{"location":"tools/lvm/#lvm-thin","title":"LVM Thin","text":"<p>Create an LVM thin pool which allocates blocks when they are written, thereby saving disk space.</p> <p>Code</p> <pre><code>(\n  lvcreate -L 100G -n data pve &amp;&amp; \\\n  lvconvert --type thin-pool pve/data\n)\n</code></pre> <code>/etc/pve/storage.cfg</code> <pre><code>lvmthin: local-lvm\n         thinpool data\n         vgname pve\n         content rootdir,images\n</code></pre>","tags":["proxmox","rpi","rpi4","rpi5"]},{"location":"tools/lvm/#troubleshooting","title":"Troubleshooting","text":"<p>Activate LVM volume group</p> <pre><code>vgchange -ay\n</code></pre> Code <pre><code>foo@pi23:/wrk $ cat sdlvm\n#!/bin/false\n\n#umount /mnt/dev/p2\n#umount /mnt/dev/p1\n#vgremove $(hostname)\n#pvremove \"$1\"\"2\"\n\nwhich pvs || exit 1\n[ -z \"$1\" ] &amp;&amp; exit 1\n\nE=echo\n#chk and umount /dev/media/*\n$E vgchange -an -y $(hostname)\n$E vgremove -y $(hostname)\n$E pvremove \"$1\"\"2\"\n\n$E parted -s \"$1\" mklabel gpt || exit 1\n$E parted -s \"$1\" mkpart primary 4M 516M || exit 1\n$E parted -s \"$1\" mkpart primary 516M 64G || exit 1\n$E parted -s \"$1\" name 1 bootfs || exit 1\n$E parted -s \"$1\" name 2 rootfs || exit 1\n$E parted -s \"$1\" set 1 boot on || exit 1\n$E parted -s \"$1\" set 2 lvm on || exit 1\n$E pvcreate \"$1\"\"2\"  || exit 1\n$E vgcreate $(hostname) \"$1\"\"2\" || exit 1\n$E lvcreate -y -n rootfs -l 100%FREE $(hostname) || exit 1\n$E mkfs.vfat \"$1\"\"1\" || exit 1\n$E mkfs.ext4 \"/dev/\"$(hostname)\"/rootfs\" || exit 1\n$E mkdir -p /mnt/dev/p{1,2} || exit 1\n$E mount \"$1\"\"1\" /mnt/dev/p1 || exit 1\n$E mount \"/dev/\"$(hostname)\"/rootfs\" /mnt/dev/p2 || exit 1\n$E update-initramfs -u -k all\n$E DRY=\" \" sys-rbackup /boot/firmware/ /mnt/dev/p1/ || exit 1\n$E DRY=\" \" sys-rbackup / /mnt/dev/p2/ || exit 1\n$E sed -i -e \"s,root=[^[:space:]]*,root=/dev/mapper/$(hostname)-rootfs,\" /mnt/dev/p1/cmdline.txt || exit 1\n$E sed -i -e \"s,PART.*=.*-01[^[:space:]]*,PARTLABEL=bootfs,\" /mnt/dev/p2/etc/fstab || exit 1\n$E sed -i -e \"s,PART.*=.*-02[^[:space:]]*,/dev/mapper/$(hostname)-rootfs,\" /mnt/dev/p2/etc/fstab || exit 1\n\n$E cat /mnt/dev/p2/etc/fstab\n$E umount /mnt/dev/p2 || exit 1\n$E cat /mnt/dev/p1/cmdline.txt\n$E umount /mnt/dev/p1 || exit 1\n</code></pre>","tags":["proxmox","rpi","rpi4","rpi5"]},{"location":"tools/lvm/#references","title":"References","text":"<ul> <li>https://github.com/MikeJansen/rpi-boot-lvm</li> <li>https://raspberrypi.stackexchange.com/questions/85958/easy-backups-and-snapshots-of-a-running-system-with-lvm</li> </ul>","tags":["proxmox","rpi","rpi4","rpi5"]},{"location":"tools/micro/","title":"micro","text":"<p>micro is my editor of choice due to its modernity.</p>","tags":["tool"]},{"location":"tools/micro/#installation","title":"Installation","text":"aptbrew <pre><code>apt install micro\n</code></pre> <pre><code>brew install micro\n</code></pre>","tags":["tool"]},{"location":"tools/micro/#config","title":"Config","text":"<p>~/.config/micro/settings.json</p> AutomatedManual <pre><code>(\n  [ -d ~/.config/micro ] || mkdir -p ~/.config/micro\n  wget https://github.com/nicholaswilde/dotfiles2/raw/refs/heads/main/.config/micro/settings.json -O ~/.config/micro/settings.json\n)\n</code></pre> <pre><code># Ctrl + e\nset colorscheme twilight\nset tabsize 2\nset tabtospaces \"true\"\n</code></pre>","tags":["tool"]},{"location":"tools/micro/#catppuccin","title":"Catppuccin","text":"<ol> <li>Copy your preferred flavor(s) from <code>src/</code> to <code>~/.config/micro/colorschemes</code>.</li> <li>Add <code>export \"MICRO_TRUECOLOR=1\"</code> to your shell RC file (<code>bashrc</code>, <code>zshrc</code>, <code>config.fish</code>, etc).</li> <li>Open Micro, press <code>Ctrl+e</code>, type set <code>colorscheme catppuccin-&lt;flavor&gt;</code> (where  is one of <code>latte</code>, <code>frappe</code>, <code>macchiato</code>, or <code>mocha</code>), and press <code>Enter</code>. <p>Code</p> <pre><code>(\n  [ -d ~/.config/micro/colorschemes ] || mkdir -p ~/.config/micro/colorschemes\n  wget -O ~/.config/micro/colorschemes/\n  wget -O ~/.config/micro/colorschemes/\n)\n</code></pre>","tags":["tool"]},{"location":"tools/micro/#references","title":"References","text":"","tags":["tool"]},{"location":"tools/rclone/","title":"rclone","text":"<p>rclone is used to sync files between online services and my homelab.</p>","tags":["tools"]},{"location":"tools/rclone/#remote-setup","title":"Remote Setup","text":"<p>Because I mainly work on headless servers, I need to perform this remote setup when verifying the account.</p>","tags":["tools"]},{"location":"tools/rclone/#configuring-using-rclone-authorize","title":"Configuring using rclone authorize","text":"<p>On the headless box run <code>rclone config</code> but answer <code>N</code> to the <code>Use auto config?</code> question.</p> <p>headless box</p> <pre><code>Use auto config?\n * Say Y if not sure\n * Say N if you are working on a remote or headless machine\n\ny) Yes (default)\nn) No\ny/n&gt; n\n\nOption config_token.\nFor this to work, you will need rclone available on a machine that has\na web browser available.\nFor more help and alternate methods see: https://rclone.org/remote_setup/\nExecute the following on the machine with the web browser (same rclone\nversion recommended):\n\nrclone authorize \"onedrive\"\nThen paste the result.\nEnter a value.\nconfig_token&gt;\n</code></pre> <p>Then on your main desktop machine, enable port forwarding of <code>53682</code> for the ssh terminal and then:</p> <p>desktop machine</p> <pre><code>rclone authorize \"onedrive\"\nIf your browser doesn't open automatically go to the following link: http://127.0.0.1:53682/auth\nLog in and authorize rclone for access\nWaiting for code...\nGot code\nPaste the following into your remote machine ---&gt;\nSECRET_TOKEN\n&lt;---End paste\n</code></pre> <p>Then back to the headless box, paste in the code</p> <p>headless box</p> <pre><code>config_token&gt; SECRET_TOKEN\n--------------------\n[acd12]\nclient_id = \nclient_secret = \ntoken = SECRET_TOKEN\n--------------------\ny) Yes this is OK\ne) Edit this remote\nd) Delete this remote\ny/e/d&gt;\n</code></pre>","tags":["tools"]},{"location":"tools/rclone/#google-drive","title":"Google Drive","text":"<p>I use Google Drive as an offsite backup for some of my sensative data, such as Vaultwarden.</p>","tags":["tools"]},{"location":"tools/rclone/#configuration","title":"Configuration","text":"<p>The initial setup for drive involves getting a token from Google drive which you need to do in your browser. rclone config walks you through it.</p> <p>Note</p> <p>The remote is called <code>remote</code> in this example and so all relevant commands must use the name <code>remote</code>.</p> <p>How to make a remote called remote</p> <pre><code>rclone config\n</code></pre> <p>This will guide you through an interactive setup process</p> <pre><code>No remotes found, make a new one?\nn) New remote\nr) Rename remote\nc) Copy remote\ns) Set configuration password\nq) Quit config\nn/r/c/s/q&gt; n\nname&gt; remote\nType of storage to configure.\nChoose a number from below, or type in your own value\n[snip]\nXX / Google Drive\n   \\ \"drive\"\n[snip]\nStorage&gt; drive\nGoogle Application Client Id - leave blank normally.\nclient_id&gt;\nGoogle Application Client Secret - leave blank normally.\nclient_secret&gt;\nScope that rclone should use when requesting access from drive.\nChoose a number from below, or type in your own value\n 1 / Full access all files, excluding Application Data Folder.\n   \\ \"drive\"\n 2 / Read-only access to file metadata and file contents.\n   \\ \"drive.readonly\"\n   / Access to files created by rclone only.\n 3 | These are visible in the drive website.\n   | File authorization is revoked when the user deauthorizes the app.\n   \\ \"drive.file\"\n   / Allows read and write access to the Application Data folder.\n 4 | This is not visible in the drive website.\n   \\ \"drive.appfolder\"\n   / Allows read-only access to file metadata but\n 5 | does not allow any access to read or download file content.\n   \\ \"drive.metadata.readonly\"\nscope&gt; 1\nService Account Credentials JSON file path - needed only if you want use SA instead of interactive login.\nservice_account_file&gt;\nRemote config\nUse web browser to automatically authenticate rclone with remote?\n * Say Y if the machine running rclone has a web browser you can use\n * Say N if running rclone on a (remote) machine without web browser access\nIf not sure try Y. If Y failed, try N.\ny) Yes\nn) No\ny/n&gt; y\nIf your browser doesn't open automatically go to the following link: http://127.0.0.1:53682/auth\nLog in and authorize rclone for access\nWaiting for code...\nGot code\nConfigure this as a Shared Drive (Team Drive)?\ny) Yes\nn) No\ny/n&gt; n\nConfiguration complete.\nOptions:\ntype: drive\n- client_id:\n- client_secret:\n- scope: drive\n- root_folder_id:\n- service_account_file:\n- token: {\"access_token\":\"XXX\",\"token_type\":\"Bearer\",\"refresh_token\":\"XXX\",\"expiry\":\"2014-03-16T13:57:58.955387075Z\"}\nKeep this \"remote\" remote?\ny) Yes this is OK\ne) Edit this remote\nd) Delete this remote\ny/e/d&gt; y\n</code></pre> <p>See the remote setup docs for how to set it up on a machine with no Internet browser available.</p> <p>Note that rclone runs a webserver on your local machine to collect the token as returned from Google if using web browser to automatically authenticate. This only runs from the moment it opens your browser to the moment you get back the verification code. This is on http://127.0.0.1:53682/ and it may require you to unblock it temporarily if you are running a host firewall, or use manual mode.</p> <p>You can then use it like this,</p> <p>List directories in top level of your drive</p> <pre><code>rclone lsd remote:\n</code></pre> <p>List all the files in your drive</p> <pre><code>rclone ls remote:\n</code></pre> <p>To copy a local directory to a drive directory called backup</p> <pre><code>rclone copy /home/source remote:backup\n</code></pre>","tags":["tools"]},{"location":"tools/rclone/#making-your-own-client_id","title":"Making your own <code>client_id</code>","text":"<p>Please follow the steps in the google drive docs. You will need these scopes:</p> <pre><code>https://www.googleapis.com/auth/docs\nhttps://www.googleapis.com/auth/drive\nhttps://www.googleapis.com/auth/drive.metadata.readonly\n</code></pre>","tags":["tools"]},{"location":"tools/rclone/#google-photos","title":"Google Photos","text":"<p>I use Google Photos to create a shared album and sync the album with my digital picture frame via FrameFi.</p> <p>Warning</p> <p>Rclone can only download photos from albums that were created by rclone itself. It cannot download from albums created directly in Google Photos or by other applications.</p> <p>How to make a remote called remote</p> <pre><code>rclone config\n</code></pre> <p>This will guide you through an interactive setup process</p> <pre><code>No remotes found, make a new one?\nn) New remote\ns) Set configuration password\nq) Quit config\nn/s/q&gt; n\nname&gt; remote\nType of storage to configure.\nEnter a string value. Press Enter for the default (\"\").\nChoose a number from below, or type in your own value\n[snip]\nXX / Google Photos\n   \\ \"google photos\"\n[snip]\nStorage&gt; google photos\n** See help for google photos backend at: https://rclone.org/googlephotos/ **\n\nGoogle Application Client Id\nLeave blank normally.\nEnter a string value. Press Enter for the default (\"\").\nclient_id&gt; \nGoogle Application Client Secret\nLeave blank normally.\nEnter a string value. Press Enter for the default (\"\").\nclient_secret&gt; \nSet to make the Google Photos backend read only.\n\nIf you choose read only then rclone will only request read only access\nto your photos, otherwise rclone will request full access.\nEnter a boolean value (true or false). Press Enter for the default (\"false\").\nread_only&gt; \nEdit advanced config? (y/n)\ny) Yes\nn) No\ny/n&gt; n\nRemote config\nUse web browser to automatically authenticate rclone with remote?\n * Say Y if the machine running rclone has a web browser you can use\n * Say N if running rclone on a (remote) machine without web browser access\nIf not sure try Y. If Y failed, try N.\ny) Yes\nn) No\ny/n&gt; y\nIf your browser doesn't open automatically go to the following link: http://127.0.0.1:53682/auth\nLog in and authorize rclone for access\nWaiting for code...\nGot code\n\n*** IMPORTANT: All media items uploaded to Google Photos with rclone\n*** are stored in full resolution at original quality.  These uploads\n*** will count towards storage in your Google Account.\n\nConfiguration complete.\nOptions:\n- type: google photos\n- token: {\"access_token\":\"XXX\",\"token_type\":\"Bearer\",\"refresh_token\":\"XXX\",\"expiry\":\"2019-06-28T17:38:04.644930156+01:00\"}\nKeep this \"remote\" remote?\ny) Yes this is OK\ne) Edit this remote\nd) Delete this remote\ny/e/d&gt; y\n</code></pre>","tags":["tools"]},{"location":"tools/rclone/#making-your-own-client_id_1","title":"Making your own <code>client_id</code>","text":"<p>When you use <code>rclone</code> with Google photos in its default configuration you are using rclone's <code>client_id</code>. This is shared between all the <code>rclone</code> users. There is a global rate limit on the number of queries per second that each <code>client_id</code> can do set by Google.</p> <p>If there is a problem with this <code>client_id</code> (eg quota too low or the <code>client_id</code> stops working) then you can make your own.</p> <p>Please follow the steps in the google drive docs. You will need these scopes instead of the drive ones detailed:</p> <pre><code>https://www.googleapis.com/auth/photoslibrary.appendonly\nhttps://www.googleapis.com/auth/photoslibrary.readonly.appcreateddata\nhttps://www.googleapis.com/auth/photoslibrary.edit.appcreateddata\n</code></pre>","tags":["tools"]},{"location":"tools/rclone/#references","title":"References","text":"<ul> <li>https://rclone.org/remote_setup/</li> <li>https://rclone.org/</li> <li>https://rclone.org/googlephotos/</li> <li>https://rclone.org/drive/</li> </ul>","tags":["tools"]},{"location":"tools/ripgrep/","title":":magnify: ripgrep","text":"<p>ripgrep is a line-oriented search tool that recursively searches your current directory for a regex pattern.</p>","tags":["tool"]},{"location":"tools/ripgrep/#installation","title":"Installation","text":"<p>You can download pre-compiled binaries from the GitHub releases page.</p> repreproaptbrew <pre><code>sudo apt install ripgrep\n</code></pre> <pre><code>sudo apt install ripgrep\n</code></pre> <pre><code>brew install ripgrep\n</code></pre>","tags":["tool"]},{"location":"tools/ripgrep/#config","title":"Config","text":"<p>Ripgrep can be configured with a configuration file. By default, ripgrep will look for a configuration file in <code>$XDG_CONFIG_HOME/ripgrep/config</code> or <code>$HOME/.ripgreprc</code>.</p> <p>$HOME/.ripgreprc</p> <pre><code>--type-not=markdown\n--smart-case\n</code></pre>","tags":["tool"]},{"location":"tools/ripgrep/#usage","title":"Usage","text":"<p>1. Find a pattern in a file</p> <pre><code>rg \"pattern\" file.txt\n</code></pre> <p>2. Recursively search for a pattern</p> <pre><code>rg \"pattern\"\n</code></pre> <p>3. Find files that contain a pattern</p> <pre><code>rg -l \"pattern\"\n</code></pre> <p>4. Search for a pattern in a specific file type</p> <pre><code>rg \"pattern\" -g \"*.js\"\n</code></pre>","tags":["tool"]},{"location":"tools/ripgrep/#references","title":"References","text":"<ul> <li>https://github.com/BurntSushi/ripgrep</li> </ul>","tags":["tool"]},{"location":"tools/sd/","title":"sd","text":"<p>sd is an intuitive find &amp; replace command line tool.</p>","tags":["tool"]},{"location":"tools/sd/#installation","title":"Installation","text":"repreproaptbrew <pre><code>sudo apt install sd\n</code></pre> <pre><code>sudo apt install sd\n</code></pre> <pre><code>brew install sd\n</code></pre>","tags":["tool"]},{"location":"tools/sd/#usage","title":"Usage","text":"<p>1. Replace a string</p> <pre><code>echo \"hello world\" | sd \"world\" \"there\"\n# Output: hello there\n</code></pre> <p>2. Replace all occurrences of a string</p> <pre><code>echo \"hello world world\" | sd -s \"world\" \"there\"\n# Output: hello there there\n</code></pre> <p>3. Replace using regular expressions</p> <pre><code>echo \"foo 123 bar\" | sd \"\\d+\" \"NUM\"\n# Output: foo NUM bar\n</code></pre> <p>4. Replace in a file (in-place)</p> <pre><code>sd \"old_string\" \"new_string\" file.txt\n</code></pre>","tags":["tool"]},{"location":"tools/sd/#references","title":"References","text":"<ul> <li>https://github.com/chmln/sd</li> </ul>","tags":["tool"]},{"location":"tools/sops/","title":"SOPS","text":"<p>SOPS is used to encrypt and decrypt secrets in my homelab.</p> <p>Typically, my secrets are kept in <code>.env</code> files that are read as environmental variables and then used my configs.</p> <p>Other files are encrypted that have secrets, such as yaml config or sqlite db files.</p> <p>age is my encryption of choice.</p>","tags":["tool"]},{"location":"tools/sops/#installation","title":"Installation","text":"repreprobrew <pre><code>apt install sops\n</code></pre> <pre><code>brew install sops\n</code></pre>","tags":["tool"]},{"location":"tools/sops/#config","title":"Config","text":"","tags":["tool"]},{"location":"tools/sops/#keys","title":"Keys","text":"<p>~/.config/sops/age/keys.txt</p> SCPLastPass <pre><code>(\n  [ -d ~/.config/sops/age ] || mkdir -p ~/.config/sops/age\n  scp nicholas@192.168.2.250/home/nicholas/.config/sops/age/keys.txt ~/.config/sops/age/\n)\n</code></pre> <pre><code>(\n  [ -d ~/.config/sops/age ] || mkdir -p ~/.config/sops/age\n  lpass show sops-age --attach=att-2571789250549588435-38084 -q &gt; ~/.config/sops/age/keys.txt\n)\n</code></pre> <p>.sops.yaml</p> Manual <pre><code>---\ncreation_rules:\n  - filename_regex: \\.yaml$\n    age: 'age1x2at6wwq2gks47fsep9a25emdeqd93e3k0gfsswtmhruqrteu5jqjvy7kd'\n  - filename_regex: \\.db$\n    age: 'age1x2at6wwq2gks47fsep9a25emdeqd93e3k0gfsswtmhruqrteu5jqjvy7kd'\n</code></pre>","tags":["tool"]},{"location":"tools/sops/#usage","title":"Usage","text":"","tags":["tool"]},{"location":"tools/sops/#encrypt","title":"Encrypt","text":"task.env <pre><code>task encrypt\n</code></pre> <pre><code>sops -e .env &gt; .env.enc\n</code></pre>","tags":["tool"]},{"location":"tools/sops/#decrypt","title":"Decrypt","text":"task.env <pre><code>task decrypt\n</code></pre> <pre><code>sops -d --input-type dotenv --output-type dotenv .env.enc &gt; .env\n</code></pre>","tags":["tool"]},{"location":"tools/sops/#references","title":"References","text":"","tags":["tool"]},{"location":"tools/syncthing/","title":"Syncthing","text":"<p>Syncthing is used to syncronize my keys across my containers so I don't need to manually copy them over.</p> <p>This is preferred over Ansible so that I can more easily update them by updating the source.</p>","tags":["tool"]},{"location":"tools/syncthing/#installation","title":"Installation","text":"<p>Installed via <code>homelab-pull</code>.</p>","tags":["tool"]},{"location":"tools/syncthing/#config","title":"Config","text":"","tags":["tool"]},{"location":"tools/syncthing/#control-node","title":"Control Node","text":"<ol> <li>Add managed node.</li> <li>Add managed node to shared folders.</li> </ol>","tags":["tool"]},{"location":"tools/syncthing/#managed-node","title":"Managed Node","text":"<ol> <li>Add control node.</li> <li>Remove shared folder.</li> <li>Accept shared folders from control node.</li> </ol>","tags":["tool"]},{"location":"tools/syncthing/#references","title":"References","text":"<ul> <li>https://syncthing.net/</li> </ul>","tags":["tool"]},{"location":"tools/task/","title":"Task","text":"<p>Task is used to help automate tasks, such as <code>make</code>.</p>","tags":["tool"]},{"location":"tools/task/#installation","title":"Installation","text":"reprepeoinstaller <pre><code>apt install task\n</code></pre> <pre><code>curl https://installer.l.nicholaswilde.io/go-task/task! | bash\n</code></pre>","tags":["tool"]},{"location":"tools/task/#config","title":"Config","text":"<p>Most apps should have <code>Taskfiles.yml</code> in their directories to help manage the apps.</p>","tags":["tool"]},{"location":"tools/task/#usage","title":"Usage","text":"<p>Change to app directory</p> <pre><code>cd pve/&lt;appname&gt;\n</code></pre> <p>List available commands</p> <pre><code>task\n</code></pre> <p>Run task</p> <pre><code>task restart\n</code></pre>","tags":["tool"]},{"location":"tools/task/#common-tasks","title":"Common Tasks","text":"Task Description <code>serve</code> Start a web server <code>up</code> Start a Docker container <code>restart</code> Restart a systemd service <code>upgrade</code> Update the repo and update the running Docker container <code>update</code> Update the running Docker container <code>mklinks</code> Make symlinks to config files <code>deps</code> Install dependencies","tags":["tool"]},{"location":"tools/task/#references","title":"References","text":"","tags":["tool"]},{"location":"tools/tmux/","title":"tmux","text":"<p>tmux is a terminal multiplexer.</p>","tags":["tool"]},{"location":"tools/tmux/#installation","title":"Installation","text":"aptbrew <pre><code>sudo apt update\nsudo apt install tmux\n</code></pre> <pre><code>brew install tmux\n</code></pre>","tags":["tool"]},{"location":"tools/tmux/#config","title":"Config","text":"<p>A basic <code>tmux</code> configuration can be set up in <code>~/.tmux.conf</code>.</p> <p>~/.tmux.conf</p> <pre><code># Set prefix key to 'Ctrl-a'\nset -g prefix C-a\nunbind C-b\nbind C-a send-prefix\n\n# Enable mouse support\nset -g mouse on\n\n# Set vi-mode for copy mode\nset-window-option -g mode-keys vi\n\n# Reload config file\nbind r source-file ~/.tmux.conf \\; display-message \"Config reloaded!\"\n</code></pre>","tags":["tool"]},{"location":"tools/tmux/#catppuccin-theme","title":"Catppuccin Theme","text":"<p>To install the Catppuccin theme for <code>tmux</code>, follow these steps:</p> <ol> <li>Clone the Catppuccin <code>tmux</code> plugin:</li> </ol> <p>Clone Catppuccin tmux plugin</p> <pre><code>git clone https://github.com/catppuccin/tmux ~/.tmux/plugins/catppuccin\n</code></pre> <ol> <li>Add the plugin to your <code>~/.tmux.conf</code> file:</li> </ol> <p>~/.tmux.conf</p> <pre><code>set -g @plugin 'catppuccin/tmux'\n\n# Optional: Set Catppuccin flavor (mocha, macchiato, frappe, latte)\nset -g @catppuccin_flavour 'mocha'\n\nrun '~/.tmux/plugins/tpm/tpm'\n</code></pre> <ol> <li>Install <code>tpm</code> (Tmux Plugin Manager) if you haven't already:</li> </ol> <p>Install tpm</p> <pre><code>git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm\n</code></pre> <ol> <li>Start a new <code>tmux</code> session or reload your <code>tmux</code> configuration (<code>prefix + r</code>), then press <code>prefix + I</code> (capital I) to install the plugin.</li> </ol>","tags":["tool"]},{"location":"tools/tmux/#usage","title":"Usage","text":"<p>To start a new <code>tmux</code> session:</p> <pre><code>tmux new -s my_session\n</code></pre> <p>To detach from a session:</p> <pre><code>tmux detach\n</code></pre> <p>To attach to an existing session:</p> <pre><code>tmux attach -t my_session\n</code></pre>","tags":["tool"]},{"location":"tools/tmux/#references","title":"References","text":"<ul> <li>https://github.com/tmux/tmux</li> <li>https://github.com/catppuccin/tmux</li> </ul>","tags":["tool"]},{"location":"tools/webhook/","title":"webhook","text":"<p>webhook is a lightweight incoming webhook server to run shell commands</p>","tags":["tool"]},{"location":"tools/webhook/#installation","title":"Installation","text":"<p>You can download pre-compiled binaries from the [GitHub releases page][2].</p> repreproaptDockerbrew <pre><code>sudo apt install webhook\n</code></pre> <pre><code>sudo apt install webhook\n</code></pre> <pre><code>docker pull adnanh/webhook\n</code></pre> <pre><code>brew install webhook\n</code></pre>","tags":["tool"]},{"location":"tools/webhook/#config","title":"Config","text":"<p>webhook is configured using a single JSON or YAML file (e..g., hooks.json) that contains an array of hook definitions. A minimal hooks.json file looks like this:</p> YAMLJSON <p>hook.yaml</p> <pre><code>- id: redeploy-my-app\n  execute-command: /var/scripts/redeploy.sh\n  command-working-directory: /var/scripts/\n</code></pre> <p><code>hook.json</code></p> <pre><code>[\n  {\n    \"id\": \"redeploy-my-app\",\n    \"execute-command\": \"/var/scripts/redeploy.sh\",\n    \"command-working-directory\": \"/var/scripts/\"\n  }\n]\n</code></pre> <p>To secure your webhook, you should add a trigger-rule. A common method is to use a secret, which can be passed as a URL parameter or in the payload.</p> <p>Here is a more secure example that triggers the hook only if the secret \"my-secret-token\" is provided:</p> YAMLJSON <p><code>hook.yaml</code></p> <pre><code>- id: redeploy-my-app\n  execute-command: /var/scripts/redeploy.sh\n  command-working-directory: /var/scripts/\n  trigger-rule:\n    match:\n      type: value\n      value: my-secret-token\n      parameter:\n        source: url\n        name: secret\n</code></pre> <p><code>hook.json</code></p> <pre><code>[\n  {\n    \"id\": \"redeploy-my-app\",\n    \"execute-command\": \"/var/scripts/redeploy.sh\",\n    \"command-working-directory\": \"/var/scripts/\",\n    \"trigger-rule\": {\n      \"match\": {\n        \"type\": \"value\",\n        \"value\": \"my-secret-token\",\n        \"parameter\": {\n          \"source\": \"url\",\n          \"name\": \"secret\"\n        }\n      }\n    }\n  }\n]\n</code></pre>","tags":["tool"]},{"location":"tools/webhook/#usage","title":"Usage","text":"<p>1. Run the Server</p> <p>Start the webhook server, pointing it to your configuration file. By default, it runs on port <code>9000</code>.</p> <pre><code>webhook -hooks /etc/webhook/hooks.json -verbose\n</code></pre> <ul> <li><code>-hooks</code>: Specifies the path to your hook configuration file.</li> <li><code>-verbose</code>: (Optional) Provides detailed logging.</li> </ul> <p>2. Trigger the Hook</p> <p>You can trigger a hook by sending an HTTP POST request to its endpoint.</p> <p>Simple Hook (no trigger rule)</p> <pre><code>curl -X POST http://your-server-ip:9000/hooks/redeploy-my-app\n</code></pre> <p>Secure Hook (with URL secret)</p> <pre><code>curl -X POST http://your-server-ip:9000/hooks/redeploy-my-app?secret=my-secret-token\n</code></pre> <p>The command specified in your hooks.json (<code>/var/scripts/redeploy.sh</code> in this example) will then be executed on the server.</p>","tags":["tool"]},{"location":"tools/webhook/#references","title":"References","text":"<ul> <li>https://github.com/adnanh/webhook</li> </ul>","tags":["tool"]}]}